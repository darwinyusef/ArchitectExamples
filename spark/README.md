# Spark MLflow Learning Examples

Proyecto de aprendizaje de Apache Spark integrado con MLflow y diferentes frameworks de Machine Learning.

## Estructura del Proyecto

```
spark/
‚îú‚îÄ‚îÄ notebooks/           # Jupyter notebooks con ejemplos pr√°cticos
‚îÇ   ‚îú‚îÄ‚îÄ 01_spark_airflow_mlflow.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_spark_pytorch_mlflow.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_spark_tensorflow_mlflow.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 04_spark_sklearn_mlflow.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 05_spark_scipy_mathematics.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 06_spark_clustering_postgres.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 07_mlflow_visualizations.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 08_proyecto_final_integracion.ipynb   ‚≠ê PROYECTO FINAL
‚îú‚îÄ‚îÄ data/               # Datos para los ejemplos
‚îÇ   ‚îú‚îÄ‚îÄ raw/           # Datos sin procesar
‚îÇ   ‚îî‚îÄ‚îÄ processed/     # Datos procesados
‚îú‚îÄ‚îÄ scripts/           # Scripts auxiliares
‚îú‚îÄ‚îÄ config/            # Configuraciones
‚îú‚îÄ‚îÄ logs/              # Logs de ejecuci√≥n
‚îú‚îÄ‚îÄ docker-compose.yml # Servicios (MLflow, Postgres, Airflow)
‚îî‚îÄ‚îÄ requirements.txt   # Dependencias Python
```

## Notebooks Disponibles

### 1. Spark + Airflow + MLflow
- Orquestaci√≥n de pipelines de datos con Airflow
- Tracking de experimentos con MLflow
- Ejecuci√≥n distribuida con Spark

### 2. Spark + PyTorch + MLflow
- Deep Learning distribuido con PyTorch y Spark
- Entrenamiento de redes neuronales
- Versionado de modelos con MLflow

### 3. Spark + TensorFlow + MLflow
- Integraci√≥n de TensorFlow con Spark
- Procesamiento de datos a escala
- Registro de m√©tricas y modelos

### 4. Spark + Scikit-learn + MLflow
- Machine Learning cl√°sico con Spark ML y Sklearn
- Pipelines de ML distribuidos
- Comparaci√≥n de modelos

### 5. Spark + SciPy + Matem√°ticas para ML
- Operaciones matem√°ticas avanzadas
- Optimizaci√≥n y estad√≠stica
- √Ålgebra lineal distribuida

### 6. Spark + Clustering + PostgreSQL
- Modelos de clustering (K-Means, DBSCAN, etc.)
- Almacenamiento en PostgreSQL
- An√°lisis de grandes vol√∫menes de datos

### 7. MLflow + Visualizaciones (Matplotlib & Seaborn)
- Integraci√≥n de gr√°ficos con MLflow
- Visualizaciones est√°ticas e interactivas
- Confusion matrix, ROC curves, Feature importance
- Dashboards con Plotly
- Best practices de visualizaci√≥n en ML

### 8. ‚≠ê PROYECTO FINAL: Sistema de Detecci√≥n de Fraude End-to-End
**Integraci√≥n completa de todas las tecnolog√≠as**
- ‚úÖ Spark (procesamiento distribuido)
- ‚úÖ MLflow (tracking y gesti√≥n de modelos)
- ‚úÖ Airflow (orquestaci√≥n de pipelines)
- ‚úÖ Scikit-learn (modelos de ML)
- ‚úÖ SciPy (an√°lisis estad√≠stico)
- ‚úÖ PostgreSQL (almacenamiento de datos)
- ‚úÖ Parquet (formato de datos eficiente)
- ‚úÖ Matplotlib/Seaborn (visualizaciones)
- ‚úÖ MLOps (best practices de producci√≥n)

**Pipeline completo de 13 pasos:**
1. Setup e inicializaci√≥n
2. Generaci√≥n de datos sint√©ticos
3. Almacenamiento en PostgreSQL
4. Procesamiento con Spark y Parquet
5. An√°lisis exploratorio con SciPy
6. Feature engineering
7. Preparaci√≥n de datos para ML
8. Entrenamiento de modelos
9. Comparaci√≥n y selecci√≥n
10. Evaluaci√≥n detallada
11. Guardado de resultados
12. Resumen y MLOps
13. Automatizaci√≥n con Airflow

üìñ Ver [PROYECTO_FINAL.md](PROYECTO_FINAL.md) para documentaci√≥n completa

## Instalaci√≥n

### Requisitos Previos
- Python 3.8+
- Java 8 o 11
- Docker y Docker Compose (opcional, para servicios)

### Instalaci√≥n de Dependencias

```bash
pip install -r requirements.txt
```

### Iniciar Servicios con Docker

```bash
docker-compose up -d
```

Esto iniciar√°:
- MLflow UI: http://localhost:5000
- PostgreSQL: localhost:5432
- Airflow: http://localhost:8080
- PgAdmin: http://localhost:5050
- Grafana: http://localhost:3000 (admin/admin)

## Uso

1. Iniciar Jupyter Notebook:
```bash
jupyter notebook
```

2. Navegar a la carpeta `notebooks/`

3. Abrir cualquier notebook y ejecutar las celdas secuencialmente

## Configuraci√≥n de Spark

Los notebooks est√°n configurados para ejecutarse en modo local por defecto. Para usar un cluster:

```python
spark = SparkSession.builder \
    .master("spark://master:7077") \
    .appName("MyApp") \
    .getOrCreate()
```

## MLflow Tracking

Para visualizar experimentos:

```bash
mlflow ui --backend-store-uri sqlite:///mlflow.db
```

## Notas

- Cada notebook es independiente y puede ejecutarse por separado
- Los datos de ejemplo se generan autom√°ticamente en cada notebook
- Los modelos se guardan en la carpeta `mlruns/`
- Los logs de Spark se almacenan en `logs/`

## Monitoreo con Grafana

El proyecto incluye dashboards pre-configurados de Grafana para monitorear:

### Dashboards Disponibles

1. **Fraud Detection Overview** (`fraud_overview`)
   - Transacciones en tiempo real
   - M√©tricas de fraude
   - An√°lisis por categor√≠a y hora
   - Refresh: 5 segundos

2. **Model Performance Monitoring** (`model_performance`)
   - M√©tricas de modelos ML (accuracy, precision, recall, F1)
   - Confusion matrix components
   - Tendencias de performance
   - Refresh: 30 segundos

### Acceso a Grafana

```
URL: http://localhost:3000
Usuario: admin
Contrase√±a: admin
```

üìñ Ver [GRAFANA_GUIDE.md](GRAFANA_GUIDE.md) para gu√≠a completa de uso

## Recursos Adicionales

- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [Airflow Documentation](https://airflow.apache.org/docs/)
- [Grafana Documentation](https://grafana.com/docs/)

## Autor

Yusef Gonz√°lez - Proyecto de aprendizaje Spark + MLflow
