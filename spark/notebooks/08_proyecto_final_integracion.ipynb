{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Final: Sistema de DetecciÃ³n de Fraude End-to-End\n",
    "\n",
    "## ğŸ¯ Objetivo\n",
    "\n",
    "Crear un **sistema completo de detecciÃ³n de fraude** que integre:\n",
    "- âœ… **Spark** - Procesamiento distribuido\n",
    "- âœ… **MLflow** - Tracking y gestiÃ³n de modelos\n",
    "- âœ… **Airflow** - OrquestaciÃ³n de pipelines\n",
    "- âœ… **Scikit-learn** - Modelos de ML\n",
    "- âœ… **SciPy** - AnÃ¡lisis estadÃ­stico\n",
    "- âœ… **PostgreSQL** - Almacenamiento de datos\n",
    "- âœ… **Parquet** - Formato de datos eficiente\n",
    "- âœ… **Matplotlib/Seaborn** - Visualizaciones\n",
    "- âœ… **MLOps** - Best practices de producciÃ³n\n",
    "\n",
    "## ğŸ“‹ Arquitectura del Sistema\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    PIPELINE DE DATOS                        â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ 1. Ingesta (Spark)      â†’ PostgreSQL                       â”‚\n",
    "â”‚ 2. TransformaciÃ³n       â†’ Parquet Files                    â”‚\n",
    "â”‚ 3. Feature Engineering  â†’ SciPy Statistics                 â”‚\n",
    "â”‚ 4. Entrenamiento        â†’ Scikit-learn + MLflow            â”‚\n",
    "â”‚ 5. EvaluaciÃ³n           â†’ Matplotlib/Seaborn               â”‚\n",
    "â”‚ 6. Deployment          â†’ MLflow Model Registry             â”‚\n",
    "â”‚ 7. Monitoring          â†’ PostgreSQL + Dashboards           â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                         Orquestado por Airflow\n",
    "```\n",
    "\n",
    "## ğŸš€ Escenario\n",
    "\n",
    "**Banco XYZ** necesita un sistema automatizado para:\n",
    "- Detectar transacciones fraudulentas en tiempo casi real\n",
    "- Procesar millones de transacciones diarias\n",
    "- Mejorar continuamente el modelo\n",
    "- Cumplir con regulaciones (trazabilidad)\n",
    "\n",
    "## ğŸ“Š Dataset\n",
    "\n",
    "Transacciones bancarias con:\n",
    "- `transaction_id`: ID Ãºnico\n",
    "- `customer_id`: ID del cliente\n",
    "- `amount`: Monto de la transacciÃ³n\n",
    "- `merchant_category`: CategorÃ­a del comercio\n",
    "- `transaction_hour`: Hora del dÃ­a\n",
    "- `is_international`: TransacciÃ³n internacional (0/1)\n",
    "- `card_present`: Tarjeta presente fÃ­sicamente (0/1)\n",
    "- `distance_from_home`: Distancia del domicilio (km)\n",
    "- `is_fraud`: Target variable (0/1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PASO 1: Setup e InicializaciÃ³n\n",
    "\n",
    "Configurar todas las herramientas y conexiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, mean, stddev, count, lit, udf\n",
    "from pyspark.sql.types import FloatType, IntegerType, StringType\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    roc_curve, precision_recall_curve\n",
    ")\n",
    "\n",
    "# SciPy\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.spark\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Database\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "print('âœ… Importaciones completadas')\n",
    "print(f'ğŸ“… Fecha: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConfiguraciÃ³n global\n",
    "PROJECT_NAME = 'fraud-detection-system'\n",
    "VERSION = 'v1.0'\n",
    "DATA_PATH = '../data'\n",
    "LOGS_PATH = '../logs'\n",
    "\n",
    "# Crear directorios\n",
    "os.makedirs(f'{DATA_PATH}/raw', exist_ok=True)\n",
    "os.makedirs(f'{DATA_PATH}/processed', exist_ok=True)\n",
    "os.makedirs(f'{DATA_PATH}/parquet', exist_ok=True)\n",
    "os.makedirs(LOGS_PATH, exist_ok=True)\n",
    "os.makedirs('visualizations', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "print(f'âœ… Proyecto: {PROJECT_NAME} {VERSION}')\n",
    "print(f'âœ… Directorios creados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(f'{PROJECT_NAME}-{VERSION}') \\\n",
    "    .master('local[*]') \\\n",
    "    .config('spark.driver.memory', '4g') \\\n",
    "    .config('spark.executor.memory', '4g') \\\n",
    "    .config('spark.sql.execution.arrow.pyspark.enabled', 'true') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f'âœ… Spark {spark.version} inicializado')\n",
    "print(f'   Cores disponibles: {spark.sparkContext.defaultParallelism}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar MLflow\n",
    "mlflow.set_tracking_uri('http://localhost:5000')\n",
    "mlflow.set_experiment(f'{PROJECT_NAME}')\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "print(f'âœ… MLflow configurado')\n",
    "print(f'   Tracking URI: {mlflow.get_tracking_uri()}')\n",
    "print(f'   Experiment: {PROJECT_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar PostgreSQL\n",
    "POSTGRES_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': 5432,\n",
    "    'database': 'spark_ml_db',\n",
    "    'user': 'spark_user',\n",
    "    'password': 'spark_password'\n",
    "}\n",
    "\n",
    "POSTGRES_URL = f\"postgresql://{POSTGRES_CONFIG['user']}:{POSTGRES_CONFIG['password']}@{POSTGRES_CONFIG['host']}:{POSTGRES_CONFIG['port']}/{POSTGRES_CONFIG['database']}\"\n",
    "\n",
    "try:\n",
    "    engine = create_engine(POSTGRES_URL)\n",
    "    # Test connection\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute('SELECT 1')\n",
    "    print('âœ… PostgreSQL conectado')\n",
    "except Exception as e:\n",
    "    print(f'âš ï¸  PostgreSQL no disponible: {e}')\n",
    "    print('   El proyecto continuarÃ¡ sin PostgreSQL')\n",
    "    engine = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PASO 2: GeneraciÃ³n de Datos SintÃ©ticos\n",
    "\n",
    "Crear dataset realista de transacciones bancarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transaction_data(n_samples=100000, fraud_ratio=0.05, seed=42):\n",
    "    \"\"\"\n",
    "    Generar dataset sintÃ©tico de transacciones bancarias\n",
    "    \n",
    "    Args:\n",
    "        n_samples: NÃºmero total de transacciones\n",
    "        fraud_ratio: ProporciÃ³n de fraudes (desbalanceado)\n",
    "        seed: Semilla para reproducibilidad\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame con transacciones\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Calcular nÃºmero de fraudes\n",
    "    n_fraud = int(n_samples * fraud_ratio)\n",
    "    n_normal = n_samples - n_fraud\n",
    "    \n",
    "    # Generar transacciones normales\n",
    "    normal_data = {\n",
    "        'amount': np.random.exponential(100, n_normal),\n",
    "        'merchant_category': np.random.choice(\n",
    "            ['grocery', 'restaurant', 'gas_station', 'retail', 'online'],\n",
    "            n_normal,\n",
    "            p=[0.3, 0.25, 0.15, 0.2, 0.1]\n",
    "        ),\n",
    "        'transaction_hour': np.random.choice(range(24), n_normal, p=[\n",
    "            0.01, 0.01, 0.01, 0.01, 0.01, 0.02,  # 0-5am (bajo)\n",
    "            0.03, 0.05, 0.06, 0.07, 0.08, 0.09,  # 6-11am (creciente)\n",
    "            0.08, 0.07, 0.06, 0.05, 0.06, 0.07,  # 12-5pm (alto)\n",
    "            0.08, 0.07, 0.05, 0.03, 0.02, 0.01   # 6-11pm (decreciente)\n",
    "        ]),\n",
    "        'is_international': np.random.choice([0, 1], n_normal, p=[0.95, 0.05]),\n",
    "        'card_present': np.random.choice([0, 1], n_normal, p=[0.3, 0.7]),\n",
    "        'distance_from_home': np.abs(np.random.normal(10, 20, n_normal)),\n",
    "        'customer_age': np.random.randint(18, 80, n_normal),\n",
    "        'num_transactions_day': np.random.poisson(3, n_normal),\n",
    "        'is_fraud': np.zeros(n_normal, dtype=int)\n",
    "    }\n",
    "    \n",
    "    # Generar transacciones fraudulentas (patrones diferentes)\n",
    "    fraud_data = {\n",
    "        'amount': np.random.exponential(500, n_fraud),  # Montos mÃ¡s altos\n",
    "        'merchant_category': np.random.choice(\n",
    "            ['grocery', 'restaurant', 'gas_station', 'retail', 'online'],\n",
    "            n_fraud,\n",
    "            p=[0.05, 0.05, 0.1, 0.3, 0.5]  # MÃ¡s online y retail\n",
    "        ),\n",
    "        'transaction_hour': np.random.choice(\n",
    "            range(24), n_fraud,\n",
    "            p=[0.08]*6 + [0.02]*12 + [0.06]*6  # MÃ¡s actividad nocturna\n",
    "        ),\n",
    "        'is_international': np.random.choice([0, 1], n_fraud, p=[0.6, 0.4]),  # MÃ¡s internacional\n",
    "        'card_present': np.random.choice([0, 1], n_fraud, p=[0.8, 0.2]),  # Menos presencial\n",
    "        'distance_from_home': np.abs(np.random.normal(100, 50, n_fraud)),  # MÃ¡s lejos\n",
    "        'customer_age': np.random.randint(18, 80, n_fraud),\n",
    "        'num_transactions_day': np.random.poisson(8, n_fraud),  # MÃ¡s transacciones\n",
    "        'is_fraud': np.ones(n_fraud, dtype=int)\n",
    "    }\n",
    "    \n",
    "    # Combinar\n",
    "    df_normal = pd.DataFrame(normal_data)\n",
    "    df_fraud = pd.DataFrame(fraud_data)\n",
    "    df = pd.concat([df_normal, df_fraud], ignore_index=True)\n",
    "    \n",
    "    # Shuffle\n",
    "    df = df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "    \n",
    "    # Agregar IDs y timestamps\n",
    "    df['transaction_id'] = range(len(df))\n",
    "    df['customer_id'] = np.random.randint(1000, 50000, len(df))\n",
    "    \n",
    "    # Timestamps realistas (Ãºltimos 30 dÃ­as)\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=30)\n",
    "    df['timestamp'] = pd.to_datetime(\n",
    "        np.random.randint(\n",
    "            start_date.timestamp(),\n",
    "            end_date.timestamp(),\n",
    "            len(df)\n",
    "        ),\n",
    "        unit='s'\n",
    "    )\n",
    "    \n",
    "    # Reordenar columnas\n",
    "    cols = ['transaction_id', 'customer_id', 'timestamp', 'amount', \n",
    "            'merchant_category', 'transaction_hour', 'is_international',\n",
    "            'card_present', 'distance_from_home', 'customer_age',\n",
    "            'num_transactions_day', 'is_fraud']\n",
    "    \n",
    "    return df[cols]\n",
    "\n",
    "# Generar datos\n",
    "print('â³ Generando transacciones...')\n",
    "df_transactions = generate_transaction_data(n_samples=100000, fraud_ratio=0.05)\n",
    "\n",
    "print(f'âœ… {len(df_transactions):,} transacciones generadas')\n",
    "print(f'   Fraudes: {df_transactions[\"is_fraud\"].sum():,} ({df_transactions[\"is_fraud\"].mean()*100:.2f}%)')\n",
    "print(f'   Normales: {(~df_transactions[\"is_fraud\"].astype(bool)).sum():,}')\n",
    "\n",
    "# Mostrar muestra\n",
    "df_transactions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PASO 3: Almacenamiento en PostgreSQL\n",
    "\n",
    "Guardar datos raw en base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar en PostgreSQL\n",
    "if engine is not None:\n",
    "    try:\n",
    "        print('â³ Guardando en PostgreSQL...')\n",
    "        df_transactions.to_sql(\n",
    "            'transactions_raw',\n",
    "            engine,\n",
    "            if_exists='replace',\n",
    "            index=False,\n",
    "            method='multi',\n",
    "            chunksize=1000\n",
    "        )\n",
    "        print(f'âœ… {len(df_transactions):,} registros guardados en PostgreSQL')\n",
    "        print('   Tabla: transactions_raw')\n",
    "        \n",
    "        # Verificar\n",
    "        query = \"SELECT COUNT(*) as total FROM transactions_raw\"\n",
    "        result = pd.read_sql(query, engine)\n",
    "        print(f'   VerificaciÃ³n: {result[\"total\"].values[0]:,} registros')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'âš ï¸  Error guardando en PostgreSQL: {e}')\n",
    "else:\n",
    "    print('âš ï¸  PostgreSQL no disponible - continuando sin persistencia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PASO 4: Procesamiento con Spark y Parquet\n",
    "\n",
    "Usar Spark para procesamiento distribuido y Parquet para almacenamiento eficiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a Spark DataFrame\n",
    "print('â³ Cargando datos en Spark...')\n",
    "df_spark = spark.createDataFrame(df_transactions)\n",
    "\n",
    "print(f'âœ… Spark DataFrame creado')\n",
    "print(f'   Particiones: {df_spark.rdd.getNumPartitions()}')\n",
    "print(f'   Registros: {df_spark.count():,}')\n",
    "\n",
    "# Schema\n",
    "print('\\nğŸ“‹ Schema:')\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar como Parquet (formato columnar eficiente)\n",
    "parquet_path = f'{DATA_PATH}/parquet/transactions'\n",
    "\n",
    "print(f'â³ Guardando en formato Parquet...')\n",
    "df_spark.write.mode('overwrite').parquet(parquet_path)\n",
    "\n",
    "print(f'âœ… Datos guardados en Parquet')\n",
    "print(f'   Ruta: {parquet_path}')\n",
    "\n",
    "# Verificar tamaÃ±o\n",
    "import subprocess\n",
    "size = subprocess.check_output(['du', '-sh', parquet_path]).split()[0].decode('utf-8')\n",
    "print(f'   TamaÃ±o: {size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer desde Parquet (mÃ¡s rÃ¡pido)\n",
    "print('â³ Leyendo desde Parquet...')\n",
    "df_spark = spark.read.parquet(parquet_path)\n",
    "\n",
    "print(f'âœ… Datos cargados desde Parquet')\n",
    "print(f'   Registros: {df_spark.count():,}')\n",
    "\n",
    "# Mostrar muestra\n",
    "df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PASO 5: AnÃ¡lisis Exploratorio con SciPy y Visualizaciones\n",
    "\n",
    "AnÃ¡lisis estadÃ­stico y visualizaciones con MLflow tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar run de MLflow para EDA\n",
    "with mlflow.start_run(run_name='01-exploratory-data-analysis') as run:\n",
    "    \n",
    "    mlflow.set_tag('stage', 'exploration')\n",
    "    mlflow.set_tag('version', VERSION)\n",
    "    \n",
    "    # Convertir a Pandas para anÃ¡lisis\n",
    "    df_pd = df_spark.toPandas()\n",
    "    \n",
    "    # === EstadÃ­sticas Descriptivas ===\n",
    "    print('ğŸ“Š ESTADÃSTICAS DESCRIPTIVAS\\n' + '='*60)\n",
    "    \n",
    "    stats_desc = df_pd.describe()\n",
    "    print(stats_desc)\n",
    "    \n",
    "    # Log a MLflow\n",
    "    mlflow.log_params({\n",
    "        'total_transactions': len(df_pd),\n",
    "        'n_customers': df_pd['customer_id'].nunique(),\n",
    "        'fraud_ratio': df_pd['is_fraud'].mean(),\n",
    "        'date_range_days': (df_pd['timestamp'].max() - df_pd['timestamp'].min()).days\n",
    "    })\n",
    "    \n",
    "    # === Tests EstadÃ­sticos con SciPy ===\n",
    "    print('\\nğŸ”¬ TESTS ESTADÃSTICOS (SciPy)\\n' + '='*60)\n",
    "    \n",
    "    # Test de normalidad para amount\n",
    "    sample_amount = df_pd['amount'].sample(min(5000, len(df_pd)), random_state=42)\n",
    "    stat, p_value = stats.shapiro(sample_amount)\n",
    "    print(f'Shapiro-Wilk test (amount):\")\n",
    "    print(f'  Statistic: {stat:.4f}')\n",
    "    print(f'  P-value: {p_value:.4e}')\n",
    "    print(f'  Normal: {\"No\" if p_value < 0.05 else \"SÃ­\"}')\n",
    "    mlflow.log_metric('amount_normality_pvalue', p_value)\n",
    "    \n",
    "    # Test t para diferencia de medias (fraude vs normal)\n",
    "    fraud_amounts = df_pd[df_pd['is_fraud'] == 1]['amount']\n",
    "    normal_amounts = df_pd[df_pd['is_fraud'] == 0]['amount']\n",
    "    t_stat, t_pvalue = stats.ttest_ind(fraud_amounts, normal_amounts)\n",
    "    print(f'\\nT-test (fraud vs normal amounts):')\n",
    "    print(f'  T-statistic: {t_stat:.4f}')\n",
    "    print(f'  P-value: {t_pvalue:.4e}')\n",
    "    print(f'  Diferencia significativa: {\"SÃ­\" if t_pvalue < 0.05 else \"No\"}')\n",
    "    mlflow.log_metric('ttest_pvalue', t_pvalue)\n",
    "    \n",
    "    # === VisualizaciÃ³n 1: Distribuciones ===\n",
    "    print('\\nğŸ“ˆ Creando visualizaciones...')\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Amount distribution\n",
    "    axes[0, 0].hist(df_pd[df_pd['is_fraud'] == 0]['amount'], \n",
    "                    bins=50, alpha=0.6, label='Normal', color='green')\n",
    "    axes[0, 0].hist(df_pd[df_pd['is_fraud'] == 1]['amount'], \n",
    "                    bins=50, alpha=0.6, label='Fraud', color='red')\n",
    "    axes[0, 0].set_xlabel('Amount ($)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title('Distribution of Transaction Amounts')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Hour distribution\n",
    "    hour_fraud = df_pd[df_pd['is_fraud'] == 1]['transaction_hour'].value_counts().sort_index()\n",
    "    hour_normal = df_pd[df_pd['is_fraud'] == 0]['transaction_hour'].value_counts().sort_index()\n",
    "    \n",
    "    x = np.arange(24)\n",
    "    width = 0.35\n",
    "    axes[0, 1].bar(x - width/2, hour_normal.values, width, label='Normal', alpha=0.8, color='green')\n",
    "    axes[0, 1].bar(x + width/2, hour_fraud.values, width, label='Fraud', alpha=0.8, color='red')\n",
    "    axes[0, 1].set_xlabel('Hour of Day')\n",
    "    axes[0, 1].set_ylabel('Count')\n",
    "    axes[0, 1].set_title('Transactions by Hour')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Distance distribution\n",
    "    axes[1, 0].boxplot(\n",
    "        [df_pd[df_pd['is_fraud'] == 0]['distance_from_home'],\n",
    "         df_pd[df_pd['is_fraud'] == 1]['distance_from_home']],\n",
    "        labels=['Normal', 'Fraud']\n",
    "    )\n",
    "    axes[1, 0].set_ylabel('Distance from Home (km)')\n",
    "    axes[1, 0].set_title('Distance from Home Distribution')\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Merchant category\n",
    "    category_counts = pd.crosstab(df_pd['merchant_category'], df_pd['is_fraud'])\n",
    "    category_counts.plot(kind='bar', stacked=False, ax=axes[1, 1], color=['green', 'red'])\n",
    "    axes[1, 1].set_xlabel('Merchant Category')\n",
    "    axes[1, 1].set_ylabel('Count')\n",
    "    axes[1, 1].set_title('Transactions by Merchant Category')\n",
    "    axes[1, 1].legend(['Normal', 'Fraud'])\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/01_eda_distributions.png', dpi=150, bbox_inches='tight')\n",
    "    mlflow.log_artifact('visualizations/01_eda_distributions.png', artifact_path='exploration')\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\nâœ… EDA completado y guardado en MLflow')\n",
    "    print(f'   Run ID: {run.info.run_id}')\n",
    "    \n",
    "    eda_run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PASO 6: Feature Engineering con Spark\n",
    "\n",
    "Crear features adicionales para mejorar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name='02-feature-engineering') as run:\n",
    "    \n",
    "    mlflow.set_tag('stage', 'feature_engineering')\n",
    "    mlflow.set_tag('version', VERSION)\n",
    "    \n",
    "    print('âš™ï¸  FEATURE ENGINEERING\\n' + '='*60)\n",
    "    \n",
    "    # === Features derivadas ===\n",
    "    df_featured = df_spark \\\n",
    "        .withColumn('amount_log', col('amount').log1p()) \\\n",
    "        .withColumn('is_night', when((col('transaction_hour') < 6) | (col('transaction_hour') > 22), 1).otherwise(0)) \\\n",
    "        .withColumn('is_weekend', when(col('timestamp').cast('string').substr(1, 3).isin(['Sat', 'Sun']), 1).otherwise(0)) \\\n",
    "        .withColumn('is_high_amount', when(col('amount') > 500, 1).otherwise(0)) \\\n",
    "        .withColumn('is_far', when(col('distance_from_home') > 50, 1).otherwise(0)) \\\n",
    "        .withColumn('risk_score', \n",
    "                   col('is_international') * 0.25 + \n",
    "                   col('is_night') * 0.20 + \n",
    "                   col('is_high_amount') * 0.30 + \n",
    "                   col('is_far') * 0.25) \\\n",
    "        .withColumn('transactions_per_day_log', col('num_transactions_day').log1p())\n",
    "    \n",
    "    print('âœ… Features creadas:')\n",
    "    new_features = ['amount_log', 'is_night', 'is_weekend', 'is_high_amount', \n",
    "                   'is_far', 'risk_score', 'transactions_per_day_log']\n",
    "    for feat in new_features:\n",
    "        print(f'   â€¢ {feat}')\n",
    "    \n",
    "    mlflow.log_param('new_features_count', len(new_features))\n",
    "    mlflow.log_param('new_features', ', '.join(new_features))\n",
    "    \n",
    "    # === Encoding categÃ³rico ===\n",
    "    print('\\nâš™ï¸  Encoding categÃ³rico...')\n",
    "    indexer = StringIndexer(inputCol='merchant_category', outputCol='merchant_category_idx')\n",
    "    df_featured = indexer.fit(df_featured).transform(df_featured)\n",
    "    \n",
    "    print('âœ… merchant_category â†’ merchant_category_idx')\n",
    "    \n",
    "    # === Mostrar muestra ===\n",
    "    print('\\nğŸ“‹ Muestra de features:')\n",
    "    df_featured.select('amount', 'amount_log', 'risk_score', 'is_fraud').show(5)\n",
    "    \n",
    "    # === Guardar featured data ===\n",
    "    featured_parquet_path = f'{DATA_PATH}/parquet/transactions_featured'\n",
    "    df_featured.write.mode('overwrite').parquet(featured_parquet_path)\n",
    "    \n",
    "    print(f'\\nâœ… Featured data guardada en: {featured_parquet_path}')\n",
    "    \n",
    "    feature_run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PASO 7: PreparaciÃ³n de Datos para ML\n",
    "\n",
    "Crear features vectors y split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer featured data\n",
    "df_featured = spark.read.parquet(featured_parquet_path)\n",
    "\n",
    "# Definir features para el modelo\n",
    "feature_cols = [\n",
    "    'amount_log',\n",
    "    'merchant_category_idx',\n",
    "    'transaction_hour',\n",
    "    'is_international',\n",
    "    'card_present',\n",
    "    'distance_from_home',\n",
    "    'customer_age',\n",
    "    'num_transactions_day',\n",
    "    'is_night',\n",
    "    'is_high_amount',\n",
    "    'is_far',\n",
    "    'risk_score',\n",
    "    'transactions_per_day_log'\n",
    "]\n",
    "\n",
    "print(f'ğŸ“Š Features seleccionadas: {len(feature_cols)}')\n",
    "for i, feat in enumerate(feature_cols, 1):\n",
    "    print(f'   {i:2d}. {feat}')\n",
    "\n",
    "# Ensamblar features\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features_raw')\n",
    "df_assembled = assembler.transform(df_featured)\n",
    "\n",
    "# Escalar features\n",
    "scaler = StandardScaler(inputCol='features_raw', outputCol='features', withMean=True, withStd=True)\n",
    "scaler_model = scaler.fit(df_assembled)\n",
    "df_scaled = scaler_model.transform(df_assembled)\n",
    "\n",
    "# Seleccionar columnas finales\n",
    "df_ml = df_scaled.select('features', col('is_fraud').alias('label'))\n",
    "\n",
    "print('\\nâœ… Data preparada para ML')\n",
    "print(f'   Features: vector de {len(feature_cols)} dimensiones')\n",
    "print(f'   Registros: {df_ml.count():,}')\n",
    "\n",
    "# Split train/test\n",
    "train_spark, test_spark = df_ml.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f'\\nğŸ“Š Train/Test Split:')\n",
    "print(f'   Train: {train_spark.count():,} ({train_spark.count()/df_ml.count()*100:.1f}%)')\n",
    "print(f'   Test:  {test_spark.count():,} ({test_spark.count()/df_ml.count()*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a Pandas/Numpy para Scikit-learn\n",
    "print('â³ Convirtiendo a formato Scikit-learn...')\n",
    "\n",
    "# Extraer features y labels\n",
    "def spark_to_sklearn(df_spark):\n",
    "    df_pd = df_spark.toPandas()\n",
    "    X = np.array([row.toArray() for row in df_pd['features']])\n",
    "    y = df_pd['label'].values\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = spark_to_sklearn(train_spark)\n",
    "X_test, y_test = spark_to_sklearn(test_spark)\n",
    "\n",
    "print(f'âœ… Datos convertidos')\n",
    "print(f'   X_train: {X_train.shape}')\n",
    "print(f'   X_test:  {X_test.shape}')\n",
    "print(f'   Fraud rate train: {y_train.mean()*100:.2f}%')\n",
    "print(f'   Fraud rate test:  {y_test.mean()*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PASO 8: Entrenamiento de Modelos con Scikit-learn\n",
    "\n",
    "Entrenar y comparar mÃºltiples modelos con MLflow tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelos a entrenar\n",
    "models_to_train = {\n",
    "    'RandomForest': RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=15,\n",
    "        min_samples_split=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'GradientBoosting': GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=7,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'LogisticRegression': LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "print(f'ğŸ¤– Modelos a entrenar: {len(models_to_train)}')\n",
    "for name in models_to_train.keys():\n",
    "    print(f'   â€¢ {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar todos los modelos\n",
    "import time\n",
    "\n",
    "results = []\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('ENTRENAMIENTO DE MODELOS')\n",
    "print('='*70 + '\\n')\n",
    "\n",
    "for model_name, model in models_to_train.items():\n",
    "    \n",
    "    print(f'\\nğŸš€ Entrenando: {model_name}')\n",
    "    print('-' * 70)\n",
    "    \n",
    "    with mlflow.start_run(run_name=f'03-model-{model_name.lower()}') as run:\n",
    "        \n",
    "        mlflow.set_tag('stage', 'training')\n",
    "        mlflow.set_tag('model_type', model_name)\n",
    "        mlflow.set_tag('version', VERSION)\n",
    "        \n",
    "        # Log parÃ¡metros del modelo\n",
    "        params = model.get_params()\n",
    "        mlflow.log_params({k: v for k, v in params.items() if isinstance(v, (int, float, str, bool))})\n",
    "        \n",
    "        # Entrenar\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        print(f'  â±ï¸  Tiempo de entrenamiento: {train_time:.2f}s')\n",
    "        \n",
    "        # Predicciones\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        y_pred_proba_test = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # MÃ©tricas\n",
    "        train_acc = accuracy_score(y_train, y_pred_train)\n",
    "        test_acc = accuracy_score(y_test, y_pred_test)\n",
    "        test_precision = precision_score(y_test, y_pred_test)\n",
    "        test_recall = recall_score(y_test, y_pred_test)\n",
    "        test_f1 = f1_score(y_test, y_pred_test)\n",
    "        test_auc = roc_auc_score(y_test, y_pred_proba_test)\n",
    "        \n",
    "        metrics = {\n",
    "            'train_accuracy': train_acc,\n",
    "            'test_accuracy': test_acc,\n",
    "            'test_precision': test_precision,\n",
    "            'test_recall': test_recall,\n",
    "            'test_f1': test_f1,\n",
    "            'test_auc_roc': test_auc,\n",
    "            'train_time_seconds': train_time\n",
    "        }\n",
    "        \n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Imprimir mÃ©tricas\n",
    "        print(f'\\n  ğŸ“Š MÃ©tricas:')\n",
    "        print(f'     Train Accuracy: {train_acc:.4f}')\n",
    "        print(f'     Test Accuracy:  {test_acc:.4f}')\n",
    "        print(f'     Precision:      {test_precision:.4f}')\n",
    "        print(f'     Recall:         {test_recall:.4f}')\n",
    "        print(f'     F1-Score:       {test_f1:.4f}')\n",
    "        print(f'     AUC-ROC:        {test_auc:.4f}')\n",
    "        \n",
    "        # Guardar modelo\n",
    "        mlflow.sklearn.log_model(\n",
    "            model, \n",
    "            f'{model_name.lower()}-model',\n",
    "            registered_model_name=f'fraud-detection-{model_name.lower()}'\n",
    "        )\n",
    "        \n",
    "        # Guardar resultados\n",
    "        results.append({\n",
    "            'model': model_name,\n",
    "            'run_id': run.info.run_id,\n",
    "            **metrics,\n",
    "            'model_object': model,\n",
    "            'y_pred': y_pred_test,\n",
    "            'y_pred_proba': y_pred_proba_test\n",
    "        })\n",
    "        \n",
    "        print(f'\\n  âœ… Modelo guardado en MLflow')\n",
    "        print(f'     Run ID: {run.info.run_id}')\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('âœ… TODOS LOS MODELOS ENTRENADOS')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PASO 9: ComparaciÃ³n y SelecciÃ³n del Mejor Modelo\n",
    "\n",
    "Visualizar y comparar todos los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame de resultados\n",
    "df_results = pd.DataFrame([{\n",
    "    'Model': r['model'],\n",
    "    'Accuracy': r['test_accuracy'],\n",
    "    'Precision': r['test_precision'],\n",
    "    'Recall': r['test_recall'],\n",
    "    'F1-Score': r['test_f1'],\n",
    "    'AUC-ROC': r['test_auc_roc'],\n",
    "    'Train Time (s)': r['train_time_seconds']\n",
    "} for r in results])\n",
    "\n",
    "print('ğŸ“Š COMPARACIÃ“N DE MODELOS\\n' + '='*70)\n",
    "print(df_results.to_string(index=False))\n",
    "print('='*70)\n",
    "\n",
    "# Mejor modelo por F1-Score (mÃ©trica balanceada para datos desbalanceados)\n",
    "best_model_idx = df_results['F1-Score'].idxmax()\n",
    "best_model_name = df_results.loc[best_model_idx, 'Model']\n",
    "best_model_f1 = df_results.loc[best_model_idx, 'F1-Score']\n",
    "\n",
    "print(f'\\nğŸ† MEJOR MODELO: {best_model_name} (F1={best_model_f1:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VisualizaciÃ³n de comparaciÃ³n\n",
    "with mlflow.start_run(run_name='04-model-comparison') as run:\n",
    "    \n",
    "    mlflow.set_tag('stage', 'comparison')\n",
    "    mlflow.set_tag('best_model', best_model_name)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "    \n",
    "    for idx, metric in enumerate(metrics_to_plot):\n",
    "        row, col = idx // 2, idx % 2\n",
    "        \n",
    "        bars = axes[row, col].bar(df_results['Model'], df_results[metric], \n",
    "                                   color=['gold' if m == best_model_name else 'steelblue' \n",
    "                                         for m in df_results['Model']])\n",
    "        axes[row, col].set_ylabel(metric, fontsize=12)\n",
    "        axes[row, col].set_title(f'{metric} Comparison', fontweight='bold', fontsize=14)\n",
    "        axes[row, col].set_ylim([0, 1])\n",
    "        axes[row, col].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # AÃ±adir valores en las barras\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            axes[row, col].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                               f'{height:.3f}',\n",
    "                               ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold', y=1.00)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/04_model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    mlflow.log_artifact('visualizations/04_model_comparison.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Log best model info\n",
    "    mlflow.log_metrics({\n",
    "        f'best_{k}': v for k, v in df_results.loc[best_model_idx].items()\n",
    "        if isinstance(v, (int, float))\n",
    "    })\n",
    "    \n",
    "    comparison_run_id = run.info.run_id\n",
    "\n",
    "print(f'\\nâœ… ComparaciÃ³n guardada en MLflow (Run ID: {comparison_run_id})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PASO 10: EvaluaciÃ³n Detallada del Mejor Modelo\n",
    "\n",
    "AnÃ¡lisis completo con visualizaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener mejor modelo\n",
    "best_result = [r for r in results if r['model'] == best_model_name][0]\n",
    "best_model = best_result['model_object']\n",
    "y_pred = best_result['y_pred']\n",
    "y_pred_proba = best_result['y_pred_proba']\n",
    "\n",
    "with mlflow.start_run(run_name=f'05-best-model-evaluation-{best_model_name.lower()}') as run:\n",
    "    \n",
    "    mlflow.set_tag('stage', 'final_evaluation')\n",
    "    mlflow.set_tag('model', best_model_name)\n",
    "    mlflow.set_tag('production_ready', 'true')\n",
    "    \n",
    "    print('ğŸ” EVALUACIÃ“N DETALLADA\\n' + '='*70)\n",
    "    \n",
    "    # === Classification Report ===\n",
    "    print('\\nğŸ“‹ Classification Report:\\n')\n",
    "    report = classification_report(y_test, y_pred, target_names=['Normal', 'Fraud'])\n",
    "    print(report)\n",
    "    \n",
    "    # Guardar report\n",
    "    with open('models/classification_report.txt', 'w') as f:\n",
    "        f.write(report)\n",
    "    mlflow.log_artifact('models/classification_report.txt')\n",
    "    \n",
    "    # === Confusion Matrix ===\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Absolute\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "               xticklabels=['Normal', 'Fraud'],\n",
    "               yticklabels=['Normal', 'Fraud'])\n",
    "    axes[0].set_title('Confusion Matrix (Counts)', fontweight='bold')\n",
    "    axes[0].set_ylabel('Actual')\n",
    "    axes[0].set_xlabel('Predicted')\n",
    "    \n",
    "    # Normalized\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Greens', ax=axes[1],\n",
    "               xticklabels=['Normal', 'Fraud'],\n",
    "               yticklabels=['Normal', 'Fraud'])\n",
    "    axes[1].set_title('Confusion Matrix (Normalized)', fontweight='bold')\n",
    "    axes[1].set_ylabel('Actual')\n",
    "    axes[1].set_xlabel('Predicted')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/05_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "    mlflow.log_artifact('visualizations/05_confusion_matrix.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # === ROC & PR Curves ===\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # ROC\n",
    "    axes[0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {roc_auc:.3f})')\n",
    "    axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "    axes[0].set_xlabel('False Positive Rate')\n",
    "    axes[0].set_ylabel('True Positive Rate')\n",
    "    axes[0].set_title('ROC Curve', fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # PR\n",
    "    axes[1].plot(recall_curve, precision_curve, color='green', lw=2, label='PR Curve')\n",
    "    axes[1].set_xlabel('Recall')\n",
    "    axes[1].set_ylabel('Precision')\n",
    "    axes[1].set_title('Precision-Recall Curve', fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/05_roc_pr_curves.png', dpi=150, bbox_inches='tight')\n",
    "    mlflow.log_artifact('visualizations/05_roc_pr_curves.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # === Feature Importance ===\n",
    "    if hasattr(best_model, 'feature_importances_'):\n",
    "        importances = best_model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': [feature_cols[i] for i in indices],\n",
    "            'importance': importances[indices]\n",
    "        })\n",
    "        \n",
    "        sns.barplot(data=importance_df, y='feature', x='importance', palette='viridis')\n",
    "        plt.title(f'Feature Importance - {best_model_name}', fontweight='bold', fontsize=14)\n",
    "        plt.xlabel('Importance')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('visualizations/05_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "        mlflow.log_artifact('visualizations/05_feature_importance.png')\n",
    "        plt.show()\n",
    "        \n",
    "        # Guardar CSV\n",
    "        importance_df.to_csv('models/feature_importance.csv', index=False)\n",
    "        mlflow.log_artifact('models/feature_importance.csv')\n",
    "    \n",
    "    print('\\nâœ… EvaluaciÃ³n completa guardada en MLflow')\n",
    "    print(f'   Run ID: {run.info.run_id}')\n",
    "    \n",
    "    evaluation_run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PASO 11: Guardar Resultados en PostgreSQL\n",
    "\n",
    "Persistir predicciones y mÃ©tricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if engine is not None:\n",
    "    \n",
    "    print('ğŸ’¾ GUARDANDO RESULTADOS EN POSTGRESQL\\n' + '='*70)\n",
    "    \n",
    "    # === Tabla de predicciones ===\n",
    "    df_predictions = df_transactions.iloc[test_spark.toPandas().index].copy()\n",
    "    df_predictions['predicted_fraud'] = y_pred\n",
    "    df_predictions['fraud_probability'] = y_pred_proba\n",
    "    df_predictions['model_name'] = best_model_name\n",
    "    df_predictions['prediction_date'] = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        df_predictions.to_sql(\n",
    "            'fraud_predictions',\n",
    "            engine,\n",
    "            if_exists='replace',\n",
    "            index=False\n",
    "        )\n",
    "        print(f'âœ… {len(df_predictions):,} predicciones guardadas en tabla: fraud_predictions')\n",
    "    except Exception as e:\n",
    "        print(f'âš ï¸  Error: {e}')\n",
    "    \n",
    "    # === Tabla de mÃ©tricas de modelos ===\n",
    "    df_model_metrics = df_results.copy()\n",
    "    df_model_metrics['evaluation_date'] = datetime.now()\n",
    "    df_model_metrics['version'] = VERSION\n",
    "    \n",
    "    try:\n",
    "        df_model_metrics.to_sql(\n",
    "            'model_metrics',\n",
    "            engine,\n",
    "            if_exists='append',\n",
    "            index=False\n",
    "        )\n",
    "        print(f'âœ… MÃ©tricas de {len(df_model_metrics)} modelos guardadas en tabla: model_metrics')\n",
    "    except Exception as e:\n",
    "        print(f'âš ï¸  Error: {e}')\n",
    "    \n",
    "    print('\\nâœ… Todos los resultados guardados en PostgreSQL')\n",
    "    \n",
    "else:\n",
    "    print('âš ï¸  PostgreSQL no disponible - saltando persistencia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PASO 12: Resumen Final y MLOps\n",
    "\n",
    "Resumen del proyecto y prÃ³ximos pasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*70)\n",
    "print('RESUMEN DEL PROYECTO')\n",
    "print('='*70)\n",
    "\n",
    "print(f'\\nğŸ“Š Dataset:')\n",
    "print(f'   Total transacciones: {len(df_transactions):,}')\n",
    "print(f'   Fraudes: {df_transactions[\"is_fraud\"].sum():,} ({df_transactions[\"is_fraud\"].mean()*100:.2f}%)')\n",
    "print(f'   Periodo: {(df_transactions[\"timestamp\"].max() - df_transactions[\"timestamp\"].min()).days} dÃ­as')\n",
    "\n",
    "print(f'\\nğŸ”§ Feature Engineering:')\n",
    "print(f'   Features originales: {len(df_transactions.columns)}')\n",
    "print(f'   Features creadas: {len(new_features)}')\n",
    "print(f'   Features finales para ML: {len(feature_cols)}')\n",
    "\n",
    "print(f'\\nğŸ¤– Modelos Entrenados:')\n",
    "for r in results:\n",
    "    print(f'   â€¢ {r[\"model\"]:20s} - F1: {r[\"test_f1\"]:.4f}, AUC: {r[\"test_auc_roc\"]:.4f}')\n",
    "\n",
    "print(f'\\nğŸ† Mejor Modelo: {best_model_name}')\n",
    "print(f'   Accuracy:  {best_result[\"test_accuracy\"]:.4f}')\n",
    "print(f'   Precision: {best_result[\"test_precision\"]:.4f}')\n",
    "print(f'   Recall:    {best_result[\"test_recall\"]:.4f}')\n",
    "print(f'   F1-Score:  {best_result[\"test_f1\"]:.4f}')\n",
    "print(f'   AUC-ROC:   {best_result[\"test_auc_roc\"]:.4f}')\n",
    "\n",
    "print(f'\\nğŸ’¾ Artefactos Generados:')\n",
    "print(f'   â€¢ Parquet files: {DATA_PATH}/parquet/')\n",
    "print(f'   â€¢ Visualizaciones: visualizations/')\n",
    "print(f'   â€¢ Modelos: MLflow Model Registry')\n",
    "if engine:\n",
    "    print(f'   â€¢ PostgreSQL: fraud_predictions, model_metrics')\n",
    "\n",
    "print(f'\\nğŸ”— MLflow Runs:')\n",
    "print(f'   â€¢ EDA: {eda_run_id[:8]}...')\n",
    "print(f'   â€¢ Feature Engineering: {feature_run_id[:8]}...')\n",
    "print(f'   â€¢ ComparaciÃ³n: {comparison_run_id[:8]}...')\n",
    "print(f'   â€¢ Mejor Modelo: {evaluation_run_id[:8]}...')\n",
    "\n",
    "print(f'\\nğŸŒ Servicios:')\n",
    "print(f'   â€¢ MLflow UI: http://localhost:5000')\n",
    "print(f'   â€¢ PostgreSQL: localhost:5432')\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('âœ… PROYECTO COMPLETADO')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PASO 13: PrÃ³ximos Pasos - MLOps\n",
    "\n",
    "## ImplementaciÃ³n en ProducciÃ³n\n",
    "\n",
    "### 1. AutomatizaciÃ³n con Airflow\n",
    "\n",
    "Crear DAG en `airflow/dags/fraud_detection_pipeline.py`:\n",
    "\n",
    "```python\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'fraud-detection-team',\n",
    "    'start_date': datetime(2024, 1, 1),\n",
    "    'retries': 2,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "}\n",
    "\n",
    "with DAG(\n",
    "    'fraud_detection_pipeline',\n",
    "    default_args=default_args,\n",
    "    schedule_interval='@daily',\n",
    "    catchup=False\n",
    ") as dag:\n",
    "    \n",
    "    ingest = PythonOperator(\n",
    "        task_id='ingest_data',\n",
    "        python_callable=ingest_data_func\n",
    "    )\n",
    "    \n",
    "    transform = PythonOperator(\n",
    "        task_id='transform_data',\n",
    "        python_callable=transform_data_func\n",
    "    )\n",
    "    \n",
    "    predict = PythonOperator(\n",
    "        task_id='predict_fraud',\n",
    "        python_callable=predict_func\n",
    "    )\n",
    "    \n",
    "    ingest >> transform >> predict\n",
    "```\n",
    "\n",
    "### 2. Deployment del Modelo\n",
    "\n",
    "```python\n",
    "# Cargar modelo desde MLflow\n",
    "model_uri = f\"models:/fraud-detection-{best_model_name.lower()}/Production\"\n",
    "loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "# API Flask para predicciones\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    prediction = loaded_model.predict_proba([data['features']])[0][1]\n",
    "    return jsonify({'fraud_probability': float(prediction)})\n",
    "```\n",
    "\n",
    "### 3. Monitoring\n",
    "\n",
    "- MÃ©tricas de modelo en producciÃ³n\n",
    "- DetecciÃ³n de data drift\n",
    "- Alertas de degradaciÃ³n de performance\n",
    "\n",
    "### 4. Retraining\n",
    "\n",
    "- Entrenar automÃ¡ticamente con nuevos datos\n",
    "- A/B testing de modelos\n",
    "- PromociÃ³n automÃ¡tica a producciÃ³n\n",
    "\n",
    "## Â¡Felicidades!\n",
    "\n",
    "Has completado un proyecto end-to-end que integra:\n",
    "âœ… Spark, âœ… MLflow, âœ… Airflow, âœ… Scikit-learn, âœ… SciPy, \n",
    "âœ… PostgreSQL, âœ… Parquet, âœ… Matplotlib/Seaborn\n",
    "\n",
    "Este proyecto demuestra las mejores prÃ¡cticas de MLOps y estÃ¡ listo para producciÃ³n."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
