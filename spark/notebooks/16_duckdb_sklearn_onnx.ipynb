{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16 - DuckDB + Scikit-learn + ONNX: ML Cl√°sico con Export\n",
    "\n",
    "## üéØ Objetivos\n",
    "- Procesamiento de datos con DuckDB\n",
    "- Feature engineering con SQL\n",
    "- Entrenamiento de modelos Scikit-learn\n",
    "- Exportaci√≥n a ONNX para producci√≥n\n",
    "- Inferencia con ONNX Runtime\n",
    "- Comparaci√≥n de performance Python vs ONNX\n",
    "- MLflow tracking completo\n",
    "\n",
    "## üìö Tecnolog√≠as\n",
    "- **DuckDB**: SQL analytics y feature engineering\n",
    "- **Scikit-learn**: Algoritmos de ML cl√°sico\n",
    "- **ONNX**: Formato de intercambio de modelos\n",
    "- **ONNX Runtime**: Inferencia optimizada\n",
    "- **MLflow**: Experiment tracking\n",
    "\n",
    "## ‚≠ê Complejidad: Intermedio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalaci√≥n y Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependencias\n",
    "!pip install duckdb pandas numpy scikit-learn mlflow onnx onnxruntime skl2onnx matplotlib seaborn plotly -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.onnx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "# ONNX\n",
    "import onnx\n",
    "import onnxruntime as rt\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "print(f\"‚úÖ DuckDB version: {duckdb.__version__}\")\n",
    "print(f\"‚úÖ MLflow version: {mlflow.__version__}\")\n",
    "print(f\"‚úÖ ONNX version: {onnx.__version__}\")\n",
    "print(f\"‚úÖ ONNX Runtime version: {rt.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configurar MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"./mlruns\")\n",
    "experiment_name = \"sklearn_onnx_export\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"‚úÖ MLflow configurado\")\n",
    "print(f\"üìä Experimento: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generar Dataset con DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a DuckDB\n",
    "con = duckdb.connect(':memory:')\n",
    "\n",
    "# Generar datos sint√©ticos de fraude bancario\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 10000\n",
    "\n",
    "# Transacciones normales (80%)\n",
    "normal_transactions = int(n_samples * 0.8)\n",
    "fraud_transactions = n_samples - normal_transactions\n",
    "\n",
    "# Features para transacciones normales\n",
    "normal_data = {\n",
    "    'transaction_id': range(1, normal_transactions + 1),\n",
    "    'amount': np.random.lognormal(4, 1.5, normal_transactions),\n",
    "    'transaction_hour': np.random.randint(6, 23, normal_transactions),\n",
    "    'day_of_week': np.random.randint(0, 7, normal_transactions),\n",
    "    'merchant_category': np.random.choice(['retail', 'restaurant', 'gas', 'grocery', 'online'], normal_transactions),\n",
    "    'distance_from_home': np.random.exponential(10, normal_transactions),\n",
    "    'distance_from_last': np.random.exponential(5, normal_transactions),\n",
    "    'ratio_to_median': np.random.normal(1.0, 0.3, normal_transactions),\n",
    "    'used_chip': np.random.choice([0, 1], normal_transactions, p=[0.1, 0.9]),\n",
    "    'used_pin': np.random.choice([0, 1], normal_transactions, p=[0.2, 0.8]),\n",
    "    'online_order': np.random.choice([0, 1], normal_transactions, p=[0.7, 0.3]),\n",
    "    'is_fraud': [0] * normal_transactions\n",
    "}\n",
    "\n",
    "# Features para transacciones fraudulentas (patrones diferentes)\n",
    "fraud_data = {\n",
    "    'transaction_id': range(normal_transactions + 1, n_samples + 1),\n",
    "    'amount': np.random.lognormal(5.5, 1.2, fraud_transactions),  # Montos m√°s altos\n",
    "    'transaction_hour': np.random.randint(0, 6, fraud_transactions),  # Horas inusuales\n",
    "    'day_of_week': np.random.randint(0, 7, fraud_transactions),\n",
    "    'merchant_category': np.random.choice(['retail', 'online', 'gas'], fraud_transactions, p=[0.2, 0.6, 0.2]),\n",
    "    'distance_from_home': np.random.exponential(50, fraud_transactions),  # Lejos de casa\n",
    "    'distance_from_last': np.random.exponential(30, fraud_transactions),  # Lejos de √∫ltima transacci√≥n\n",
    "    'ratio_to_median': np.random.normal(2.5, 0.5, fraud_transactions),  # Ratio alto\n",
    "    'used_chip': np.random.choice([0, 1], fraud_transactions, p=[0.8, 0.2]),  # Sin chip\n",
    "    'used_pin': np.random.choice([0, 1], fraud_transactions, p=[0.9, 0.1]),  # Sin PIN\n",
    "    'online_order': np.random.choice([0, 1], fraud_transactions, p=[0.2, 0.8]),  # M√°s online\n",
    "    'is_fraud': [1] * fraud_transactions\n",
    "}\n",
    "\n",
    "# Combinar\n",
    "df_normal = pd.DataFrame(normal_data)\n",
    "df_fraud = pd.DataFrame(fraud_data)\n",
    "df = pd.concat([df_normal, df_fraud], ignore_index=True)\n",
    "\n",
    "# Shuffle\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"üìä Dataset generado: {len(df):,} transacciones\")\n",
    "print(f\"üìä Fraudes: {df['is_fraud'].sum():,} ({df['is_fraud'].mean()*100:.1f}%)\")\n",
    "print(f\"\\nüìä Primeras filas:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering con DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis exploratorio con DuckDB\n",
    "fraud_stats = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        is_fraud,\n",
    "        COUNT(*) as count,\n",
    "        ROUND(AVG(amount), 2) as avg_amount,\n",
    "        ROUND(AVG(distance_from_home), 2) as avg_distance_home,\n",
    "        ROUND(AVG(transaction_hour), 2) as avg_hour,\n",
    "        ROUND(AVG(used_chip), 2) as chip_usage,\n",
    "        ROUND(AVG(online_order), 2) as online_rate\n",
    "    FROM df\n",
    "    GROUP BY is_fraud\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"üìä Estad√≠sticas por clase:\")\n",
    "print(fraud_stats)\n",
    "\n",
    "# Feature engineering con SQL\n",
    "df_engineered = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        transaction_id,\n",
    "        amount,\n",
    "        LN(amount + 1) as log_amount,\n",
    "        transaction_hour,\n",
    "        CASE \n",
    "            WHEN transaction_hour BETWEEN 6 AND 22 THEN 1\n",
    "            ELSE 0\n",
    "        END as is_business_hours,\n",
    "        day_of_week,\n",
    "        CASE \n",
    "            WHEN day_of_week IN (5, 6) THEN 1\n",
    "            ELSE 0\n",
    "        END as is_weekend,\n",
    "        merchant_category,\n",
    "        distance_from_home,\n",
    "        LN(distance_from_home + 1) as log_distance_home,\n",
    "        distance_from_last,\n",
    "        LN(distance_from_last + 1) as log_distance_last,\n",
    "        ratio_to_median,\n",
    "        used_chip,\n",
    "        used_pin,\n",
    "        online_order,\n",
    "        amount * ratio_to_median as weighted_amount,\n",
    "        CASE \n",
    "            WHEN used_chip = 0 AND used_pin = 0 THEN 1\n",
    "            ELSE 0\n",
    "        END as no_security,\n",
    "        is_fraud\n",
    "    FROM df\n",
    "\"\"\").df()\n",
    "\n",
    "print(f\"\\n‚úÖ Feature engineering completado\")\n",
    "print(f\"üìä Features creadas: {df_engineered.shape[1]}\")\n",
    "print(f\"\\nüìä Nuevas features:\")\n",
    "print(df_engineered.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preparar Datos para ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding para merchant_category\n",
    "df_encoded = pd.get_dummies(df_engineered, columns=['merchant_category'], prefix='merchant')\n",
    "\n",
    "# Separar features y target\n",
    "X = df_encoded.drop(['transaction_id', 'is_fraud'], axis=1)\n",
    "y = df_encoded['is_fraud']\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Normalizar\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"üìä Train set: {X_train.shape}\")\n",
    "print(f\"üìä Test set: {X_test.shape}\")\n",
    "print(f\"üìä Features: {X_train.shape[1]}\")\n",
    "print(f\"\\nüìä Feature names:\")\n",
    "print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Entrenar M√∫ltiples Modelos con MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_export_model(model, model_name, X_train, X_test, y_train, y_test, feature_names):\n",
    "    \"\"\"\n",
    "    Entrena modelo, exporta a ONNX y trackea con MLflow\n",
    "    \"\"\"\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"{model_name}_onnx_export\"):\n",
    "        \n",
    "        # Log par√°metros del modelo\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        mlflow.log_param(\"n_features\", X_train.shape[1])\n",
    "        mlflow.log_param(\"n_train_samples\", len(X_train))\n",
    "        mlflow.log_param(\"n_test_samples\", len(X_test))\n",
    "        \n",
    "        if hasattr(model, 'get_params'):\n",
    "            for param, value in model.get_params().items():\n",
    "                mlflow.log_param(f\"model_{param}\", value)\n",
    "        \n",
    "        # Entrenar\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Entrenando: {model_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        # Predicciones\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        # M√©tricas\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        mlflow.log_metric(\"train_time_seconds\", train_time)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        \n",
    "        if y_pred_proba is not None:\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            mlflow.log_metric(\"auc_roc\", auc)\n",
    "        else:\n",
    "            auc = None\n",
    "        \n",
    "        # Guardar modelo scikit-learn\n",
    "        mlflow.sklearn.log_model(model, \"sklearn_model\")\n",
    "        \n",
    "        # Exportar a ONNX\n",
    "        print(f\"\\nüîÑ Exportando a ONNX...\")\n",
    "        \n",
    "        # Definir tipos de entrada\n",
    "        initial_type = [('float_input', FloatTensorType([None, X_train.shape[1]]))]\n",
    "        \n",
    "        # Convertir a ONNX\n",
    "        onnx_model = convert_sklearn(model, initial_types=initial_type)\n",
    "        \n",
    "        # Guardar ONNX\n",
    "        onnx_filename = f\"{model_name.lower()}_model.onnx\"\n",
    "        onnx.save_model(onnx_model, onnx_filename)\n",
    "        \n",
    "        # Log ONNX model en MLflow\n",
    "        mlflow.onnx.log_model(onnx_model, \"onnx_model\")\n",
    "        mlflow.log_artifact(onnx_filename)\n",
    "        \n",
    "        print(f\"‚úÖ Modelo ONNX guardado: {onnx_filename}\")\n",
    "        \n",
    "        # Test ONNX inference\n",
    "        print(f\"\\nüß™ Testeando inferencia ONNX...\")\n",
    "        \n",
    "        sess = rt.InferenceSession(onnx_filename)\n",
    "        input_name = sess.get_inputs()[0].name\n",
    "        label_name = sess.get_outputs()[0].name\n",
    "        \n",
    "        # Inferencia con ONNX\n",
    "        start_time = time.time()\n",
    "        onnx_pred = sess.run([label_name], {input_name: X_test.astype(np.float32)})[0]\n",
    "        onnx_inference_time = time.time() - start_time\n",
    "        \n",
    "        # Inferencia con Sklearn (para comparar)\n",
    "        start_time = time.time()\n",
    "        sklearn_pred = model.predict(X_test)\n",
    "        sklearn_inference_time = time.time() - start_time\n",
    "        \n",
    "        # Comparar resultados\n",
    "        predictions_match = np.array_equal(onnx_pred, sklearn_pred)\n",
    "        \n",
    "        mlflow.log_metric(\"onnx_inference_time\", onnx_inference_time)\n",
    "        mlflow.log_metric(\"sklearn_inference_time\", sklearn_inference_time)\n",
    "        mlflow.log_metric(\"onnx_speedup\", sklearn_inference_time / onnx_inference_time)\n",
    "        mlflow.log_metric(\"predictions_match\", int(predictions_match))\n",
    "        \n",
    "        # Visualizaciones\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix - {model_name}')\n",
    "        plt.ylabel('Real')\n",
    "        plt.xlabel('Predicci√≥n')\n",
    "        plt.savefig(f'{model_name}_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "        mlflow.log_artifact(f'{model_name}_confusion_matrix.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # ROC Curve si es posible\n",
    "        if y_pred_proba is not None:\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(fpr, tpr, linewidth=2, label=f'AUC = {auc:.4f}')\n",
    "            plt.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title(f'ROC Curve - {model_name}')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.savefig(f'{model_name}_roc_curve.png', dpi=150, bbox_inches='tight')\n",
    "            mlflow.log_artifact(f'{model_name}_roc_curve.png')\n",
    "            plt.close()\n",
    "        \n",
    "        # Feature importance si est√° disponible\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importances = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.barh(importances['feature'][:15], importances['importance'][:15])\n",
    "            plt.xlabel('Importance')\n",
    "            plt.title(f'Top 15 Feature Importance - {model_name}')\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{model_name}_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "            mlflow.log_artifact(f'{model_name}_feature_importance.png')\n",
    "            plt.close()\n",
    "            \n",
    "            importances.to_csv(f'{model_name}_feature_importance.csv', index=False)\n",
    "            mlflow.log_artifact(f'{model_name}_feature_importance.csv')\n",
    "        \n",
    "        # Resultados\n",
    "        print(f\"\\nüìä M√©tricas:\")\n",
    "        print(f\"   Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"   Precision: {precision:.4f}\")\n",
    "        print(f\"   Recall: {recall:.4f}\")\n",
    "        print(f\"   F1-Score: {f1:.4f}\")\n",
    "        if auc:\n",
    "            print(f\"   AUC-ROC: {auc:.4f}\")\n",
    "        \n",
    "        print(f\"\\n‚ö° Performance:\")\n",
    "        print(f\"   Training time: {train_time:.4f}s\")\n",
    "        print(f\"   Sklearn inference: {sklearn_inference_time:.4f}s\")\n",
    "        print(f\"   ONNX inference: {onnx_inference_time:.4f}s\")\n",
    "        print(f\"   Speedup: {sklearn_inference_time/onnx_inference_time:.2f}x\")\n",
    "        print(f\"   Predictions match: {predictions_match}\")\n",
    "        \n",
    "        return {\n",
    "            'model_name': model_name,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'auc_roc': auc if auc else 0,\n",
    "            'sklearn_time': sklearn_inference_time,\n",
    "            'onnx_time': onnx_inference_time,\n",
    "            'speedup': sklearn_inference_time / onnx_inference_time\n",
    "        }\n",
    "\n",
    "# Entrenar modelos\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
    "    'DecisionTree': DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "for model_name, model in models.items():\n",
    "    result = train_and_export_model(\n",
    "        model, \n",
    "        model_name, \n",
    "        X_train_scaled, \n",
    "        X_test_scaled, \n",
    "        y_train, \n",
    "        y_test,\n",
    "        X.columns.tolist()\n",
    "    )\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparaci√≥n de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame de resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"üìä COMPARACI√ìN DE MODELOS\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Visualizar comparaci√≥n\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# M√©tricas de clasificaci√≥n\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "for idx, (ax, metric) in enumerate(zip(axes.flat, metrics)):\n",
    "    results_df.plot(x='model_name', y=metric, kind='bar', ax=ax, legend=False, color='skyblue')\n",
    "    ax.set_title(f'{metric.replace(\"_\", \" \").title()}')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('models_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Comparaci√≥n de tiempos\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, results_df['sklearn_time'] * 1000, width, label='Sklearn', alpha=0.8)\n",
    "ax.bar(x + width/2, results_df['onnx_time'] * 1000, width, label='ONNX', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Modelo')\n",
    "ax.set_ylabel('Tiempo de Inferencia (ms)')\n",
    "ax.set_title('Comparaci√≥n de Tiempo de Inferencia: Sklearn vs ONNX')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(results_df['model_name'], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('inference_time_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüèÜ Mejor modelo por m√©trica:\")\n",
    "print(f\"   Accuracy: {results_df.loc[results_df['accuracy'].idxmax(), 'model_name']}\")\n",
    "print(f\"   F1-Score: {results_df.loc[results_df['f1_score'].idxmax(), 'model_name']}\")\n",
    "print(f\"   AUC-ROC: {results_df.loc[results_df['auc_roc'].idxmax(), 'model_name']}\")\n",
    "print(f\"   Speedup ONNX: {results_df.loc[results_df['speedup'].idxmax(), 'model_name']} ({results_df['speedup'].max():.2f}x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Demo de Inferencia ONNX en Producci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar el mejor modelo (por F1-Score)\n",
    "best_model_name = results_df.loc[results_df['f1_score'].idxmax(), 'model_name']\n",
    "onnx_file = f\"{best_model_name.lower()}_model.onnx\"\n",
    "\n",
    "print(f\"üèÜ Mejor modelo: {best_model_name}\")\n",
    "print(f\"üì¶ Archivo ONNX: {onnx_file}\")\n",
    "\n",
    "# Cargar modelo ONNX\n",
    "sess = rt.InferenceSession(onnx_file)\n",
    "\n",
    "# Informaci√≥n del modelo\n",
    "print(f\"\\nüìä Informaci√≥n del modelo ONNX:\")\n",
    "print(f\"   Inputs: {[inp.name for inp in sess.get_inputs()]}\")\n",
    "print(f\"   Outputs: {[out.name for out in sess.get_outputs()]}\")\n",
    "print(f\"   Input shape: {sess.get_inputs()[0].shape}\")\n",
    "print(f\"   Input type: {sess.get_inputs()[0].type}\")\n",
    "\n",
    "# Simulaci√≥n de inferencia en producci√≥n\n",
    "def predict_fraud_onnx(transaction_data):\n",
    "    \"\"\"\n",
    "    Predice fraude usando modelo ONNX\n",
    "    \"\"\"\n",
    "    input_name = sess.get_inputs()[0].name\n",
    "    label_name = sess.get_outputs()[0].name\n",
    "    \n",
    "    # Asegurar formato correcto\n",
    "    if len(transaction_data.shape) == 1:\n",
    "        transaction_data = transaction_data.reshape(1, -1)\n",
    "    \n",
    "    # Inferencia\n",
    "    pred = sess.run([label_name], {input_name: transaction_data.astype(np.float32)})[0]\n",
    "    \n",
    "    return pred\n",
    "\n",
    "# Test con ejemplos\n",
    "print(f\"\\nüß™ Testing predicciones en producci√≥n...\\n\")\n",
    "\n",
    "test_samples = X_test_scaled[:10]\n",
    "real_labels = y_test.values[:10]\n",
    "\n",
    "for i in range(len(test_samples)):\n",
    "    prediction = predict_fraud_onnx(test_samples[i])\n",
    "    real = real_labels[i]\n",
    "    status = \"‚úÖ\" if prediction[0] == real else \"‚ùå\"\n",
    "    \n",
    "    print(f\"Transacci√≥n {i+1}: Predicci√≥n={prediction[0]}, Real={real} {status}\")\n",
    "\n",
    "# Benchmark de inferencia\n",
    "print(f\"\\n‚ö° Benchmark de inferencia (1000 predicciones):\")\n",
    "\n",
    "n_iterations = 1000\n",
    "test_batch = X_test_scaled[:100]\n",
    "\n",
    "start = time.time()\n",
    "for _ in range(n_iterations):\n",
    "    _ = predict_fraud_onnx(test_batch)\n",
    "total_time = time.time() - start\n",
    "\n",
    "print(f\"   Total: {total_time:.4f}s\")\n",
    "print(f\"   Promedio: {total_time/n_iterations*1000:.4f}ms por batch\")\n",
    "print(f\"   Throughput: {n_iterations/total_time:.2f} batches/segundo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Resumen y Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üí° BEST PRACTICES: SKLEARN + ONNX\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ FEATURE ENGINEERING con DuckDB:\")\n",
    "print(\"   ‚úÖ Usa SQL para transformaciones complejas\")\n",
    "print(\"   ‚úÖ Aprovecha window functions para features temporales\")\n",
    "print(\"   ‚úÖ Crea features agregadas eficientemente\")\n",
    "print(\"   ‚úÖ One-hot encoding para categor√≠as\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ EXPORTACI√ìN ONNX:\")\n",
    "print(\"   ‚úÖ Valida que predicciones coincidan con sklearn\")\n",
    "print(\"   ‚úÖ Define tipos de entrada correctamente\")\n",
    "print(\"   ‚úÖ Prueba con datos reales antes de producci√≥n\")\n",
    "print(\"   ‚úÖ Versiona modelos ONNX junto con c√≥digo\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ PERFORMANCE:\")\n",
    "print(\"   ‚úÖ ONNX t√≠picamente 2-10x m√°s r√°pido\")\n",
    "print(\"   ‚úÖ Usa batch inference cuando sea posible\")\n",
    "print(\"   ‚úÖ Considera ONNX Runtime GPU para vol√∫menes grandes\")\n",
    "print(\"   ‚úÖ Cachea sesiones de inferencia\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ DEPLOYMENT:\")\n",
    "print(\"   ‚úÖ ONNX es portable entre lenguajes/plataformas\")\n",
    "print(\"   ‚úÖ No requiere Python/sklearn en producci√≥n\")\n",
    "print(\"   ‚úÖ Ideal para edge devices y microservicios\")\n",
    "print(\"   ‚úÖ Soporta C++, C#, Java, JavaScript, etc.\")\n",
    "\n",
    "print(\"\\n5Ô∏è‚É£ MLFLOW TRACKING:\")\n",
    "print(\"   ‚úÖ Trackea modelo sklearn y ONNX\")\n",
    "print(\"   ‚úÖ Compara tiempos de inferencia\")\n",
    "print(\"   ‚úÖ Guarda artefactos (features, visualizaciones)\")\n",
    "print(\"   ‚úÖ Versiona todo el pipeline\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Estad√≠sticas finales\n",
    "print(\"\\nüìä RESUMEN FINAL:\")\n",
    "print(f\"   Dataset: {len(df):,} transacciones\")\n",
    "print(f\"   Features: {X_train.shape[1]}\")\n",
    "print(f\"   Modelos entrenados: {len(results)}\")\n",
    "print(f\"   Modelos ONNX exportados: {len(results)}\")\n",
    "print(f\"   Promedio speedup ONNX: {results_df['speedup'].mean():.2f}x\")\n",
    "print(f\"   Mejor F1-Score: {results_df['f1_score'].max():.4f} ({best_model_name})\")\n",
    "\n",
    "con.close()\n",
    "print(\"\\n‚úÖ Conexi√≥n DuckDB cerrada\")\n",
    "print(\"\\nüíª Ver resultados: mlflow ui --port 5000\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
