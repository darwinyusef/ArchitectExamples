{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18 - DuckDB + RNN: Series Temporales con Redes Neuronales Recurrentes\n",
    "\n",
    "## üéØ Objetivos\n",
    "- Procesamiento de series temporales con DuckDB\n",
    "- Implementar m√∫ltiples arquitecturas RNN (LSTM, GRU, Bidirectional)\n",
    "- Attention mechanisms para series temporales\n",
    "- Comparaci√≥n de arquitecturas\n",
    "- Multi-step forecasting\n",
    "- Export a ONNX para producci√≥n\n",
    "- MLflow tracking completo\n",
    "\n",
    "## üìö Tecnolog√≠as\n",
    "- **DuckDB**: Procesamiento de datos\n",
    "- **PyTorch**: Framework de deep learning\n",
    "- **LSTM/GRU**: Arquitecturas recurrentes\n",
    "- **Attention**: Mecanismos de atenci√≥n\n",
    "- **MLflow**: Experiment tracking\n",
    "- **ONNX**: Model export\n",
    "\n",
    "## ‚≠ê Complejidad: Avanzado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalaci√≥n y Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependencias\n",
    "!pip install duckdb pandas numpy torch torchvision mlflow onnx onnxruntime matplotlib seaborn plotly scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import mlflow.onnx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ONNX\n",
    "import onnx\n",
    "import onnxruntime as rt\n",
    "\n",
    "# Config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ DuckDB version: {duckdb.__version__}\")\n",
    "print(f\"‚úÖ MLflow version: {mlflow.__version__}\")\n",
    "print(f\"‚úÖ ONNX version: {onnx.__version__}\")\n",
    "print(f\"‚úÖ Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configurar MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"./mlruns\")\n",
    "experiment_name = \"rnn_timeseries_forecasting\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"‚úÖ MLflow configurado\")\n",
    "print(f\"üìä Experimento: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generar Datos de Serie Temporal con DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a DuckDB\n",
    "con = duckdb.connect(':memory:')\n",
    "\n",
    "# Generar serie temporal compleja\n",
    "np.random.seed(42)\n",
    "\n",
    "# 3 a√±os de datos por hora\n",
    "n_hours = 24 * 365 * 3\n",
    "start_date = datetime(2021, 1, 1)\n",
    "dates = pd.date_range(start=start_date, periods=n_hours, freq='H')\n",
    "\n",
    "# Componentes de la serie\n",
    "# 1. Tendencia\n",
    "trend = np.linspace(1000, 1500, n_hours)\n",
    "\n",
    "# 2. Estacionalidad anual\n",
    "annual_season = 150 * np.sin(2 * np.pi * np.arange(n_hours) / (24 * 365))\n",
    "\n",
    "# 3. Estacionalidad semanal\n",
    "weekly_season = 80 * np.sin(2 * np.pi * np.arange(n_hours) / (24 * 7))\n",
    "\n",
    "# 4. Estacionalidad diaria\n",
    "daily_season = 50 * np.sin(2 * np.pi * np.arange(n_hours) / 24)\n",
    "\n",
    "# 5. Ruido\n",
    "noise = np.random.normal(0, 30, n_hours)\n",
    "\n",
    "# 6. Eventos especiales (picos de demanda)\n",
    "special_events = np.zeros(n_hours)\n",
    "# Picos aleatorios\n",
    "event_indices = np.random.choice(n_hours, size=50, replace=False)\n",
    "for idx in event_indices:\n",
    "    duration = np.random.randint(1, 24)\n",
    "    magnitude = np.random.uniform(200, 400)\n",
    "    special_events[idx:min(idx+duration, n_hours)] = magnitude\n",
    "\n",
    "# Serie final\n",
    "energy_demand = trend + annual_season + weekly_season + daily_season + noise + special_events\n",
    "energy_demand = np.maximum(energy_demand, 0)\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'timestamp': dates,\n",
    "    'energy_demand': energy_demand,\n",
    "    'hour': dates.hour,\n",
    "    'day_of_week': dates.dayofweek,\n",
    "    'day_of_month': dates.day,\n",
    "    'month': dates.month,\n",
    "    'year': dates.year,\n",
    "    'is_weekend': dates.dayofweek.isin([5, 6]).astype(int),\n",
    "    'is_business_hours': ((dates.hour >= 8) & (dates.hour <= 18)).astype(int)\n",
    "})\n",
    "\n",
    "print(f\"üìä Serie temporal generada\")\n",
    "print(f\"   Per√≠odo: {df['timestamp'].min()} a {df['timestamp'].max()}\")\n",
    "print(f\"   Total registros: {len(df):,}\")\n",
    "print(f\"   Frecuencia: Horaria\")\n",
    "print(f\"\\nüìä Estad√≠sticas:\")\n",
    "print(df['energy_demand'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. An√°lisis Exploratorio con DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas por hora del d√≠a\n",
    "hourly_stats = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        hour,\n",
    "        COUNT(*) as observations,\n",
    "        ROUND(AVG(energy_demand), 2) as avg_demand,\n",
    "        ROUND(STDDEV(energy_demand), 2) as std_demand,\n",
    "        ROUND(MIN(energy_demand), 2) as min_demand,\n",
    "        ROUND(MAX(energy_demand), 2) as max_demand\n",
    "    FROM df\n",
    "    GROUP BY hour\n",
    "    ORDER BY hour\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"üìä Patr√≥n por hora del d√≠a:\")\n",
    "print(hourly_stats)\n",
    "\n",
    "# Comparaci√≥n fines de semana vs d√≠as laborables\n",
    "weekend_comparison = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        CASE WHEN is_weekend = 1 THEN 'Weekend' ELSE 'Weekday' END as day_type,\n",
    "        COUNT(*) as observations,\n",
    "        ROUND(AVG(energy_demand), 2) as avg_demand,\n",
    "        ROUND(STDDEV(energy_demand), 2) as std_demand\n",
    "    FROM df\n",
    "    GROUP BY is_weekend\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\nüìä Weekend vs Weekday:\")\n",
    "print(weekend_comparison)\n",
    "\n",
    "# Tendencia mensual\n",
    "monthly_trend = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        year,\n",
    "        month,\n",
    "        ROUND(AVG(energy_demand), 2) as avg_demand,\n",
    "        COUNT(*) as hours\n",
    "    FROM df\n",
    "    GROUP BY year, month\n",
    "    ORDER BY year, month\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\nüìä Tendencia mensual (primeros 12 meses):\")\n",
    "print(monthly_trend.head(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizaci√≥n de la Serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n interactiva\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=1,\n",
    "    subplot_titles=('Serie Temporal Completa', '√öltimo Mes', 'Patr√≥n Semanal Promedio'),\n",
    "    vertical_spacing=0.1\n",
    ")\n",
    "\n",
    "# Serie completa\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df['timestamp'], y=df['energy_demand'], \n",
    "               mode='lines', name='Demanda de Energ√≠a', line=dict(width=1)),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# √öltimo mes\n",
    "last_month = df.tail(24*30)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=last_month['timestamp'], y=last_month['energy_demand'],\n",
    "               mode='lines', name='√öltimo Mes', line=dict(color='red', width=1)),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Patr√≥n semanal\n",
    "weekly_pattern = df.groupby(['day_of_week', 'hour'])['energy_demand'].mean().reset_index()\n",
    "for day in range(7):\n",
    "    day_data = weekly_pattern[weekly_pattern['day_of_week'] == day]\n",
    "    day_names = ['Lun', 'Mar', 'Mie', 'Jue', 'Vie', 'Sab', 'Dom']\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=day_data['hour'], y=day_data['energy_demand'],\n",
    "                   mode='lines', name=day_names[day]),\n",
    "        row=3, col=1\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=900, showlegend=True, title_text=\"An√°lisis de Demanda de Energ√≠a\")\n",
    "fig.update_xaxes(title_text=\"Hora\", row=3, col=1)\n",
    "fig.update_yaxes(title_text=\"Demanda (MW)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Demanda (MW)\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Demanda (MW)\", row=3, col=1)\n",
    "fig.show()\n",
    "\n",
    "print(\"‚úÖ Visualizaciones generadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preparar Datos para RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length, pred_length=1):\n",
    "    \"\"\"\n",
    "    Crea secuencias para entrenamiento de RNN\n",
    "    \n",
    "    Args:\n",
    "        data: Serie temporal\n",
    "        seq_length: Longitud de la secuencia de entrada\n",
    "        pred_length: N√∫mero de pasos a predecir\n",
    "    \n",
    "    Returns:\n",
    "        X, y: Secuencias de entrada y salida\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(len(data) - seq_length - pred_length + 1):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        if pred_length == 1:\n",
    "            y.append(data[i + seq_length])\n",
    "        else:\n",
    "            y.append(data[i + seq_length:i + seq_length + pred_length])\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Normalizar datos\n",
    "scaler = MinMaxScaler()\n",
    "energy_scaled = scaler.fit_transform(df[['energy_demand']]).flatten()\n",
    "\n",
    "# Par√°metros\n",
    "seq_length = 24 * 7  # 1 semana de datos (24 horas * 7 d√≠as)\n",
    "pred_length = 24  # Predecir pr√≥ximas 24 horas\n",
    "\n",
    "# Crear secuencias\n",
    "X, y = create_sequences(energy_scaled, seq_length, pred_length)\n",
    "\n",
    "print(f\"üìä Secuencias creadas:\")\n",
    "print(f\"   Longitud de secuencia de entrada: {seq_length} horas (1 semana)\")\n",
    "print(f\"   Longitud de predicci√≥n: {pred_length} horas (1 d√≠a)\")\n",
    "print(f\"   Total secuencias: {len(X):,}\")\n",
    "print(f\"   Shape X: {X.shape}\")\n",
    "print(f\"   Shape y: {y.shape}\")\n",
    "\n",
    "# Split train/val/test\n",
    "train_size = int(0.7 * len(X))\n",
    "val_size = int(0.15 * len(X))\n",
    "\n",
    "X_train = X[:train_size]\n",
    "y_train = y[:train_size]\n",
    "\n",
    "X_val = X[train_size:train_size + val_size]\n",
    "y_val = y[train_size:train_size + val_size]\n",
    "\n",
    "X_test = X[train_size + val_size:]\n",
    "y_test = y[train_size + val_size:]\n",
    "\n",
    "# Convertir a tensores\n",
    "X_train_tensor = torch.FloatTensor(X_train).unsqueeze(-1).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train).to(device)\n",
    "\n",
    "X_val_tensor = torch.FloatTensor(X_val).unsqueeze(-1).to(device)\n",
    "y_val_tensor = torch.FloatTensor(y_val).to(device)\n",
    "\n",
    "X_test_tensor = torch.FloatTensor(X_test).unsqueeze(-1).to(device)\n",
    "y_test_tensor = torch.FloatTensor(y_test).to(device)\n",
    "\n",
    "print(f\"\\nüìä Splits:\")\n",
    "print(f\"   Train: {len(X_train):,} secuencias\")\n",
    "print(f\"   Val: {len(X_val):,} secuencias\")\n",
    "print(f\"   Test: {len(X_test):,} secuencias\")\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "print(f\"\\n‚úÖ DataLoaders creados (batch_size={batch_size})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Arquitecturas RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LSTM Simple\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, output_size=24, dropout=0.2):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, input_size)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # Tomar √∫ltima salida\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        out = self.fc(last_output)\n",
    "        return out\n",
    "\n",
    "# 2. GRU\n",
    "class SimpleGRU(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, output_size=24, dropout=0.2):\n",
    "        super(SimpleGRU, self).__init__()\n",
    "        \n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        gru_out, _ = self.gru(x)\n",
    "        last_output = gru_out[:, -1, :]\n",
    "        out = self.fc(last_output)\n",
    "        return out\n",
    "\n",
    "# 3. Bidirectional LSTM\n",
    "class BidirectionalLSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, output_size=24, dropout=0.2):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # *2 porque es bidirectional\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        out = self.fc(last_output)\n",
    "        return out\n",
    "\n",
    "# 4. LSTM con Attention\n",
    "class LSTMWithAttention(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, output_size=24, dropout=0.2):\n",
    "        super(LSTMWithAttention, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Attention\n",
    "        self.attention = nn.Linear(hidden_size, 1)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # LSTM output\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # lstm_out: (batch, seq_len, hidden_size)\n",
    "        \n",
    "        # Attention weights\n",
    "        attention_weights = torch.softmax(self.attention(lstm_out), dim=1)\n",
    "        # attention_weights: (batch, seq_len, 1)\n",
    "        \n",
    "        # Context vector (weighted sum)\n",
    "        context = torch.sum(attention_weights * lstm_out, dim=1)\n",
    "        # context: (batch, hidden_size)\n",
    "        \n",
    "        out = self.fc(context)\n",
    "        return out\n",
    "\n",
    "print(\"‚úÖ Arquitecturas RNN definidas:\")\n",
    "print(\"   1. SimpleLSTM\")\n",
    "print(\"   2. SimpleGRU\")\n",
    "print(\"   3. BidirectionalLSTM\")\n",
    "print(\"   4. LSTMWithAttention\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Funci√≥n de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn_model(model, model_name, train_loader, val_loader, X_test, y_test, epochs=50, lr=0.001):\n",
    "    \"\"\"\n",
    "    Entrena modelo RNN y trackea con MLflow\n",
    "    \"\"\"\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"{model_name}_forecast\"):\n",
    "        \n",
    "        # Log par√°metros\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        mlflow.log_param(\"seq_length\", seq_length)\n",
    "        mlflow.log_param(\"pred_length\", pred_length)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"learning_rate\", lr)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        \n",
    "        # Optimizer y loss\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        # Training\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Entrenando: {model_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        patience = 10\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Train\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for batch_X, batch_y in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            train_loss /= len(train_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for batch_X, batch_y in val_loader:\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    val_loss += loss.item()\n",
    "            \n",
    "            val_loss /= len(val_loader)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                # Guardar mejor modelo\n",
    "                torch.save(model.state_dict(), f'{model_name}_best.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}] - Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "            \n",
    "            # Log m√©tricas\n",
    "            mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "            mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping en epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        # Cargar mejor modelo\n",
    "        model.load_state_dict(torch.load(f'{model_name}_best.pth'))\n",
    "        \n",
    "        # Predicciones en test\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = model(X_test).cpu().numpy()\n",
    "        \n",
    "        y_test_np = y_test.cpu().numpy()\n",
    "        \n",
    "        # Desnormalizar\n",
    "        predictions_rescaled = scaler.inverse_transform(predictions.reshape(-1, 1)).reshape(predictions.shape)\n",
    "        y_test_rescaled = scaler.inverse_transform(y_test_np.reshape(-1, 1)).reshape(y_test_np.shape)\n",
    "        \n",
    "        # M√©tricas\n",
    "        mae = mean_absolute_error(y_test_rescaled.flatten(), predictions_rescaled.flatten())\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_rescaled.flatten(), predictions_rescaled.flatten()))\n",
    "        r2 = r2_score(y_test_rescaled.flatten(), predictions_rescaled.flatten())\n",
    "        mape = np.mean(np.abs((y_test_rescaled.flatten() - predictions_rescaled.flatten()) / y_test_rescaled.flatten())) * 100\n",
    "        \n",
    "        mlflow.log_metric(\"test_mae\", mae)\n",
    "        mlflow.log_metric(\"test_rmse\", rmse)\n",
    "        mlflow.log_metric(\"test_r2\", r2)\n",
    "        mlflow.log_metric(\"test_mape\", mape)\n",
    "        mlflow.log_metric(\"best_val_loss\", best_val_loss)\n",
    "        \n",
    "        # Guardar modelo PyTorch\n",
    "        mlflow.pytorch.log_model(model, \"pytorch_model\")\n",
    "        \n",
    "        # Visualizaciones\n",
    "        # Training curves\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(train_losses, label='Train Loss')\n",
    "        plt.plot(val_losses, label='Val Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(f'{model_name} - Training Curves')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig(f'{model_name}_training_curves.png', dpi=150, bbox_inches='tight')\n",
    "        mlflow.log_artifact(f'{model_name}_training_curves.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Predictions plot (primeras 5 secuencias)\n",
    "        fig, axes = plt.subplots(5, 1, figsize=(14, 12))\n",
    "        for i in range(5):\n",
    "            axes[i].plot(y_test_rescaled[i], label='Real', linewidth=2)\n",
    "            axes[i].plot(predictions_rescaled[i], label='Predicci√≥n', linestyle='--', linewidth=2)\n",
    "            axes[i].set_title(f'Secuencia {i+1}')\n",
    "            axes[i].set_ylabel('Demanda (MW)')\n",
    "            axes[i].legend()\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[-1].set_xlabel('Hora')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{model_name}_predictions.png', dpi=150, bbox_inches='tight')\n",
    "        mlflow.log_artifact(f'{model_name}_predictions.png')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"\\n‚úÖ {model_name} completado\")\n",
    "        print(f\"   MAE: {mae:.2f} MW\")\n",
    "        print(f\"   RMSE: {rmse:.2f} MW\")\n",
    "        print(f\"   R¬≤: {r2:.4f}\")\n",
    "        print(f\"   MAPE: {mape:.2f}%\")\n",
    "        \n",
    "        return {\n",
    "            'model_name': model_name,\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2,\n",
    "            'mape': mape,\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'model': model\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Entrenar Todos los Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n com√∫n\n",
    "hidden_size = 128\n",
    "num_layers = 3\n",
    "dropout = 0.3\n",
    "epochs = 50\n",
    "lr = 0.001\n",
    "\n",
    "# Modelos a entrenar\n",
    "models = {\n",
    "    'SimpleLSTM': SimpleLSTM(hidden_size=hidden_size, num_layers=num_layers, \n",
    "                             output_size=pred_length, dropout=dropout).to(device),\n",
    "    'SimpleGRU': SimpleGRU(hidden_size=hidden_size, num_layers=num_layers, \n",
    "                          output_size=pred_length, dropout=dropout).to(device),\n",
    "    'BidirectionalLSTM': BidirectionalLSTM(hidden_size=hidden_size, num_layers=num_layers, \n",
    "                                           output_size=pred_length, dropout=dropout).to(device),\n",
    "    'LSTMWithAttention': LSTMWithAttention(hidden_size=hidden_size, num_layers=num_layers, \n",
    "                                           output_size=pred_length, dropout=dropout).to(device)\n",
    "}\n",
    "\n",
    "# Entrenar\n",
    "results = []\n",
    "for model_name, model in models.items():\n",
    "    result = train_rnn_model(\n",
    "        model, model_name, \n",
    "        train_loader, val_loader, \n",
    "        X_test_tensor, y_test_tensor,\n",
    "        epochs=epochs, lr=lr\n",
    "    )\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Comparaci√≥n de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame de resultados\n",
    "results_df = pd.DataFrame([{k: v for k, v in r.items() if k != 'model'} for r in results])\n",
    "\n",
    "print(\"üìä COMPARACI√ìN DE ARQUITECTURAS RNN\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Visualizar comparaci√≥n\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics = ['mae', 'rmse', 'r2', 'mape']\n",
    "titles = ['MAE (MW)', 'RMSE (MW)', 'R¬≤ Score', 'MAPE (%)']\n",
    "\n",
    "for idx, (ax, metric, title) in enumerate(zip(axes.flat, metrics, titles)):\n",
    "    results_df.plot(x='model_name', y=metric, kind='bar', ax=ax, legend=False, color='steelblue')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel(title.split('(')[0].strip())\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rnn_models_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Mejor modelo\n",
    "best_idx = results_df['mae'].idxmin()\n",
    "best_model_name = results_df.loc[best_idx, 'model_name']\n",
    "best_model = results[best_idx]['model']\n",
    "\n",
    "print(f\"\\nüèÜ Mejor modelo: {best_model_name}\")\n",
    "print(f\"   MAE: {results_df.loc[best_idx, 'mae']:.2f} MW\")\n",
    "print(f\"   RMSE: {results_df.loc[best_idx, 'rmse']:.2f} MW\")\n",
    "print(f\"   R¬≤: {results_df.loc[best_idx, 'r2']:.4f}\")\n",
    "print(f\"   MAPE: {results_df.loc[best_idx, 'mape']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Export ONNX del Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üîÑ Exportando {best_model_name} a ONNX...\\n\")\n",
    "\n",
    "# Preparar modelo para export\n",
    "best_model.eval()\n",
    "\n",
    "# Input de ejemplo\n",
    "dummy_input = torch.randn(1, seq_length, 1).to(device)\n",
    "\n",
    "# Export a ONNX\n",
    "onnx_filename = f\"{best_model_name}_timeseries.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    best_model,\n",
    "    dummy_input,\n",
    "    onnx_filename,\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Modelo ONNX guardado: {onnx_filename}\")\n",
    "\n",
    "# Verificar modelo ONNX\n",
    "onnx_model = onnx.load(onnx_filename)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"‚úÖ Modelo ONNX verificado\")\n",
    "\n",
    "# Test de inferencia ONNX\n",
    "print(\"\\nüß™ Testeando inferencia ONNX...\")\n",
    "\n",
    "ort_session = rt.InferenceSession(onnx_filename)\n",
    "\n",
    "# Comparar predicciones\n",
    "test_input = X_test_tensor[:5].cpu().numpy()\n",
    "\n",
    "# PyTorch\n",
    "with torch.no_grad():\n",
    "    pytorch_pred = best_model(torch.FloatTensor(test_input).to(device)).cpu().numpy()\n",
    "\n",
    "# ONNX\n",
    "onnx_pred = ort_session.run(None, {'input': test_input.astype(np.float32)})[0]\n",
    "\n",
    "# Comparar\n",
    "diff = np.abs(pytorch_pred - onnx_pred).max()\n",
    "print(f\"   Diferencia m√°xima: {diff:.8f}\")\n",
    "print(f\"   Predicciones coinciden: {'‚úÖ S√≠' if diff < 1e-5 else '‚ùå No'}\")\n",
    "\n",
    "# Benchmark\n",
    "print(\"\\n‚ö° Benchmark de inferencia (100 iteraciones):\")\n",
    "\n",
    "n_iterations = 100\n",
    "test_batch = X_test_tensor[:32]\n",
    "\n",
    "# PyTorch\n",
    "start = time.time()\n",
    "with torch.no_grad():\n",
    "    for _ in range(n_iterations):\n",
    "        _ = best_model(test_batch)\n",
    "pytorch_time = time.time() - start\n",
    "\n",
    "# ONNX\n",
    "test_batch_np = test_batch.cpu().numpy()\n",
    "start = time.time()\n",
    "for _ in range(n_iterations):\n",
    "    _ = ort_session.run(None, {'input': test_batch_np.astype(np.float32)})\n",
    "onnx_time = time.time() - start\n",
    "\n",
    "print(f\"   PyTorch: {pytorch_time:.4f}s ({pytorch_time/n_iterations*1000:.2f}ms/iter)\")\n",
    "print(f\"   ONNX: {onnx_time:.4f}s ({onnx_time/n_iterations*1000:.2f}ms/iter)\")\n",
    "print(f\"   Speedup: {pytorch_time/onnx_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Predicci√≥n Multi-Step con Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_step_forecast(model, initial_sequence, n_steps, scaler):\n",
    "    \"\"\"\n",
    "    Predicci√≥n multi-step iterativa\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    current_seq = initial_sequence.clone()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_steps):\n",
    "            # Predecir pr√≥ximos 24 pasos\n",
    "            pred = model(current_seq.unsqueeze(0))\n",
    "            predictions.append(pred.cpu().numpy()[0])\n",
    "            \n",
    "            # Actualizar secuencia (usar √∫ltimos 24 valores predichos)\n",
    "            current_seq = torch.cat([\n",
    "                current_seq[pred_length:],\n",
    "                pred.unsqueeze(-1)\n",
    "            ], dim=0)\n",
    "    \n",
    "    predictions = np.array(predictions).reshape(-1)\n",
    "    predictions_rescaled = scaler.inverse_transform(predictions.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    return predictions_rescaled\n",
    "\n",
    "# Hacer predicci√≥n de 7 d√≠as (7 * 24 horas)\n",
    "print(\"üîÆ Predicci√≥n multi-step: 7 d√≠as (168 horas)\\n\")\n",
    "\n",
    "initial_seq = X_test_tensor[0]\n",
    "n_days = 7\n",
    "n_steps_forecast = n_days  # Cada step predice 24 horas\n",
    "\n",
    "multi_step_preds = multi_step_forecast(best_model, initial_seq, n_steps_forecast, scaler)\n",
    "\n",
    "# Obtener datos reales correspondientes\n",
    "start_idx = train_size + val_size + seq_length\n",
    "end_idx = start_idx + (n_days * pred_length)\n",
    "real_values = scaler.inverse_transform(energy_scaled[start_idx:end_idx].reshape(-1, 1)).flatten()\n",
    "\n",
    "# Visualizar\n",
    "hours = np.arange(len(multi_step_preds))\n",
    "days_labels = [f\"D√≠a {i//24 + 1}\" if i % 24 == 0 else \"\" for i in hours]\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(hours, real_values[:len(multi_step_preds)], label='Real', linewidth=2, alpha=0.7)\n",
    "plt.plot(hours, multi_step_preds, label='Predicci√≥n', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Horas')\n",
    "plt.ylabel('Demanda de Energ√≠a (MW)')\n",
    "plt.title(f'Predicci√≥n Multi-Step: {n_days} d√≠as ({best_model_name})')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Marcar d√≠as\n",
    "for day in range(1, n_days + 1):\n",
    "    plt.axvline(x=day*24, color='gray', linestyle=':', alpha=0.5)\n",
    "    plt.text(day*24 - 12, plt.ylim()[1]*0.95, f'D√≠a {day}', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('multi_step_forecast.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# M√©tricas multi-step\n",
    "mae_multi = mean_absolute_error(real_values[:len(multi_step_preds)], multi_step_preds)\n",
    "rmse_multi = np.sqrt(mean_squared_error(real_values[:len(multi_step_preds)], multi_step_preds))\n",
    "\n",
    "print(f\"\\nüìä M√©tricas de predicci√≥n multi-step ({n_days} d√≠as):\")\n",
    "print(f\"   MAE: {mae_multi:.2f} MW\")\n",
    "print(f\"   RMSE: {rmse_multi:.2f} MW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Resumen y Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéâ RESUMEN: RNN PARA SERIES TEMPORALES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä DATOS:\")\n",
    "print(f\"   Total registros: {len(df):,} horas ({len(df)/(24*365):.1f} a√±os)\")\n",
    "print(f\"   Secuencia de entrada: {seq_length} horas (1 semana)\")\n",
    "print(f\"   Predicci√≥n: {pred_length} horas (1 d√≠a)\")\n",
    "print(f\"   Train: {len(X_train):,}, Val: {len(X_val):,}, Test: {len(X_test):,}\")\n",
    "\n",
    "print(f\"\\nü§ñ ARQUITECTURAS EVALUADAS: {len(results)}\")\n",
    "for r in results:\n",
    "    print(f\"   - {r['model_name']}: MAE={r['mae']:.2f} MW, R¬≤={r['r2']:.4f}\")\n",
    "\n",
    "print(f\"\\nüèÜ MEJOR MODELO: {best_model_name}\")\n",
    "print(f\"   MAE: {results_df.loc[best_idx, 'mae']:.2f} MW\")\n",
    "print(f\"   RMSE: {results_df.loc[best_idx, 'rmse']:.2f} MW\")\n",
    "print(f\"   R¬≤: {results_df.loc[best_idx, 'r2']:.4f}\")\n",
    "print(f\"   MAPE: {results_df.loc[best_idx, 'mape']:.2f}%\")\n",
    "\n",
    "print(f\"\\n‚úÖ EXPORTACI√ìN ONNX:\")\n",
    "print(f\"   Archivo: {onnx_filename}\")\n",
    "print(f\"   Verificado: S√≠\")\n",
    "print(f\"   Speedup: {pytorch_time/onnx_time:.2f}x\")\n",
    "\n",
    "print(f\"\\nüí° MEJORES PR√ÅCTICAS:\")\n",
    "print(f\"   ‚úÖ Usa secuencias largas para capturar patrones (1 semana+)\")\n",
    "print(f\"   ‚úÖ Normaliza datos antes de entrenar\")\n",
    "print(f\"   ‚úÖ Implementa early stopping\")\n",
    "print(f\"   ‚úÖ Compara m√∫ltiples arquitecturas\")\n",
    "print(f\"   ‚úÖ Bidirectional LSTM captura contexto pasado/futuro\")\n",
    "print(f\"   ‚úÖ Attention ayuda a enfocarse en partes relevantes\")\n",
    "print(f\"   ‚úÖ Export a ONNX para producci√≥n\")\n",
    "print(f\"   ‚úÖ DuckDB acelera procesamiento de datos\")\n",
    "\n",
    "print(f\"\\nüöÄ CASOS DE USO:\")\n",
    "print(f\"   - Predicci√≥n de demanda energ√©tica\")\n",
    "print(f\"   - Forecasting de ventas\")\n",
    "print(f\"   - Predicci√≥n de tr√°fico\")\n",
    "print(f\"   - An√°lisis de series financieras\")\n",
    "print(f\"   - Mantenimiento predictivo\")\n",
    "\n",
    "con.close()\n",
    "print(\"\\n‚úÖ Conexi√≥n DuckDB cerrada\")\n",
    "print(\"\\nüíª Ver resultados: mlflow ui --port 5000\")\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
