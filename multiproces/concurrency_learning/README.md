# ðŸš€ GuÃ­a Completa de Concurrencia y Paralelismo en Python

Proyecto educativo completo para aprender concurrencia, paralelismo, multiprocessing y WebSockets en Python, optimizado para sistemas con mÃºltiples CPUs (como tu droplet de Digital Ocean con 2 CPUs).

## ðŸ“š Tabla de Contenidos

1. [Conceptos Fundamentales](#conceptos-fundamentales)
2. [Estructura del Proyecto](#estructura-del-proyecto)
3. [InstalaciÃ³n y ConfiguraciÃ³n](#instalaciÃ³n-y-configuraciÃ³n)
4. [GuÃ­a de Aprendizaje](#guÃ­a-de-aprendizaje)
5. [Ejemplos PrÃ¡cticos](#ejemplos-prÃ¡cticos)
6. [IntegraciÃ³n con Prometheus/Grafana](#integraciÃ³n-con-prometheusgrafana)
7. [Mejores PrÃ¡cticas](#mejores-prÃ¡cticas)
8. [Troubleshooting](#troubleshooting)

---

## ðŸŽ¯ Conceptos Fundamentales

### Â¿QuÃ© es Concurrencia vs Paralelismo?

```
CONCURRENCIA (Concurrent):
- MÃºltiples tareas PROGRESAN al mismo tiempo
- Una CPU alterna entre tareas rÃ¡pidamente
- Ãštil para I/O-bound (esperas)

    Tiempo â†’
CPU: [Task A][Task B][Task A][Task B]

PARALELISMO (Parallel):
- MÃºltiples tareas EJECUTAN al mismo tiempo
- MÃºltiples CPUs trabajando simultÃ¡neamente
- Ãštil para CPU-bound (cÃ¡lculos)

    Tiempo â†’
CPU1: [Task A][Task A][Task A]
CPU2: [Task B][Task B][Task B]
```

### Threading vs Multiprocessing

| CaracterÃ­stica | Threading | Multiprocessing |
|----------------|-----------|-----------------|
| **Memoria** | Compartida | Separada |
| **GIL** | SÃ­ (limitante) | No |
| **CPU-bound** | âŒ Malo | âœ… Excelente |
| **I/O-bound** | âœ… Bueno | âœ… Funciona |
| **Overhead** | Bajo | Alto |
| **ComunicaciÃ³n** | FÃ¡cil | Queues/Pipes |
| **Debugging** | DifÃ­cil | MÃ¡s fÃ¡cil |

### El GIL (Global Interpreter Lock)

El GIL es un mutex que protege el acceso a objetos Python, evitando que mÃºltiples threads ejecuten bytecode Python simultÃ¡neamente.

```python
# Threading con GIL
# Solo 1 thread ejecuta cÃ³digo Python a la vez
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Thread 1â”‚ â†’â†’â†’ [GIL] â†’â†’â†’ Ejecuta
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚Thread 2â”‚ â†’â†’â†’ Espera el GIL
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# Multiprocessing sin GIL
# Cada proceso tiene su propio GIL
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Process 1 â”‚ â†’â†’â†’ [GIL propio] â†’â†’â†’ Ejecuta en CPU1
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Process 2 â”‚ â†’â†’â†’ [GIL propio] â†’â†’â†’ Ejecuta en CPU2
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ConclusiÃ³n**: Para aprovechar tus 2 CPUs en tareas de cÃ¡lculo, debes usar **multiprocessing**, no threading.

---

## ðŸ“ Estructura del Proyecto

```
concurrency_learning/
â”œâ”€â”€ basics/
â”‚   â”œâ”€â”€ 01_threading_basics.py       # Fundamentos de threading
â”‚   â””â”€â”€ 02_multiprocessing_basics.py # Fundamentos de multiprocessing
â”‚
â”œâ”€â”€ workers/
â”‚   â””â”€â”€ job_queue_system.py          # Sistema de job queue con workers
â”‚
â”œâ”€â”€ websockets/
â”‚   â””â”€â”€ websocket_server.py          # Servidor WebSocket + workers
â”‚
â”œâ”€â”€ monitoring/
â”‚   â””â”€â”€ cpu_monitor.py               # Monitor de CPU y recursos
â”‚
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ demo_completo.py             # Demo completo del sistema
â”‚
â””â”€â”€ README.md                         # Esta guÃ­a
```

---

## ðŸ› ï¸ InstalaciÃ³n y ConfiguraciÃ³n

### En tu Droplet de Digital Ocean

```bash
# 1. Conectar a tu droplet
ssh root@your_droplet_ip

# 2. Instalar Python 3.8+ (si no estÃ¡ instalado)
apt update
apt install python3 python3-pip -y

# 3. Clonar/copiar el proyecto
# (asumiendo que subiste los archivos al droplet)

# 4. Instalar dependencias
pip3 install psutil websockets

# 5. (Opcional) Para Prometheus/Grafana
pip3 install prometheus-client
```

### Verificar tu Sistema

```bash
# Ver nÃºmero de CPUs
python3 -c "import multiprocessing as mp; print(f'CPUs: {mp.cpu_count()}')"

# Ver memoria
python3 -c "import psutil; print(f'RAM: {psutil.virtual_memory().total / (1024**3):.1f} GB')"
```

DeberÃ­as ver:
```
CPUs: 2
RAM: 2.0 GB
```

---

## ðŸ“– GuÃ­a de Aprendizaje

### Nivel 1: Conceptos BÃ¡sicos

#### 1.1 Threading BÃ¡sico

```bash
cd concurrency_learning/basics
python3 01_threading_basics.py
```

**QuÃ© aprenderÃ¡s**:
- Diferencia entre ejecuciÃ³n secuencial y concurrente
- Por quÃ© threading es bueno para I/O
- El problema del GIL con tareas CPU-intensive

**Salida esperada**:
```
[12:30:45.123] [Worker-1] Iniciando tarea I/O: Tarea-1
[12:30:45.124] [Worker-2] Iniciando tarea I/O: Tarea-2
[12:30:45.125] [Worker-3] Iniciando tarea I/O: Tarea-3
...
Tiempo total: 2.02s
(Si fuera secuencial: ~6s, con threading: ~2s)
```

#### 1.2 Multiprocessing BÃ¡sico

```bash
python3 02_multiprocessing_basics.py
```

**QuÃ© aprenderÃ¡s**:
- CÃ³mo crear procesos separados
- Uso de Pool para gestionar workers
- DistribuciÃ³n de carga entre CPUs
- ComunicaciÃ³n entre procesos con Queues

**Conceptos clave**:
```python
# Pool automÃ¡tico (recomendado)
with mp.Pool(processes=2) as pool:
    resultados = pool.map(funcion, datos)

# Control manual de procesos
proceso = mp.Process(target=funcion, args=(arg1, arg2))
proceso.start()
proceso.join()

# ComunicaciÃ³n entre procesos
cola = mp.Queue()
cola.put(datos)
resultado = cola.get()
```

### Nivel 2: Job Queue System

```bash
cd ../workers
python3 job_queue_system.py
```

**QuÃ© aprenderÃ¡s**:
- Sistema de cola de trabajos (como Celery/RQ)
- Workers que procesan jobs en background
- PriorizaciÃ³n de jobs
- Manejo de errores por job

**Arquitectura**:
```
Cliente â†’ Job Queue â†’ Workers (cada uno en un CPU)
                        â†“
                   Results Queue â†’ Cliente
```

**Casos de uso reales**:
- Procesamiento de imÃ¡genes en batch
- GeneraciÃ³n de reportes
- EnvÃ­o de emails masivos
- AnÃ¡lisis de datos

### Nivel 3: WebSockets + Workers

```bash
cd ../websockets

# Terminal 1: Servidor
python3 websocket_server.py

# Terminal 2: Cliente (en otra sesiÃ³n SSH)
python3 websocket_server.py client
```

**QuÃ© aprenderÃ¡s**:
- Servidor WebSocket asÃ­ncrono
- Delegar trabajo pesado a workers
- Mantener conexiones responsivas
- Arquitectura async + multiprocessing

**Flujo de trabajo**:
```
1. Cliente conecta via WebSocket
2. Cliente envÃ­a job (ej: calcular Fibonacci)
3. Servidor encola job para workers
4. Worker en CPU separado procesa job
5. Resultado se envÃ­a de vuelta al cliente via WebSocket
```

**Ejemplo de cliente**:
```javascript
// Cliente JavaScript (para navegador)
const ws = new WebSocket('ws://your_droplet_ip:8765');

ws.onmessage = (event) => {
    const data = JSON.parse(event.data);
    console.log('Recibido:', data);
};

// Enviar job
ws.send(JSON.stringify({
    command: 'submit_job',
    task_type: 'calcular_fibonacci',
    data: { n: 35 }
}));
```

### Nivel 4: Monitoreo

```bash
cd ../monitoring

# Monitoreo bÃ¡sico
python3 cpu_monitor.py

# Monitoreo continuo
python3 cpu_monitor.py monitor

# Servidor Prometheus
python3 cpu_monitor.py prometheus
```

**QuÃ© aprenderÃ¡s**:
- Monitorear uso de CPU por core
- Ver quÃ© proceso usa quÃ© CPU
- Exportar mÃ©tricas para Prometheus
- Detectar bottlenecks

**Salida esperada**:
```
[12:45:30] ==================================================
CPU Total:  45.2%
  CPU0: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.5%
  CPU1: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 30.1%
Memoria:   35.4% (708/2000 MB)
Load Avg:  1.23, 0.98, 0.76
```

### Nivel 5: Demo Completo

```bash
cd ../examples
python3 demo_completo.py
```

**QuÃ© incluye**:
- Sistema completo de procesamiento de imÃ¡genes
- Workers con CPU affinity (cada worker en un CPU especÃ­fico)
- Monitor de rendimiento en tiempo real
- EstadÃ­sticas detalladas

**Conceptos avanzados**:
- CPU affinity para asignar workers a CPUs
- Dashboard en tiempo real
- MÃ©tricas de throughput
- DistribuciÃ³n de carga

---

## ðŸ“Š IntegraciÃ³n con Prometheus/Grafana

### Setup en tu Droplet

#### 1. Instalar Prometheus

```bash
# Descargar Prometheus
cd /opt
wget https://github.com/prometheus/prometheus/releases/download/v2.45.0/prometheus-2.45.0.linux-amd64.tar.gz
tar xvfz prometheus-*.tar.gz
cd prometheus-*

# Configurar prometheus.yml
cat > prometheus.yml << EOF
global:
  scrape_interval: 5s

scrape_configs:
  - job_name: 'python_app'
    static_configs:
      - targets: ['localhost:8000']
EOF

# Ejecutar Prometheus
./prometheus --config.file=prometheus.yml &
```

Prometheus estarÃ¡ en: `http://your_droplet_ip:9090`

#### 2. Instalar Grafana

```bash
# Instalar Grafana
apt-get install -y software-properties-common
add-apt-repository "deb https://packages.grafana.com/oss/deb stable main"
wget -q -O - https://packages.grafana.com/gpg.key | apt-key add -
apt-get update
apt-get install grafana

# Iniciar Grafana
systemctl start grafana-server
systemctl enable grafana-server
```

Grafana estarÃ¡ en: `http://your_droplet_ip:3000` (usuario/password: admin/admin)

#### 3. Exportar MÃ©tricas desde Python

```bash
cd concurrency_learning/monitoring
python3 cpu_monitor.py prometheus
```

Esto expone mÃ©tricas en: `http://your_droplet_ip:8000`

#### 4. Configurar Dashboard en Grafana

1. Abrir Grafana: `http://your_droplet_ip:3000`
2. Agregar Prometheus como data source:
   - Configuration â†’ Data Sources â†’ Add Prometheus
   - URL: `http://localhost:9090`
3. Crear dashboard:
   - Create â†’ Dashboard â†’ Add panel

**Queries Ãºtiles**:
```promql
# Uso total de CPU
cpu_usage_total

# Uso por CPU core
cpu_usage_per_core{core="cpu0"}
cpu_usage_per_core{core="cpu1"}

# Uso de memoria
memory_usage_percent

# Load average
system_load_average{interval="1min"}
```

**Panel recomendado**:
```
TÃ­tulo: CPU Usage por Core
Query: cpu_usage_per_core
Visualization: Time series
Legend: {{core}}
```

### Ejemplo de Dashboard JSON

```json
{
  "dashboard": {
    "title": "Python Multiprocessing Monitor",
    "panels": [
      {
        "title": "CPU Usage per Core",
        "targets": [
          {
            "expr": "cpu_usage_per_core",
            "legendFormat": "{{core}}"
          }
        ]
      },
      {
        "title": "Memory Usage",
        "targets": [
          {
            "expr": "memory_usage_percent"
          }
        ]
      }
    ]
  }
}
```

---

## ðŸŽ“ Mejores PrÃ¡cticas

### 1. CuÃ¡ndo Usar QuÃ©

```python
# âœ… Usa Threading para:
- Llamadas HTTP/API
- Lectura/escritura de archivos
- Database queries
- Operaciones de red

# âœ… Usa Multiprocessing para:
- CÃ¡lculos matemÃ¡ticos intensivos
- Procesamiento de imÃ¡genes/video
- Machine Learning inference
- Data processing pesado

# âœ… Usa AsyncIO para:
- Servidores web (muchas conexiones)
- WebSockets
- Scraping masivo
- I/O concurrente sin overhead de threads
```

### 2. Optimizar para tus 2 CPUs

```python
import multiprocessing as mp

# Siempre usar nÃºmero de CPUs disponibles
num_workers = mp.cpu_count()  # = 2 en tu droplet

# Para CPU-intensive: workers = CPUs
with mp.Pool(processes=num_workers) as pool:
    results = pool.map(cpu_intensive_task, data)

# Para I/O-intensive: puedes usar mÃ¡s workers
num_workers = mp.cpu_count() * 2  # = 4

# Para tareas mixtas: empezar con CPUs y ajustar
num_workers = mp.cpu_count()  # Luego monitorear y ajustar
```

### 3. CPU Affinity (Asignar Workers a CPUs)

```python
import psutil
import os

def worker_with_affinity(worker_id):
    # Asignar worker a CPU especÃ­fico
    cpu_id = (worker_id - 1) % mp.cpu_count()
    process = psutil.Process(os.getpid())
    process.cpu_affinity([cpu_id])

    print(f"Worker {worker_id} asignado a CPU {cpu_id}")
    # ... resto del cÃ³digo del worker
```

**Beneficios**:
- Mejor uso del cache L1/L2 de cada CPU
- Evita context switching entre CPUs
- Rendimiento mÃ¡s predecible

### 4. Manejo de Memoria

```python
# âŒ MAL: Compartir datos grandes entre procesos
datos_grandes = list(range(10_000_000))
with mp.Pool() as pool:
    # Esto COPIA los datos a cada proceso
    results = pool.map(procesar, [datos_grandes] * 10)

# âœ… BIEN: Usar shared memory
from multiprocessing import shared_memory

# Crear shared memory
shm = shared_memory.SharedMemory(create=True, size=1000000)
# ... usar shared memory

# O mejor: procesar en chunks
def procesar_chunk(start, end):
    # Generar datos solo en este proceso
    datos = list(range(start, end))
    return process(datos)

with mp.Pool() as pool:
    results = pool.starmap(procesar_chunk, [
        (0, 5000000),
        (5000000, 10000000)
    ])
```

### 5. Debugging Multiprocessing

```python
# Activar logging detallado
import logging
mp.log_to_stderr(logging.DEBUG)

# Usar try-except en workers
def safe_worker(job):
    try:
        return process(job)
    except Exception as e:
        import traceback
        return {
            'error': str(e),
            'traceback': traceback.format_exc()
        }

# Usar timeout para evitar hangs
result = queue.get(timeout=30)  # Timeout de 30s
```

---

## ðŸ”§ Troubleshooting

### Problema: "Workers no usan CPUs diferentes"

**SoluciÃ³n**: Verificar con htop

```bash
# Instalar htop
apt install htop

# Ejecutar tu programa en una terminal
python3 demo_completo.py

# En otra terminal, ver uso de CPU
htop
# Presiona 't' para vista de Ã¡rbol
# Verifica que mÃºltiples procesos Python usen CPUs diferentes
```

### Problema: "Queue estÃ¡ llena"

```python
# Usar maxsize
queue = mp.Queue(maxsize=100)

# O procesar en batches
def procesar_en_batches(items, batch_size=50):
    for i in range(0, len(items), batch_size):
        batch = items[i:i+batch_size]
        procesar_batch(batch)
```

### Problema: "Workers no terminan (hang)"

```python
# Usar timeout en joins
worker.join(timeout=10)
if worker.is_alive():
    worker.terminate()
    worker.join()

# Usar Event para shutdown graceful
shutdown_event = mp.Event()

def worker(shutdown_event):
    while not shutdown_event.is_set():
        # ... trabajo
        pass
```

### Problema: "Memoria se llena"

```python
# Procesar en chunks
def procesar_grande(filename):
    with open(filename) as f:
        while True:
            chunk = f.readlines(10000)  # Leer 10k lÃ­neas
            if not chunk:
                break
            procesar_chunk(chunk)

# Limpiar despuÃ©s de cada job
import gc
gc.collect()
```

### Problema: "No puedo conectar al WebSocket desde fuera"

```bash
# Verificar firewall
ufw allow 8765/tcp

# Verificar que servidor escucha en 0.0.0.0
# En websocket_server.py:
server = WebSocketServer(
    host="0.0.0.0",  # No "localhost"
    port=8765
)
```

---

## ðŸš€ Comandos RÃ¡pidos

```bash
# NavegaciÃ³n
cd ~/concurrency_learning

# Ejecutar ejemplos bÃ¡sicos
python3 basics/01_threading_basics.py
python3 basics/02_multiprocessing_basics.py

# Job queue
python3 workers/job_queue_system.py

# WebSocket
python3 websockets/websocket_server.py          # Servidor
python3 websockets/websocket_server.py client   # Cliente

# Monitoreo
python3 monitoring/cpu_monitor.py               # Snapshot
python3 monitoring/cpu_monitor.py monitor       # Continuo
python3 monitoring/cpu_monitor.py prometheus    # Prometheus

# Demo completo
python3 examples/demo_completo.py

# Ver procesos Python
ps aux | grep python

# Ver uso de CPU en tiempo real
htop
```

---

## ðŸ“ Ejercicios Propuestos

### Ejercicio 1: Web Scraper Paralelo

Crear un scraper que:
- Use multiprocessing para scraping paralelo
- Procese 50 URLs simultÃ¡neamente con 2 workers
- Guarde resultados en una base de datos

### Ejercicio 2: API Server con Workers

Crear API REST que:
- Reciba requests de procesamiento
- Delegue a workers multiprocessing
- Retorne resultados via polling o WebSocket

### Ejercicio 3: Sistema de Thumbnails

Crear sistema que:
- Procese imÃ¡genes subidas
- Genere thumbnails de diferentes tamaÃ±os
- Use job queue con prioridades

---

## ðŸ“š Recursos Adicionales

- [Python multiprocessing docs](https://docs.python.org/3/library/multiprocessing.html)
- [Understanding the GIL](https://realpython.com/python-gil/)
- [Prometheus Python Client](https://github.com/prometheus/client_python)
- [psutil docs](https://psutil.readthedocs.io/)

---

## ðŸ¤ PrÃ³ximos Pasos

1. âœ… Ejecuta todos los ejemplos bÃ¡sicos
2. âœ… Entiende la diferencia threading vs multiprocessing
3. âœ… Implementa tu propio job queue
4. âœ… Configura monitoreo con Prometheus/Grafana
5. ðŸš€ Aplica estos conceptos a tu proyecto real

---

**Â¿Preguntas?** Revisa los comentarios en cada archivo `.py` - estÃ¡n documentados extensivamente con explicaciones de cada concepto.

**Â¡Buena suerte aprendiendo concurrencia y paralelismo en Python! ðŸŽ‰**
