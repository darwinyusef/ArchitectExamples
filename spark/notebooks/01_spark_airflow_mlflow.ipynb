{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark + Airflow + MLflow: OrquestaciÃ³n de Pipelines ML\n",
    "\n",
    "## Objetivos\n",
    "- Crear un pipeline de datos con Apache Spark\n",
    "- Orquestar el pipeline con Apache Airflow\n",
    "- Trackear experimentos y mÃ©tricas con MLflow\n",
    "- Implementar un flujo end-to-end de ML\n",
    "\n",
    "## Conceptos Clave\n",
    "- **Spark**: Motor de procesamiento distribuido\n",
    "- **Airflow**: Plataforma de orquestaciÃ³n de workflows\n",
    "- **MLflow**: Plataforma de gestiÃ³n del ciclo de vida ML\n",
    "\n",
    "## Arquitectura del Pipeline\n",
    "```\n",
    "Airflow DAG\n",
    "    â†“\n",
    "1. Ingesta de datos (Spark)\n",
    "    â†“\n",
    "2. TransformaciÃ³n (Spark)\n",
    "    â†“\n",
    "3. Feature Engineering (Spark)\n",
    "    â†“\n",
    "4. Entrenamiento de modelo (Spark ML + MLflow)\n",
    "    â†“\n",
    "5. EvaluaciÃ³n y registro (MLflow)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup e Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones necesarias\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, mean, stddev, count\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "\n",
    "# Spark ML\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Airflow (para definir DAGs)\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator\n",
    "\n",
    "# Utilidades\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"âœ“ Importaciones completadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ConfiguraciÃ³n de Spark y MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Airflow-MLflow-Pipeline\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Configurar MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")  # Cambiar si usas servidor remoto\n",
    "mlflow.set_experiment(\"spark-airflow-pipeline\")\n",
    "\n",
    "print(f\"âœ“ Spark version: {spark.version}\")\n",
    "print(f\"âœ“ MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"âœ“ MLflow experiment: {mlflow.get_experiment_by_name('spark-airflow-pipeline').name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SimulaciÃ³n de DAG de Airflow\n",
    "\n",
    "En un entorno real, este DAG estarÃ­a en `airflow/dags/`. AquÃ­ lo simulamos para propÃ³sitos educativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DefiniciÃ³n del DAG (esto normalmente va en airflow/dags/spark_ml_pipeline.py)\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'yusef',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime(2024, 1, 1),\n",
    "    'email_on_failure': False,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "}\n",
    "\n",
    "# Estructura del DAG\n",
    "dag_structure = \"\"\"\n",
    "DAG: spark_ml_pipeline\n",
    "â”œâ”€â”€ Task 1: ingest_data\n",
    "â”œâ”€â”€ Task 2: transform_data\n",
    "â”œâ”€â”€ Task 3: feature_engineering\n",
    "â”œâ”€â”€ Task 4: train_model\n",
    "â””â”€â”€ Task 5: evaluate_model\n",
    "\"\"\"\n",
    "\n",
    "print(dag_structure)\n",
    "print(\"\\nNota: En producciÃ³n, este DAG se ejecutarÃ­a en Airflow\")\n",
    "print(\"AquÃ­ ejecutaremos cada tarea manualmente para demostraciÃ³n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Task 1: Ingesta de Datos\n",
    "\n",
    "Generamos datos sintÃ©ticos que simulan transacciones de clientes para detectar fraude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_data():\n",
    "    \"\"\"Task 1: Ingesta de datos usando Spark\"\"\"\n",
    "    print(\"[Task 1] Iniciando ingesta de datos...\")\n",
    "    \n",
    "    # Generar datos sintÃ©ticos\n",
    "    np.random.seed(42)\n",
    "    n_samples = 10000\n",
    "    \n",
    "    data = {\n",
    "        'transaction_id': range(n_samples),\n",
    "        'amount': np.random.exponential(100, n_samples),\n",
    "        'merchant_category': np.random.choice(['retail', 'online', 'restaurant', 'travel'], n_samples),\n",
    "        'transaction_hour': np.random.randint(0, 24, n_samples),\n",
    "        'customer_age': np.random.randint(18, 80, n_samples),\n",
    "        'is_international': np.random.choice([0, 1], n_samples, p=[0.9, 0.1]),\n",
    "        'num_previous_transactions': np.random.randint(0, 100, n_samples),\n",
    "        'is_fraud': np.random.choice([0, 1], n_samples, p=[0.95, 0.05])  # 5% fraude\n",
    "    }\n",
    "    \n",
    "    # Crear DataFrame de Spark\n",
    "    df = spark.createDataFrame(pd.DataFrame(data))\n",
    "    \n",
    "    print(f\"âœ“ Datos ingestados: {df.count()} registros\")\n",
    "    print(f\"âœ“ Columnas: {df.columns}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Ejecutar Task 1\n",
    "raw_df = ingest_data()\n",
    "raw_df.show(5)\n",
    "raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Task 2: TransformaciÃ³n de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "    \"\"\"Task 2: TransformaciÃ³n y limpieza de datos\"\"\"\n",
    "    print(\"[Task 2] Iniciando transformaciÃ³n de datos...\")\n",
    "    \n",
    "    # Limpieza: eliminar duplicados\n",
    "    df_clean = df.dropDuplicates(['transaction_id'])\n",
    "    \n",
    "    # Crear nuevas features\n",
    "    df_transformed = df_clean \\\n",
    "        .withColumn('amount_log', col('amount').log1p()) \\\n",
    "        .withColumn('is_night_transaction', when(col('transaction_hour') < 6, 1).otherwise(0)) \\\n",
    "        .withColumn('is_large_amount', when(col('amount') > 500, 1).otherwise(0)) \\\n",
    "        .withColumn('risk_score', \n",
    "                   col('is_international') * 0.3 + \n",
    "                   col('is_night_transaction') * 0.2 + \n",
    "                   col('is_large_amount') * 0.5)\n",
    "    \n",
    "    # EstadÃ­sticas\n",
    "    stats = df_transformed.select(\n",
    "        count('*').alias('total_records'),\n",
    "        mean('amount').alias('avg_amount'),\n",
    "        stddev('amount').alias('stddev_amount')\n",
    "    ).collect()[0]\n",
    "    \n",
    "    print(f\"âœ“ Registros transformados: {stats['total_records']}\")\n",
    "    print(f\"âœ“ Monto promedio: ${stats['avg_amount']:.2f}\")\n",
    "    print(f\"âœ“ DesviaciÃ³n estÃ¡ndar: ${stats['stddev_amount']:.2f}\")\n",
    "    \n",
    "    return df_transformed\n",
    "\n",
    "# Ejecutar Task 2\n",
    "transformed_df = transform_data(raw_df)\n",
    "transformed_df.select('transaction_id', 'amount', 'amount_log', 'risk_score', 'is_fraud').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Task 3: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    \"\"\"Task 3: PreparaciÃ³n de features para ML\"\"\"\n",
    "    print(\"[Task 3] Iniciando feature engineering...\")\n",
    "    \n",
    "    # Indexar variables categÃ³ricas\n",
    "    indexer = StringIndexer(inputCol='merchant_category', outputCol='merchant_category_idx')\n",
    "    df_indexed = indexer.fit(df).transform(df)\n",
    "    \n",
    "    # Seleccionar features para el modelo\n",
    "    feature_cols = [\n",
    "        'amount_log',\n",
    "        'merchant_category_idx',\n",
    "        'transaction_hour',\n",
    "        'customer_age',\n",
    "        'is_international',\n",
    "        'num_previous_transactions',\n",
    "        'is_night_transaction',\n",
    "        'is_large_amount',\n",
    "        'risk_score'\n",
    "    ]\n",
    "    \n",
    "    # Ensamblar features en vector\n",
    "    assembler = VectorAssembler(inputCols=feature_cols, outputCol='features_raw')\n",
    "    df_assembled = assembler.transform(df_indexed)\n",
    "    \n",
    "    # Escalar features\n",
    "    scaler = StandardScaler(inputCol='features_raw', outputCol='features', withMean=True, withStd=True)\n",
    "    scaler_model = scaler.fit(df_assembled)\n",
    "    df_final = scaler_model.transform(df_assembled)\n",
    "    \n",
    "    # Seleccionar columnas finales\n",
    "    df_ml = df_final.select('features', col('is_fraud').alias('label'))\n",
    "    \n",
    "    print(f\"âœ“ Features creadas: {len(feature_cols)}\")\n",
    "    print(f\"âœ“ Features: {feature_cols}\")\n",
    "    \n",
    "    return df_ml, feature_cols\n",
    "\n",
    "# Ejecutar Task 3\n",
    "ml_df, feature_names = feature_engineering(transformed_df)\n",
    "ml_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Task 4: Entrenamiento de Modelo con MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df, feature_names):\n",
    "    \"\"\"Task 4: Entrenamiento de modelo con tracking en MLflow\"\"\"\n",
    "    print(\"[Task 4] Iniciando entrenamiento de modelo...\")\n",
    "    \n",
    "    # Split train/test\n",
    "    train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "    \n",
    "    print(f\"âœ“ Training set: {train_df.count()} registros\")\n",
    "    print(f\"âœ“ Test set: {test_df.count()} registros\")\n",
    "    \n",
    "    # Iniciar MLflow run\n",
    "    with mlflow.start_run(run_name=\"random-forest-fraud-detection\") as run:\n",
    "        \n",
    "        # Log parÃ¡metros\n",
    "        params = {\n",
    "            'model_type': 'RandomForest',\n",
    "            'num_trees': 100,\n",
    "            'max_depth': 10,\n",
    "            'feature_subset_strategy': 'auto'\n",
    "        }\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Entrenar modelo\n",
    "        rf = RandomForestClassifier(\n",
    "            featuresCol='features',\n",
    "            labelCol='label',\n",
    "            numTrees=params['num_trees'],\n",
    "            maxDepth=params['max_depth'],\n",
    "            featureSubsetStrategy=params['feature_subset_strategy'],\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "        print(\"\\nâ³ Entrenando Random Forest...\")\n",
    "        model = rf.fit(train_df)\n",
    "        print(\"âœ“ Modelo entrenado\")\n",
    "        \n",
    "        # Feature importance\n",
    "        feature_importance = list(zip(feature_names, model.featureImportances.toArray()))\n",
    "        feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(\"\\nðŸ“Š Top 5 Features mÃ¡s importantes:\")\n",
    "        for feat, importance in feature_importance[:5]:\n",
    "            print(f\"  - {feat}: {importance:.4f}\")\n",
    "            mlflow.log_metric(f\"feature_importance_{feat}\", importance)\n",
    "        \n",
    "        # Guardar modelo\n",
    "        mlflow.spark.log_model(model, \"random-forest-model\")\n",
    "        \n",
    "        # Log artifacts adicionales\n",
    "        mlflow.log_param(\"num_features\", len(feature_names))\n",
    "        mlflow.set_tag(\"pipeline_stage\", \"training\")\n",
    "        mlflow.set_tag(\"framework\", \"spark-ml\")\n",
    "        \n",
    "        print(f\"\\nâœ“ Run ID: {run.info.run_id}\")\n",
    "        \n",
    "        return model, train_df, test_df, run.info.run_id\n",
    "\n",
    "# Ejecutar Task 4\n",
    "model, train_df, test_df, run_id = train_model(ml_df, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Task 5: EvaluaciÃ³n del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_df, run_id):\n",
    "    \"\"\"Task 5: EvaluaciÃ³n del modelo y logging de mÃ©tricas\"\"\"\n",
    "    print(\"[Task 5] Iniciando evaluaciÃ³n del modelo...\")\n",
    "    \n",
    "    # Predicciones\n",
    "    predictions = model.transform(test_df)\n",
    "    \n",
    "    # Continuar el run anterior\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        \n",
    "        # Evaluadores\n",
    "        binary_evaluator = BinaryClassificationEvaluator(\n",
    "            labelCol='label',\n",
    "            rawPredictionCol='rawPrediction',\n",
    "            metricName='areaUnderROC'\n",
    "        )\n",
    "        \n",
    "        multiclass_evaluator = MulticlassClassificationEvaluator(\n",
    "            labelCol='label',\n",
    "            predictionCol='prediction'\n",
    "        )\n",
    "        \n",
    "        # Calcular mÃ©tricas\n",
    "        auc = binary_evaluator.evaluate(predictions)\n",
    "        accuracy = multiclass_evaluator.evaluate(predictions, {multiclass_evaluator.metricName: \"accuracy\"})\n",
    "        precision = multiclass_evaluator.evaluate(predictions, {multiclass_evaluator.metricName: \"weightedPrecision\"})\n",
    "        recall = multiclass_evaluator.evaluate(predictions, {multiclass_evaluator.metricName: \"weightedRecall\"})\n",
    "        f1 = multiclass_evaluator.evaluate(predictions, {multiclass_evaluator.metricName: \"f1\"})\n",
    "        \n",
    "        # Log mÃ©tricas\n",
    "        metrics = {\n",
    "            'test_auc': auc,\n",
    "            'test_accuracy': accuracy,\n",
    "            'test_precision': precision,\n",
    "            'test_recall': recall,\n",
    "            'test_f1': f1\n",
    "        }\n",
    "        \n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Mostrar resultados\n",
    "        print(\"\\nðŸ“Š MÃ©tricas del Modelo:\")\n",
    "        print(f\"  â€¢ AUC-ROC: {auc:.4f}\")\n",
    "        print(f\"  â€¢ Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  â€¢ Precision: {precision:.4f}\")\n",
    "        print(f\"  â€¢ Recall: {recall:.4f}\")\n",
    "        print(f\"  â€¢ F1-Score: {f1:.4f}\")\n",
    "        \n",
    "        # Matriz de confusiÃ³n (simplificada)\n",
    "        confusion = predictions.groupBy('label', 'prediction').count().toPandas()\n",
    "        print(\"\\nðŸ“Š Matriz de ConfusiÃ³n:\")\n",
    "        print(confusion)\n",
    "        \n",
    "        # Ejemplos de predicciones\n",
    "        print(\"\\nðŸ” Ejemplos de Predicciones:\")\n",
    "        predictions.select('label', 'prediction', 'probability').show(10, truncate=False)\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "# Ejecutar Task 5\n",
    "metrics = evaluate_model(model, test_df, run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Resumen del Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"RESUMEN DEL PIPELINE SPARK + AIRFLOW + MLFLOW\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nâœ… Tasks Completadas:\")\n",
    "print(\"  1. âœ“ Ingesta de datos (Spark)\")\n",
    "print(\"  2. âœ“ TransformaciÃ³n de datos (Spark)\")\n",
    "print(\"  3. âœ“ Feature Engineering (Spark ML)\")\n",
    "print(\"  4. âœ“ Entrenamiento de modelo (Random Forest)\")\n",
    "print(\"  5. âœ“ EvaluaciÃ³n y registro (MLflow)\")\n",
    "\n",
    "print(\"\\nðŸ“Š MÃ©tricas Finales:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  â€¢ {metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ”— MLflow Tracking:\")\n",
    "print(f\"  â€¢ Run ID: {run_id}\")\n",
    "print(f\"  â€¢ Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"  â€¢ Experiment: spark-airflow-pipeline\")\n",
    "\n",
    "print(\"\\nðŸ’¡ PrÃ³ximos Pasos:\")\n",
    "print(\"  1. Implementar el DAG completo en Airflow\")\n",
    "print(\"  2. Configurar scheduling automÃ¡tico (daily, hourly, etc.)\")\n",
    "print(\"  3. AÃ±adir alertas y monitoring\")\n",
    "print(\"  4. Deploy del modelo en producciÃ³n\")\n",
    "print(\"  5. Implementar retraining automÃ¡tico\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Archivo DAG para Airflow (CÃ³digo de ProducciÃ³n)\n",
    "\n",
    "Este cÃ³digo deberÃ­a ir en `airflow/dags/spark_ml_pipeline.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CÃ³digo de ejemplo para airflow/dags/spark_ml_pipeline.py\n",
    "\n",
    "dag_code = '''\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'yusef',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime(2024, 1, 1),\n",
    "    'email': ['yusef@example.com'],\n",
    "    'email_on_failure': True,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 2,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    'spark_ml_pipeline',\n",
    "    default_args=default_args,\n",
    "    description='Pipeline ML con Spark y MLflow',\n",
    "    schedule_interval='@daily',  # Ejecutar diariamente\n",
    "    catchup=False,\n",
    "    tags=['spark', 'ml', 'mlflow'],\n",
    ")\n",
    "\n",
    "# Task 1: Ingesta\n",
    "ingest_task = SparkSubmitOperator(\n",
    "    task_id='ingest_data',\n",
    "    application='scripts/ingest_data.py',\n",
    "    conn_id='spark_default',\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "# Task 2: TransformaciÃ³n\n",
    "transform_task = SparkSubmitOperator(\n",
    "    task_id='transform_data',\n",
    "    application='scripts/transform_data.py',\n",
    "    conn_id='spark_default',\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "# Task 3: Feature Engineering\n",
    "feature_task = SparkSubmitOperator(\n",
    "    task_id='feature_engineering',\n",
    "    application='scripts/feature_engineering.py',\n",
    "    conn_id='spark_default',\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "# Task 4: Training\n",
    "train_task = SparkSubmitOperator(\n",
    "    task_id='train_model',\n",
    "    application='scripts/train_model.py',\n",
    "    conn_id='spark_default',\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "# Task 5: Evaluation\n",
    "eval_task = PythonOperator(\n",
    "    task_id='evaluate_model',\n",
    "    python_callable=evaluate_model_func,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "# Definir dependencias\n",
    "ingest_task >> transform_task >> feature_task >> train_task >> eval_task\n",
    "'''\n",
    "\n",
    "print(\"CÃ³digo del DAG para Airflow:\")\n",
    "print(dag_code)\n",
    "\n",
    "# Guardar a archivo\n",
    "with open('../scripts/example_airflow_dag.py', 'w') as f:\n",
    "    f.write(dag_code)\n",
    "    \n",
    "print(\"\\nâœ“ DAG guardado en: scripts/example_airflow_dag.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerrar sesiÃ³n de Spark\n",
    "# spark.stop()\n",
    "# print(\"âœ“ Spark session cerrada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "### Aprendizajes Clave\n",
    "\n",
    "1. **IntegraciÃ³n Spark + Airflow + MLflow**\n",
    "   - Airflow orquesta las tareas del pipeline\n",
    "   - Spark procesa datos a escala\n",
    "   - MLflow trackea experimentos y modelos\n",
    "\n",
    "2. **Pipeline End-to-End**\n",
    "   - Ingesta â†’ TransformaciÃ³n â†’ Feature Engineering â†’ Training â†’ Evaluation\n",
    "   - Cada etapa es modular e independiente\n",
    "   - FÃ¡cil de escalar y mantener\n",
    "\n",
    "3. **Ventajas**\n",
    "   - âœ… Reproducibilidad (MLflow)\n",
    "   - âœ… Escalabilidad (Spark)\n",
    "   - âœ… AutomatizaciÃ³n (Airflow)\n",
    "   - âœ… Monitoreo centralizado\n",
    "\n",
    "### Recursos Adicionales\n",
    "\n",
    "- [Airflow Documentation](https://airflow.apache.org/)\n",
    "- [Spark ML Guide](https://spark.apache.org/docs/latest/ml-guide.html)\n",
    "- [MLflow Tracking](https://mlflow.org/docs/latest/tracking.html)\n",
    "\n",
    "### Ejercicios Propuestos\n",
    "\n",
    "1. Modificar el pipeline para usar otros algoritmos (GBT, SVM)\n",
    "2. Implementar hyperparameter tuning con CrossValidator\n",
    "3. AÃ±adir data validation con Great Expectations\n",
    "4. Crear alertas en Airflow para fallos del modelo\n",
    "5. Deploy del modelo usando MLflow Model Registry"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
