{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark + SciPy + Matemáticas para ML\n",
    "\n",
    "## Objetivos\n",
    "- Operaciones matemáticas avanzadas con SciPy\n",
    "- Optimización distribuida\n",
    "- Estadística y análisis numérico\n",
    "- Álgebra lineal a escala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import pandas_udf, col\n",
    "from pyspark.sql.types import FloatType, ArrayType\n",
    "\n",
    "import scipy\n",
    "from scipy import optimize, stats, linalg, special, integrate\n",
    "from scipy.spatial import distance\n",
    "from scipy.signal import correlate\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(f'SciPy version: {scipy.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "spark = SparkSession.builder.appName('SciPy-Math-ML').master('local[*]').getOrCreate()\n",
    "mlflow.set_tracking_uri('http://localhost:5000')\n",
    "mlflow.set_experiment('spark-scipy-mathematics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Optimización Matemática\n",
    "\n",
    "### Optimización de funciones personalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función objetivo: Rosenbrock\n",
    "def rosenbrock(x):\n",
    "    return sum(100.0 * (x[1:] - x[:-1]**2)**2 + (1 - x[:-1])**2)\n",
    "\n",
    "# Optimizar\n",
    "x0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\n",
    "result = optimize.minimize(rosenbrock, x0, method='BFGS')\n",
    "\n",
    "print('Optimización de Rosenbrock:')\n",
    "print(f'Solución: {result.x}')\n",
    "print(f'Valor mínimo: {result.fun:.6f}')\n",
    "print(f'Iteraciones: {result.nit}')\n",
    "\n",
    "# Log a MLflow\n",
    "with mlflow.start_run(run_name='rosenbrock-optimization'):\n",
    "    mlflow.log_params({'method': 'BFGS', 'dimensions': len(x0)})\n",
    "    mlflow.log_metric('min_value', result.fun)\n",
    "    mlflow.log_metric('iterations', result.nit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análisis Estadístico Distribuido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos\n",
    "np.random.seed(42)\n",
    "n_samples = 50000\n",
    "\n",
    "data = {\n",
    "    'normal_dist': np.random.normal(100, 15, n_samples),\n",
    "    'exponential_dist': np.random.exponential(5, n_samples),\n",
    "    'uniform_dist': np.random.uniform(0, 100, n_samples),\n",
    "    'gamma_dist': np.random.gamma(2, 2, n_samples)\n",
    "}\n",
    "\n",
    "df = spark.createDataFrame(pd.DataFrame(data))\n",
    "\n",
    "print(f'Dataset: {df.count()} registros')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests estadísticos con UDF\n",
    "@pandas_udf(\"double\")\n",
    "def normality_test_pvalue(col1: pd.Series) -> pd.Series:\n",
    "    \"\"\"Test de normalidad (Shapiro-Wilk) - retorna p-value\"\"\"\n",
    "    # Usar muestra para test (Shapiro-Wilk tiene límites)\n",
    "    sample = col1.sample(min(5000, len(col1)), random_state=42)\n",
    "    _, p_value = stats.shapiro(sample)\n",
    "    return pd.Series([p_value] * len(col1))\n",
    "\n",
    "@pandas_udf(\"double\")\n",
    "def skewness_calc(col1: pd.Series) -> pd.Series:\n",
    "    \"\"\"Calcular asimetría\"\"\"\n",
    "    skew = stats.skew(col1)\n",
    "    return pd.Series([skew] * len(col1))\n",
    "\n",
    "@pandas_udf(\"double\")\n",
    "def kurtosis_calc(col1: pd.Series) -> pd.Series:\n",
    "    \"\"\"Calcular curtosis\"\"\"\n",
    "    kurt = stats.kurtosis(col1)\n",
    "    return pd.Series([kurt] * len(col1))\n",
    "\n",
    "# Aplicar tests\n",
    "df_stats = df.select(\n",
    "    col('normal_dist'),\n",
    "    skewness_calc(col('normal_dist')).alias('skewness'),\n",
    "    kurtosis_calc(col('normal_dist')).alias('kurtosis')\n",
    ")\n",
    "\n",
    "print('\\nEstadísticas de la distribución normal:')\n",
    "df_stats.select('skewness', 'kurtosis').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Álgebra Lineal Distribuida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operaciones de álgebra lineal\n",
    "def matrix_operations_example():\n",
    "    # Crear matriz\n",
    "    A = np.random.randn(1000, 1000)\n",
    "    \n",
    "    # Descomposición SVD\n",
    "    U, s, Vt = linalg.svd(A, full_matrices=False)\n",
    "    \n",
    "    # Valores propios\n",
    "    eigenvalues, eigenvectors = linalg.eig(A @ A.T)\n",
    "    \n",
    "    # Determinante\n",
    "    det = linalg.det(A)\n",
    "    \n",
    "    # Norma\n",
    "    norm = linalg.norm(A)\n",
    "    \n",
    "    print('Operaciones de Álgebra Lineal:')\n",
    "    print(f'Dimensiones de A: {A.shape}')\n",
    "    print(f'Valores singulares (top 5): {s[:5]}')\n",
    "    print(f'Determinante: {det:.4e}')\n",
    "    print(f'Norma Frobenius: {norm:.4f}')\n",
    "    \n",
    "    return {'det': det, 'norm': norm, 'singular_values': s[:10].tolist()}\n",
    "\n",
    "with mlflow.start_run(run_name='linear-algebra-ops'):\n",
    "    results = matrix_operations_example()\n",
    "    mlflow.log_metrics({'determinant': results['det'], 'frobenius_norm': results['norm']})\n",
    "    mlflow.log_param('matrix_size', '1000x1000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Distancias y Similaridades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular distancias entre vectores\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "\n",
    "# Generar vectores\n",
    "vectors = np.random.randn(100, 50)\n",
    "\n",
    "# Diferentes métricas de distancia\n",
    "dist_metrics = ['euclidean', 'cosine', 'manhattan', 'chebyshev']\n",
    "\n",
    "print('Distancias entre vectores:')\n",
    "for metric in dist_metrics:\n",
    "    dist_matrix = pdist(vectors, metric=metric)\n",
    "    avg_dist = np.mean(dist_matrix)\n",
    "    print(f'{metric:15s}: {avg_dist:.4f}')\n",
    "\n",
    "# Usar en Spark con UDF\n",
    "@pandas_udf(ArrayType(FloatType()))\n",
    "def compute_pairwise_distances(features: pd.Series) -> pd.Series:\n",
    "    \"\"\"Calcular distancias entre vectores\"\"\"\n",
    "    def calc_dist(row):\n",
    "        if row is None or len(row) == 0:\n",
    "            return []\n",
    "        # Convertir a array\n",
    "        arr = np.array(row).reshape(1, -1)\n",
    "        # Calcular distancias a centros (ejemplo simple)\n",
    "        centers = np.random.randn(5, arr.shape[1])\n",
    "        dists = cdist(arr, centers, metric='euclidean')[0]\n",
    "        return dists.tolist()\n",
    "    \n",
    "    return features.apply(calc_dist)\n",
    "\n",
    "print('\\n✓ UDF de distancias creada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Integración Numérica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integración de funciones\n",
    "def gaussian(x, mu, sigma):\n",
    "    return (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma)**2)\n",
    "\n",
    "# Integrar distribución normal\n",
    "mu, sigma = 0, 1\n",
    "result, error = integrate.quad(lambda x: gaussian(x, mu, sigma), -3, 3)\n",
    "\n",
    "print(f'\\nIntegración de distribución normal N(0,1) en [-3, 3]:')\n",
    "print(f'Resultado: {result:.6f} (esperado: ~0.9973)')\n",
    "print(f'Error estimado: {error:.2e}')\n",
    "\n",
    "# Integración múltiple\n",
    "def integrand(y, x):\n",
    "    return x * y**2\n",
    "\n",
    "result_2d = integrate.dblquad(integrand, 0, 2, 0, 1)\n",
    "print(f'\\nIntegración doble: {result_2d[0]:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Funciones Especiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones especiales útiles en ML\n",
    "x = np.linspace(-5, 5, 100)\n",
    "\n",
    "# Sigmoid\n",
    "sigmoid = special.expit(x)\n",
    "\n",
    "# Log-sigmoid (más estable numéricamente)\n",
    "log_sigmoid = special.log_expit(x)\n",
    "\n",
    "# Softmax\n",
    "softmax_vals = special.softmax(x)\n",
    "\n",
    "# Gamma function\n",
    "gamma_vals = special.gamma(np.linspace(0.1, 5, 50))\n",
    "\n",
    "# Visualizar\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].plot(x, sigmoid, linewidth=2, color='steelblue')\n",
    "axes[0, 0].set_title('Sigmoid Function', fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(x, log_sigmoid, linewidth=2, color='coral')\n",
    "axes[0, 1].set_title('Log-Sigmoid Function', fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].plot(x, softmax_vals, linewidth=2, color='green')\n",
    "axes[1, 0].set_title('Softmax Function', fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(np.linspace(0.1, 5, 50), gamma_vals, linewidth=2, color='purple')\n",
    "axes[1, 1].set_title('Gamma Function', fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('special_functions.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print('✓ Funciones especiales visualizadas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Aplicación Práctica: Gradient Descent Personalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_gradient_descent(X, y, learning_rate=0.01, epochs=100):\n",
    "    \"\"\"Implementación de gradient descent con SciPy\"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    weights = np.zeros(n_features)\n",
    "    bias = 0\n",
    "    \n",
    "    history = {'loss': [], 'weights_norm': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Predicción\n",
    "        y_pred = X @ weights + bias\n",
    "        \n",
    "        # Loss (MSE)\n",
    "        loss = np.mean((y - y_pred)**2)\n",
    "        \n",
    "        # Gradientes\n",
    "        dw = -(2/n_samples) * X.T @ (y - y_pred)\n",
    "        db = -(2/n_samples) * np.sum(y - y_pred)\n",
    "        \n",
    "        # Update\n",
    "        weights -= learning_rate * dw\n",
    "        bias -= learning_rate * db\n",
    "        \n",
    "        # Guardar historia\n",
    "        history['loss'].append(loss)\n",
    "        history['weights_norm'].append(linalg.norm(weights))\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch:3d}: Loss = {loss:.6f}, ||w|| = {linalg.norm(weights):.4f}')\n",
    "    \n",
    "    return weights, bias, history\n",
    "\n",
    "# Generar datos\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(1000, 5)\n",
    "true_weights = np.array([2, -1, 0.5, 3, -2])\n",
    "y = X @ true_weights + np.random.randn(1000) * 0.5\n",
    "\n",
    "# Entrenar\n",
    "with mlflow.start_run(run_name='custom-gradient-descent'):\n",
    "    weights, bias, history = custom_gradient_descent(X, y, learning_rate=0.01, epochs=100)\n",
    "    \n",
    "    mlflow.log_params({'learning_rate': 0.01, 'epochs': 100})\n",
    "    mlflow.log_metric('final_loss', history['loss'][-1])\n",
    "    mlflow.log_metric('weights_norm', linalg.norm(weights))\n",
    "    \n",
    "    print(f'\\nPesos aprendidos: {weights}')\n",
    "    print(f'Pesos verdaderos: {true_weights}')\n",
    "    print(f'Error: {linalg.norm(weights - true_weights):.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Análisis de Correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos correlacionados\n",
    "n = 500\n",
    "x1 = np.random.randn(n)\n",
    "x2 = 0.8 * x1 + 0.2 * np.random.randn(n)\n",
    "x3 = -0.5 * x1 + 0.5 * np.random.randn(n)\n",
    "x4 = np.random.randn(n)\n",
    "\n",
    "# Tests de correlación\n",
    "pearson_corr, pearson_p = stats.pearsonr(x1, x2)\n",
    "spearman_corr, spearman_p = stats.spearmanr(x1, x2)\n",
    "kendall_corr, kendall_p = stats.kendalltau(x1, x2)\n",
    "\n",
    "print('\\nAnálisis de Correlación (x1 vs x2):')\n",
    "print(f'Pearson:  r = {pearson_corr:.4f}, p = {pearson_p:.4e}')\n",
    "print(f'Spearman: ρ = {spearman_corr:.4f}, p = {spearman_p:.4e}')\n",
    "print(f'Kendall:  τ = {kendall_corr:.4f}, p = {kendall_p:.4e}')\n",
    "\n",
    "# Matriz de correlación\n",
    "data_matrix = np.column_stack([x1, x2, x3, x4])\n",
    "corr_matrix = np.corrcoef(data_matrix.T)\n",
    "\n",
    "# Visualizar\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            xticklabels=['X1', 'X2', 'X3', 'X4'],\n",
    "            yticklabels=['X1', 'X2', 'X3', 'X4'])\n",
    "plt.title('Matriz de Correlación', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_matrix.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "### SciPy en ML\n",
    "\n",
    "**Casos de Uso:**\n",
    "- ✅ Optimización de hiperparámetros\n",
    "- ✅ Tests estadísticos para validación\n",
    "- ✅ Implementación de algoritmos custom\n",
    "- ✅ Análisis numérico avanzado\n",
    "\n",
    "**Ventajas:**\n",
    "- Altamente optimizado (BLAS/LAPACK)\n",
    "- Funciones estables numéricamente\n",
    "- Amplia variedad de algoritmos\n",
    "\n",
    "**Integración con Spark:**\n",
    "- Usar en UDFs para operaciones complejas\n",
    "- Procesar particiones con operaciones matemáticas\n",
    "- Combinar con Spark ML para pipelines híbridos\n",
    "\n",
    "### Ejercicios\n",
    "1. Implementar PCA desde cero con SVD\n",
    "2. Crear optimizer custom para redes neuronales\n",
    "3. Implementar test de hipótesis distribuido\n",
    "4. Calcular distancias de Mahalanobis en Spark\n",
    "5. Implementar kernel methods con SciPy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
