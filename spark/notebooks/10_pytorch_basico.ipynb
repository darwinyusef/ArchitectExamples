{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 - PyTorch B√°sico: Neural Networks Fundamentales\n",
    "\n",
    "## üéØ Objetivos\n",
    "- Entender los conceptos fundamentales de PyTorch\n",
    "- Trabajar con tensores y operaciones b√°sicas\n",
    "- Crear redes neuronales desde cero\n",
    "- Entrenar modelos con diferentes optimizadores\n",
    "- Evaluar y guardar modelos\n",
    "\n",
    "## üìö Tecnolog√≠as\n",
    "- **PyTorch**: Framework de deep learning\n",
    "- **torchvision**: Datasets y transformaciones\n",
    "- **matplotlib**: Visualizaci√≥n\n",
    "\n",
    "## ‚≠ê Complejidad: B√°sico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalaci√≥n y Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar PyTorch y dependencias\n",
    "!pip install torch torchvision torchaudio matplotlib numpy pandas scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification, make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Configurar device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nüñ•Ô∏è Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tensores: El Coraz√≥n de PyTorch\n",
    "\n",
    "Los tensores son arrays multidimensionales similares a NumPy pero con soporte para GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tensores de diferentes formas\n",
    "print(\"üìä Creaci√≥n de Tensores:\\n\")\n",
    "\n",
    "# Tensor desde lista\n",
    "t1 = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(f\"1. Desde lista: {t1}\")\n",
    "\n",
    "# Tensor de ceros\n",
    "t2 = torch.zeros(3, 4)\n",
    "print(f\"\\n2. Ceros (3x4):\\n{t2}\")\n",
    "\n",
    "# Tensor de unos\n",
    "t3 = torch.ones(2, 3)\n",
    "print(f\"\\n3. Unos (2x3):\\n{t3}\")\n",
    "\n",
    "# Tensor aleatorio\n",
    "t4 = torch.randn(2, 3)  # Distribuci√≥n normal\n",
    "print(f\"\\n4. Aleatorio normal (2x3):\\n{t4}\")\n",
    "\n",
    "# Tensor desde NumPy\n",
    "np_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "t5 = torch.from_numpy(np_array)\n",
    "print(f\"\\n5. Desde NumPy:\\n{t5}\")\n",
    "\n",
    "# Informaci√≥n del tensor\n",
    "print(f\"\\nüìä Informaci√≥n del tensor:\")\n",
    "print(f\"   Shape: {t4.shape}\")\n",
    "print(f\"   Dtype: {t4.dtype}\")\n",
    "print(f\"   Device: {t4.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Operaciones con Tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operaciones matem√°ticas\n",
    "a = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "b = torch.tensor([5, 6, 7, 8], dtype=torch.float32)\n",
    "\n",
    "print(\"üî¢ Operaciones Matem√°ticas:\\n\")\n",
    "print(f\"a = {a}\")\n",
    "print(f\"b = {b}\")\n",
    "print(f\"\\nSuma: a + b = {a + b}\")\n",
    "print(f\"Resta: a - b = {a - b}\")\n",
    "print(f\"Multiplicaci√≥n: a * b = {a * b}\")\n",
    "print(f\"Divisi√≥n: a / b = {a / b}\")\n",
    "print(f\"Potencia: a ** 2 = {a ** 2}\")\n",
    "\n",
    "# Operaciones matriciales\n",
    "A = torch.randn(3, 4)\n",
    "B = torch.randn(4, 5)\n",
    "C = torch.matmul(A, B)  # Multiplicaci√≥n matricial\n",
    "\n",
    "print(f\"\\nüî¢ Multiplicaci√≥n Matricial:\")\n",
    "print(f\"   A shape: {A.shape}\")\n",
    "print(f\"   B shape: {B.shape}\")\n",
    "print(f\"   C = A @ B shape: {C.shape}\")\n",
    "\n",
    "# Operaciones de agregaci√≥n\n",
    "print(f\"\\nüìä Agregaciones:\")\n",
    "print(f\"   Sum: {a.sum()}\")\n",
    "print(f\"   Mean: {a.mean()}\")\n",
    "print(f\"   Max: {a.max()}\")\n",
    "print(f\"   Min: {a.min()}\")\n",
    "print(f\"   Std: {a.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Autograd: Diferenciaci√≥n Autom√°tica\n",
    "\n",
    "PyTorch calcula gradientes autom√°ticamente para el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tensor con requires_grad=True para tracking de gradientes\n",
    "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "print(f\"x = {x}\")\n",
    "\n",
    "# Operaci√≥n: y = x^2 + 3x + 1\n",
    "y = x**2 + 3*x + 1\n",
    "print(f\"y = x^2 + 3x + 1 = {y}\")\n",
    "\n",
    "# Calcular suma para backpropagation\n",
    "z = y.sum()\n",
    "print(f\"z = sum(y) = {z}\")\n",
    "\n",
    "# Backward: calcular gradientes\n",
    "z.backward()\n",
    "\n",
    "# El gradiente de z respecto a x es dy/dx = 2x + 3\n",
    "print(f\"\\nüìä Gradientes:\")\n",
    "print(f\"   dz/dx = {x.grad}\")\n",
    "print(f\"   Esperado (2x + 3) para x=[2,3]: {2*x.data + 3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Red Neuronal Simple: Clasificaci√≥n Binaria\n",
    "\n",
    "Crearemos una red neuronal para clasificaci√≥n binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos sint√©ticos\n",
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)\n",
    "\n",
    "# Normalizar\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convertir a tensores\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "# Visualizar datos\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='viridis', alpha=0.6)\n",
    "plt.title('Training Data')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='viridis', alpha=0.6)\n",
    "plt.title('Test Data')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üìä Dataset:\")\n",
    "print(f\"   Train: {X_train.shape}\")\n",
    "print(f\"   Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Definir la Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir arquitectura de la red\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Capas\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward pass\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Crear modelo\n",
    "input_size = 2  # 2 features\n",
    "hidden_size = 16\n",
    "output_size = 2  # 2 clases\n",
    "\n",
    "model = SimpleNN(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "print(\"üß† Arquitectura de la Red:\\n\")\n",
    "print(model)\n",
    "\n",
    "# Contar par√°metros\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nüìä Par√°metros:\")\n",
    "print(f\"   Total: {total_params:,}\")\n",
    "print(f\"   Entrenables: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar entrenamiento\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Mover datos a device\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "# Historial de entrenamiento\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "# Entrenamiento\n",
    "num_epochs = 100\n",
    "\n",
    "print(\"üöÄ Iniciando entrenamiento...\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Modo entrenamiento\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Calcular accuracy\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    train_acc = (predicted == y_train).sum().item() / y_train.size(0)\n",
    "    \n",
    "    # Evaluaci√≥n en test\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test)\n",
    "        test_loss = criterion(test_outputs, y_test)\n",
    "        _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "        test_acc = (test_predicted == y_test).sum().item() / y_test.size(0)\n",
    "    \n",
    "    # Guardar m√©tricas\n",
    "    train_losses.append(loss.item())\n",
    "    test_losses.append(test_loss.item())\n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)\n",
    "    \n",
    "    # Imprimir progreso\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        print(f\"  Train Loss: {loss.item():.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"  Test Loss: {test_loss.item():.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Entrenamiento completado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualizaci√≥n del Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar p√©rdida y accuracy\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Loss\n",
    "ax1.plot(train_losses, label='Train Loss', linewidth=2)\n",
    "ax1.plot(test_losses, label='Test Loss', linewidth=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Test Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "ax2.plot(train_accs, label='Train Accuracy', linewidth=2)\n",
    "ax2.plot(test_accs, label='Test Accuracy', linewidth=2)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Training and Test Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üìä Resultados finales:\")\n",
    "print(f\"   Train Accuracy: {train_accs[-1]:.4f}\")\n",
    "print(f\"   Test Accuracy: {test_accs[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualizaci√≥n de Fronteras de Decisi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear grid para visualizar fronteras de decisi√≥n\n",
    "def plot_decision_boundary(model, X, y):\n",
    "    # Mover a CPU para plotting\n",
    "    X = X.cpu().numpy()\n",
    "    y = y.cpu().numpy()\n",
    "    \n",
    "    # Crear mesh\n",
    "    h = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Predecir en todo el grid\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        Z = model(torch.FloatTensor(np.c_[xx.ravel(), yy.ravel()]).to(device))\n",
    "        Z = torch.argmax(Z, dim=1).cpu().numpy()\n",
    "    \n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap='viridis')\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', edgecolors='black', s=50)\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.title('Decision Boundary')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "plot_decision_boundary(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Guardar y Cargar Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo completo\n",
    "torch.save(model.state_dict(), 'simple_nn_model.pth')\n",
    "print(\"‚úÖ Modelo guardado: simple_nn_model.pth\")\n",
    "\n",
    "# Guardar checkpoint completo (modelo + optimizador + √©poca)\n",
    "checkpoint = {\n",
    "    'epoch': num_epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_loss': train_losses[-1],\n",
    "    'test_loss': test_losses[-1],\n",
    "    'train_acc': train_accs[-1],\n",
    "    'test_acc': test_accs[-1]\n",
    "}\n",
    "torch.save(checkpoint, 'simple_nn_checkpoint.pth')\n",
    "print(\"‚úÖ Checkpoint guardado: simple_nn_checkpoint.pth\")\n",
    "\n",
    "# Cargar modelo\n",
    "loaded_model = SimpleNN(input_size, hidden_size, output_size).to(device)\n",
    "loaded_model.load_state_dict(torch.load('simple_nn_model.pth'))\n",
    "loaded_model.eval()\n",
    "print(\"\\n‚úÖ Modelo cargado exitosamente\")\n",
    "\n",
    "# Verificar que funciona\n",
    "with torch.no_grad():\n",
    "    test_outputs = loaded_model(X_test)\n",
    "    _, predicted = torch.max(test_outputs, 1)\n",
    "    accuracy = (predicted == y_test).sum().item() / y_test.size(0)\n",
    "    print(f\"üìä Accuracy del modelo cargado: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Ejemplo con MNIST (Dataset Cl√°sico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"üìä MNIST Dataset:\")\n",
    "print(f\"   Train samples: {len(train_dataset)}\")\n",
    "print(f\"   Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Visualizar algunos ejemplos\n",
    "examples = iter(train_loader)\n",
    "images, labels = next(examples)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(images[i].squeeze(), cmap='gray')\n",
    "    ax.set_title(f'Label: {labels[i]}')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Red para MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Crear modelo MNIST\n",
    "mnist_model = MNISTNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mnist_model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"üß† Modelo MNIST:\")\n",
    "print(mnist_model)\n",
    "print(f\"\\nüìä Par√°metros: {sum(p.numel() for p in mnist_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar MNIST (solo 5 √©pocas para demo)\n",
    "num_epochs = 5\n",
    "\n",
    "print(\"üöÄ Entrenando MNIST...\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    mnist_model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = mnist_model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    # Evaluaci√≥n\n",
    "    mnist_model.eval()\n",
    "    test_loss = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = mnist_model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            _, predicted = output.max(1)\n",
    "            test_total += target.size(0)\n",
    "            test_correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"  Train Loss: {train_loss/len(train_loader):.4f}, Acc: {100.*correct/total:.2f}%\")\n",
    "    print(f\"  Test Loss: {test_loss/len(test_loader):.4f}, Acc: {100.*test_correct/test_total:.2f}%\")\n",
    "\n",
    "print(\"\\n‚úÖ Entrenamiento MNIST completado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Predicci√≥n en MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones en ejemplos del test set\n",
    "mnist_model.eval()\n",
    "\n",
    "# Obtener batch de test\n",
    "test_examples = iter(test_loader)\n",
    "test_images, test_labels = next(test_examples)\n",
    "\n",
    "# Predecir\n",
    "with torch.no_grad():\n",
    "    test_images = test_images.to(device)\n",
    "    outputs = mnist_model(test_images)\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "# Visualizar predicciones\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(test_images[i].cpu().squeeze(), cmap='gray')\n",
    "    pred_label = predictions[i].cpu().item()\n",
    "    true_label = test_labels[i].item()\n",
    "    color = 'green' if pred_label == true_label else 'red'\n",
    "    ax.set_title(f'Pred: {pred_label} | True: {true_label}', color=color)\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Resumen y Mejores Pr√°cticas\n",
    "\n",
    "### ‚úÖ Conceptos Clave:\n",
    "1. **Tensores**: Arrays multidimensionales con soporte GPU\n",
    "2. **Autograd**: Diferenciaci√≥n autom√°tica para gradientes\n",
    "3. **nn.Module**: Clase base para redes neuronales\n",
    "4. **forward()**: Define el flujo de datos\n",
    "5. **Loss Functions**: CrossEntropyLoss, MSELoss, etc.\n",
    "6. **Optimizers**: Adam, SGD, RMSprop, etc.\n",
    "7. **DataLoader**: Manejo eficiente de datos en batches\n",
    "\n",
    "### üí° Mejores Pr√°cticas:\n",
    "- ‚úÖ Usa GPU cuando est√© disponible (`.to(device)`)\n",
    "- ‚úÖ Normaliza tus datos antes de entrenar\n",
    "- ‚úÖ Usa `model.train()` y `model.eval()` apropiadamente\n",
    "- ‚úÖ Usa `torch.no_grad()` para inferencia (ahorra memoria)\n",
    "- ‚úÖ Guarda checkpoints durante el entrenamiento\n",
    "- ‚úÖ Monitorea m√©tricas en train y test\n",
    "- ‚úÖ Usa dropout para regularizaci√≥n\n",
    "- ‚úÖ Experimenta con diferentes arquitecturas y hiperpar√°metros\n",
    "\n",
    "### üöÄ Pr√≥ximos Pasos:\n",
    "- Redes Convolucionales (CNN) para im√°genes\n",
    "- Redes Recurrentes (RNN/LSTM) para secuencias\n",
    "- Transfer Learning con modelos pre-entrenados\n",
    "- Integraci√≥n con MLflow para tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéâ Tutorial de PyTorch B√°sico completado!\")\n",
    "print(f\"\\nüìä Resumen:\")\n",
    "print(f\"   Device usado: {device}\")\n",
    "print(f\"   Modelo Simple NN - Test Acc: {test_accs[-1]:.4f}\")\n",
    "print(f\"   Modelo MNIST - Test Acc: {100.*test_correct/test_total:.2f}%\")\n",
    "print(f\"\\nüìÅ Archivos guardados:\")\n",
    "print(f\"   - simple_nn_model.pth\")\n",
    "print(f\"   - simple_nn_checkpoint.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
