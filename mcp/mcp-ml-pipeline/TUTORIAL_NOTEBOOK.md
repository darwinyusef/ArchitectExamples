# ğŸ““ Tutorial Interactivo: Spark + Airflow + MLflow

Notebook Jupyter completo que te guÃ­a paso a paso en el uso del pipeline de ML.

## ğŸ“‹ Contenido del Notebook

### 1. Setup Inicial
- VerificaciÃ³n de servicios
- InstalaciÃ³n de dependencias
- ConfiguraciÃ³n de entorno

### 2. IntroducciÃ³n a Spark
- Â¿QuÃ© es Apache Spark?
- Arquitectura de Spark
- Crear SparkSession
- Spark UI

### 3. Procesamiento de Datos con Spark
- Crear dataset de ejemplo (10,000 registros de ventas)
- Convertir pandas â†’ Spark DataFrame
- **Operaciones bÃ¡sicas**:
  - Filtrado
  - Agregaciones
  - Joins
  - Window Functions
- AnÃ¡lisis temporal con visualizaciones
- Guardar datos en Parquet

### 4. Entrenamiento de Modelos con Spark MLlib
- PreparaciÃ³n de features
- Feature engineering (indexing, vectorizaciÃ³n, scaling)
- DivisiÃ³n train/test
- **Entrenar 2 modelos**:
  - RegresiÃ³n Lineal
  - Random Forest
- EvaluaciÃ³n con mÃ©tricas (RMSE, RÂ², MAE)
- ComparaciÃ³n de modelos con grÃ¡ficos

### 5. Tracking con MLflow
- Configurar MLflow
- Registrar experimentos
- Log de parÃ¡metros y mÃ©tricas
- Guardar modelos
- Comparar experimentos en MLflow UI

### 6. OrquestaciÃ³n con Airflow
- Listar DAGs disponibles
- Disparar DAGs programÃ¡ticamente
- Monitorear estado en tiempo real
- CÃ³digo de ejemplo para DAG personalizado

### 7. Pipeline Completo End-to-End
- FunciÃ³n que integra todo:
  1. Carga de datos
  2. Procesamiento con Spark
  3. Entrenamiento de modelo
  4. EvaluaciÃ³n
  5. Registro en MLflow
- Ejecutar pipeline completo con un solo comando

### 8. Monitoreo y Debugging
- URLs de monitoreo
- InformaciÃ³n de Spark Context
- EstadÃ­sticas de ejecuciÃ³n
- Cleanup de recursos

## ğŸš€ CÃ³mo Usar el Notebook

### OpciÃ³n 1: Jupyter Notebook

```bash
# 1. AsegÃºrate de que los servicios estÃ©n corriendo
cd mcp-ml-pipeline
docker-compose up -d

# 2. Esperar 2-3 minutos para inicializaciÃ³n
sleep 120

# 3. Instalar Jupyter
pip install jupyter notebook

# 4. Iniciar Jupyter
jupyter notebook

# 5. Abrir tutorial_spark_airflow.ipynb
```

### OpciÃ³n 2: JupyterLab

```bash
# Instalar JupyterLab
pip install jupyterlab

# Iniciar
jupyter lab

# Navegar a tutorial_spark_airflow.ipynb
```

### OpciÃ³n 3: VS Code

```bash
# 1. Instalar extensiÃ³n de Jupyter en VS Code
# 2. Abrir tutorial_spark_airflow.ipynb
# 3. Seleccionar kernel de Python
# 4. Ejecutar celdas
```

## ğŸ“Š Requisitos

### Servicios (deben estar corriendo)

```bash
# Verificar que todos los servicios estÃ©n activos
docker-compose ps

# DeberÃ­as ver:
# - ml-postgres (PostgreSQL)
# - ml-mlflow (MLflow)
# - ml-airflow-webserver (Airflow Web)
# - ml-airflow-scheduler (Airflow Scheduler)
# - ml-spark-master (Spark Master)
# - ml-spark-worker (Spark Worker)
```

### Dependencias Python

El notebook instala automÃ¡ticamente las dependencias, pero tambiÃ©n puedes instalarlas manualmente:

```bash
pip install pyspark mlflow pandas numpy matplotlib seaborn scikit-learn jupyter
```

## ğŸ¯ Flujo del Tutorial

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              INICIO DEL TUTORIAL                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Setup y VerificaciÃ³n de Servicios               â”‚
â”‚     âœ“ Airflow, MLflow, Spark                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Spark Basics                                    â”‚
â”‚     â€¢ Crear SparkSession                            â”‚
â”‚     â€¢ DataFrames                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Procesamiento de Datos                          â”‚
â”‚     â€¢ 10K registros de ventas                       â”‚
â”‚     â€¢ Filtros, Agregaciones, Joins                 â”‚
â”‚     â€¢ Window Functions                              â”‚
â”‚     â€¢ AnÃ¡lisis Temporal                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Machine Learning con MLlib                      â”‚
â”‚     â€¢ Feature Engineering                           â”‚
â”‚     â€¢ Train/Test Split                              â”‚
â”‚     â€¢ RegresiÃ³n Lineal                             â”‚
â”‚     â€¢ Random Forest                                 â”‚
â”‚     â€¢ EvaluaciÃ³n y ComparaciÃ³n                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. MLflow Tracking                                 â”‚
â”‚     â€¢ Log experimentos                              â”‚
â”‚     â€¢ MÃ©tricas: RMSE, RÂ², MAE                      â”‚
â”‚     â€¢ Guardar modelos                               â”‚
â”‚     â€¢ Comparar en UI                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. Airflow Orchestration                           â”‚
â”‚     â€¢ Listar DAGs                                   â”‚
â”‚     â€¢ Trigger DAGs                                  â”‚
â”‚     â€¢ Monitorear ejecuciÃ³n                          â”‚
â”‚     â€¢ Crear DAG personalizado                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. Pipeline End-to-End                             â”‚
â”‚     â€¢ FunciÃ³n que integra todo                      â”‚
â”‚     â€¢ AutomatizaciÃ³n completa                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  8. Monitoreo y Debugging                           â”‚
â”‚     â€¢ Spark UI, Airflow UI, MLflow UI              â”‚
â”‚     â€¢ EstadÃ­sticas de recursos                      â”‚
â”‚     â€¢ Cleanup                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              âœ… TUTORIAL COMPLETADO                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ˆ Resultados Esperados

Al completar el notebook, habrÃ¡s:

### âœ… Procesado Datos
- 10,000 registros de ventas
- AnÃ¡lisis por categorÃ­a, regiÃ³n, tiempo
- GrÃ¡ficos de tendencias

### âœ… Entrenado Modelos
- 2 modelos de ML (Linear Regression, Random Forest)
- MÃ©tricas de evaluaciÃ³n
- ComparaciÃ³n de rendimiento

### âœ… Registrado en MLflow
- 2+ experimentos
- ParÃ¡metros, mÃ©tricas y modelos guardados
- Visible en http://localhost:5000

### âœ… Orquestado con Airflow
- DAG ejecutado
- Tareas monitoreadas
- CÃ³digo de DAG personalizado

### âœ… Creado Pipeline Completo
- FunciÃ³n reutilizable
- AutomatizaciÃ³n end-to-end
- Listo para producciÃ³n

## ğŸ“ Lo que AprenderÃ¡s

### Nivel BÃ¡sico
- âœ“ Conceptos de Spark (Driver, Executors, Partitions)
- âœ“ DataFrames y operaciones bÃ¡sicas
- âœ“ Leer/escribir datos en Parquet

### Nivel Intermedio
- âœ“ Feature engineering con MLlib
- âœ“ Entrenamiento de modelos
- âœ“ Tracking de experimentos con MLflow
- âœ“ OrquestaciÃ³n con Airflow

### Nivel Avanzado
- âœ“ Window Functions
- âœ“ Pipeline completo end-to-end
- âœ“ Monitoreo y optimizaciÃ³n
- âœ“ IntegraciÃ³n de mÃºltiples herramientas

## ğŸ” Visualizaciones Incluidas

El notebook genera grÃ¡ficos automÃ¡ticamente:

1. **Ventas por Mes**
   - Bar chart de totales
   - Line chart de ticket promedio

2. **ComparaciÃ³n de Modelos**
   - RMSE por modelo
   - MAE por modelo
   - RÂ² por modelo

3. **Predicciones vs Real**
   - Tabla comparativa
   - Primeras 10 predicciones

## ğŸ› ï¸ PersonalizaciÃ³n

### Cambiar TamaÃ±o del Dataset

```python
# En la celda de creaciÃ³n de datos
n_records = 50000  # Cambiar de 10000 a 50000
```

### Cambiar Modelo de ML

```python
# En el pipeline completo
result = run_complete_pipeline(model_type='LinearRegression')
# o
result = run_complete_pipeline(model_type='RandomForest')
```

### Agregar MÃ¡s Features

```python
# Modificar feature_cols
feature_cols = [
    'cantidad', 'precio_unitario', 'descuento',
    'mes', 'dia_semana', 'hora',
    'categoria_idx', 'region_idx',
    'nueva_feature_1',  # Agregar nueva
    'nueva_feature_2'   # Agregar nueva
]
```

### Cambiar HiperparÃ¡metros

```python
# Random Forest
rf = RandomForestRegressor(
    numTrees=50,      # Cambiar de 20 a 50
    maxDepth=10,      # Cambiar de 5 a 10
    seed=42
)

# Linear Regression
lr = LinearRegression(
    maxIter=20,       # Cambiar de 10 a 20
    regParam=0.1      # Cambiar de 0.01 a 0.1
)
```

## ğŸ› Troubleshooting

### Error: "Servicios no disponibles"

```bash
# Verificar que los servicios estÃ©n corriendo
docker-compose ps

# Si no estÃ¡n corriendo, iniciar
docker-compose up -d

# Esperar 2-3 minutos
sleep 120
```

### Error: "Spark Session not found"

```bash
# Reiniciar kernel de Jupyter
# Menu: Kernel â†’ Restart Kernel

# Re-ejecutar celdas desde el inicio
```

### Error: "MLflow connection refused"

```bash
# Verificar que MLflow estÃ© corriendo
curl http://localhost:5000/health

# Ver logs
docker-compose logs mlflow
```

### Error: "Airflow API 401 Unauthorized"

```bash
# Verificar credenciales en el cÃ³digo
AIRFLOW_AUTH = HTTPBasicAuth("airflow", "airflow")

# Verificar que Airflow estÃ© corriendo
curl http://localhost:8080/health
```

### Jupyter se queda sin memoria

```bash
# Detener kernel
# Menu: Kernel â†’ Restart & Clear Output

# Limpiar cache de Spark
train_data.unpersist()
test_data.unpersist()

# O reducir tamaÃ±o del dataset
n_records = 5000  # En lugar de 10000
```

## ğŸ“š Recursos Adicionales

### Dentro del Notebook
- CÃ³digo comentado en cada celda
- Explicaciones detalladas
- Links a documentaciÃ³n oficial

### DocumentaciÃ³n Externa
- [Spark SQL Guide](https://spark.apache.org/docs/latest/sql-programming-guide.html)
- [MLlib Guide](https://spark.apache.org/docs/latest/ml-guide.html)
- [MLflow Tracking](https://mlflow.org/docs/latest/tracking.html)
- [Airflow API](https://airflow.apache.org/docs/apache-airflow/stable/stable-rest-api-ref.html)

### Ejemplos de CÃ³digo
- DAG personalizado incluido
- Pipeline completo reutilizable
- Funciones de monitoreo

## ğŸ¯ PrÃ³ximos Pasos

DespuÃ©s de completar el tutorial:

1. **Experimenta**:
   - Modifica parÃ¡metros
   - Prueba otros modelos
   - Agrega mÃ¡s features

2. **Escala**:
   - Usa datasets mÃ¡s grandes
   - Conecta a cluster Spark real
   - Implementa en producciÃ³n

3. **Optimiza**:
   - Tuning de hiperparÃ¡metros
   - OptimizaciÃ³n de Spark
   - ParalelizaciÃ³n avanzada

4. **Automatiza**:
   - Crea tus propios DAGs
   - Implementa CI/CD
   - Agrega alertas

## â±ï¸ Tiempo Estimado

- **Setup**: 5 minutos
- **EjecuciÃ³n completa**: 15-20 minutos
- **Con experimentaciÃ³n**: 1-2 horas

## ğŸ“ Notas

- El notebook usa datos simulados (no requiere fuentes externas)
- Todas las dependencias se instalan automÃ¡ticamente
- Compatible con Python 3.11+
- Requiere ~4GB RAM libre

---

**Â¡Disfruta aprendiendo Spark + Airflow + MLflow!** ğŸš€

Para preguntas o problemas, consulta el README principal del proyecto.
