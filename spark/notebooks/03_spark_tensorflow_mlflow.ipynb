{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark + TensorFlow + MLflow\n",
    "\n",
    "Este notebook demuestra:\n",
    "- Integración de TensorFlow con Spark\n",
    "- Procesamiento distribuido de datos\n",
    "- Entrenamiento de modelos con TensorFlow 2.x\n",
    "- Tracking con MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pyspark.sql import SparkSession\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "print(f'GPU available: {tf.test.is_gpu_available()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración\n",
    "spark = SparkSession.builder.appName('TensorFlow-Spark').master('local[*]').getOrCreate()\n",
    "mlflow.set_tracking_uri('http://localhost:5000')\n",
    "mlflow.set_experiment('spark-tensorflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples=10000, n_features=20, noise=10, random_state=42)\n",
    "df = spark.createDataFrame(pd.DataFrame(X))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo TensorFlow\n",
    "def create_model(input_dim):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_dim=input_dim),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "model = create_model(X.shape[1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar con MLflow\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "with mlflow.start_run(run_name='tensorflow-regression') as run:\n",
    "    # Log params\n",
    "    mlflow.log_params({\n",
    "        'layers': '128-64-32',\n",
    "        'dropout': 0.3,\n",
    "        'optimizer': 'adam',\n",
    "        'batch_size': 32,\n",
    "        'epochs': 50\n",
    "    })\n",
    "    \n",
    "    # Callbacks\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    # Train\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "    mlflow.log_metrics({'test_loss': test_loss, 'test_mae': test_mae})\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.tensorflow.log_model(model, 'model')\n",
    "    \n",
    "    print(f'Test MAE: {test_mae:.4f}')\n",
    "    print(f'Run ID: {run.info.run_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "- TensorFlow 2.x se integra fácilmente con Spark\n",
    "- MLflow trackea automáticamente métricas de Keras\n",
    "- Ideal para modelos de deep learning en producción\n",
    "\n",
    "### Ejercicios\n",
    "1. Implementar un modelo CNN para imágenes\n",
    "2. Usar TensorFlow Datasets con Spark\n",
    "3. Implementar transfer learning con modelos pre-entrenados\n",
    "4. Crear un pipeline de preprocesamiento con tf.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
