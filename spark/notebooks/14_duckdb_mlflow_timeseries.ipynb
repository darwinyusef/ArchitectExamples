{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14 - DuckDB + MLflow: Time Series Forecasting con Experiment Tracking\n",
    "\n",
    "## üéØ Objetivos\n",
    "- Integrar DuckDB con MLflow para time series\n",
    "- Procesar datos con DuckDB y trackear experimentos con MLflow\n",
    "- Comparar m√∫ltiples modelos de forecasting\n",
    "- Optimizaci√≥n de hiperpar√°metros\n",
    "- Registro y versionado de modelos\n",
    "- Deployment y predicciones en producci√≥n\n",
    "\n",
    "## üìö Tecnolog√≠as\n",
    "- **DuckDB**: SQL analytics y procesamiento de datos\n",
    "- **MLflow**: Experiment tracking y model registry\n",
    "- **Prophet**: Facebook's forecasting library\n",
    "- **ARIMA**: Statistical forecasting\n",
    "- **LSTM**: Deep learning para series temporales\n",
    "\n",
    "## ‚≠ê Complejidad: Intermedio/Avanzado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalaci√≥n y Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependencias\n",
    "!pip install duckdb mlflow pandas numpy matplotlib seaborn plotly prophet statsmodels scikit-learn torch -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.pytorch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Time series libraries\n",
    "from prophet import Prophet\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# PyTorch for LSTM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print(f\"‚úÖ DuckDB version: {duckdb.__version__}\")\n",
    "print(f\"‚úÖ MLflow version: {mlflow.__version__}\")\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configurar MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar MLflow\n",
    "mlflow.set_tracking_uri(\"./mlruns\")\n",
    "experiment_name = \"timeseries_forecasting_duckdb\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"‚úÖ MLflow configurado\")\n",
    "print(f\"üìä Experimento: {experiment_name}\")\n",
    "print(f\"üìÅ Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"\\nüí° Para ver la UI ejecuta: mlflow ui --port 5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generar y Procesar Datos con DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a DuckDB\n",
    "con = duckdb.connect(':memory:')\n",
    "\n",
    "# Generar serie temporal sint√©tica con m√∫ltiples componentes\n",
    "np.random.seed(42)\n",
    "\n",
    "# 3 a√±os de datos diarios\n",
    "start_date = datetime.now() - timedelta(days=1095)\n",
    "dates = pd.date_range(start=start_date, periods=1095, freq='D')\n",
    "\n",
    "# Componentes\n",
    "trend = np.linspace(1000, 2500, len(dates))\n",
    "seasonal_yearly = 300 * np.sin(2 * np.pi * np.arange(len(dates)) / 365.25)\n",
    "seasonal_weekly = 150 * np.sin(2 * np.pi * np.arange(len(dates)) / 7)\n",
    "noise = np.random.normal(0, 80, len(dates))\n",
    "\n",
    "# Eventos especiales (Black Friday, Navidad, etc.)\n",
    "special_events = np.zeros(len(dates))\n",
    "for i in range(len(dates)):\n",
    "    if dates[i].month == 11 and 20 <= dates[i].day <= 27:  # Black Friday\n",
    "        special_events[i] = 800\n",
    "    elif dates[i].month == 12 and 15 <= dates[i].day <= 25:  # Navidad\n",
    "        special_events[i] = 600\n",
    "\n",
    "# Serie final\n",
    "sales = trend + seasonal_yearly + seasonal_weekly + noise + special_events\n",
    "sales = np.maximum(sales, 0)\n",
    "\n",
    "# Crear DataFrame y guardarlo\n",
    "df = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'sales': sales,\n",
    "    'day_of_week': dates.dayofweek,\n",
    "    'month': dates.month,\n",
    "    'year': dates.year,\n",
    "    'quarter': dates.quarter,\n",
    "    'is_weekend': dates.dayofweek.isin([5, 6]).astype(int),\n",
    "    'is_month_start': dates.is_month_start.astype(int),\n",
    "    'is_month_end': dates.is_month_end.astype(int)\n",
    "})\n",
    "\n",
    "print(f\"üìä Datos generados: {len(df)} d√≠as\")\n",
    "print(f\"üìä Rango: {df['date'].min()} a {df['date'].max()}\")\n",
    "print(f\"\\nüìä Primeras filas:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. An√°lisis Exploratorio con DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis agregado por mes\n",
    "monthly_stats = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        year,\n",
    "        month,\n",
    "        COUNT(*) as days,\n",
    "        ROUND(AVG(sales), 2) as avg_sales,\n",
    "        ROUND(SUM(sales), 2) as total_sales,\n",
    "        ROUND(STDDEV(sales), 2) as stddev_sales,\n",
    "        ROUND(MIN(sales), 2) as min_sales,\n",
    "        ROUND(MAX(sales), 2) as max_sales\n",
    "    FROM df\n",
    "    GROUP BY year, month\n",
    "    ORDER BY year, month\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"üìä Estad√≠sticas Mensuales:\")\n",
    "print(monthly_stats.head(12))\n",
    "\n",
    "# An√°lisis por d√≠a de la semana\n",
    "weekly_pattern = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        day_of_week,\n",
    "        CASE day_of_week\n",
    "            WHEN 0 THEN 'Lunes'\n",
    "            WHEN 1 THEN 'Martes'\n",
    "            WHEN 2 THEN 'Mi√©rcoles'\n",
    "            WHEN 3 THEN 'Jueves'\n",
    "            WHEN 4 THEN 'Viernes'\n",
    "            WHEN 5 THEN 'S√°bado'\n",
    "            WHEN 6 THEN 'Domingo'\n",
    "        END as day_name,\n",
    "        ROUND(AVG(sales), 2) as avg_sales,\n",
    "        COUNT(*) as observations\n",
    "    FROM df\n",
    "    GROUP BY day_of_week\n",
    "    ORDER BY day_of_week\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\nüìä Patr√≥n Semanal:\")\n",
    "print(weekly_pattern)\n",
    "\n",
    "# Detectar outliers con DuckDB\n",
    "outliers = con.execute(\"\"\"\n",
    "    WITH stats AS (\n",
    "        SELECT \n",
    "            AVG(sales) as mean_sales,\n",
    "            STDDEV(sales) as std_sales\n",
    "        FROM df\n",
    "    )\n",
    "    SELECT \n",
    "        date,\n",
    "        sales,\n",
    "        ROUND((sales - s.mean_sales) / s.std_sales, 2) as z_score\n",
    "    FROM df, stats s\n",
    "    WHERE ABS((sales - s.mean_sales) / s.std_sales) > 2.5\n",
    "    ORDER BY ABS((sales - s.mean_sales) / s.std_sales) DESC\n",
    "\"\"\").df()\n",
    "\n",
    "print(f\"\\nüìä Outliers detectados: {len(outliers)}\")\n",
    "if len(outliers) > 0:\n",
    "    print(outliers.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preparar Datos para Modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test usando DuckDB\n",
    "train_size = 0.8\n",
    "split_date = df['date'].iloc[int(len(df) * train_size)]\n",
    "\n",
    "train_df = con.execute(f\"\"\"\n",
    "    SELECT * FROM df\n",
    "    WHERE date < '{split_date}'\n",
    "    ORDER BY date\n",
    "\"\"\").df()\n",
    "\n",
    "test_df = con.execute(f\"\"\"\n",
    "    SELECT * FROM df\n",
    "    WHERE date >= '{split_date}'\n",
    "    ORDER BY date\n",
    "\"\"\").df()\n",
    "\n",
    "print(f\"üìä Train set: {len(train_df)} d√≠as ({train_df['date'].min()} a {train_df['date'].max()})\")\n",
    "print(f\"üìä Test set: {len(test_df)} d√≠as ({test_df['date'].min()} a {test_df['date'].max()})\")\n",
    "\n",
    "# Guardar en Parquet para tracking con MLflow\n",
    "Path('data').mkdir(exist_ok=True)\n",
    "train_df.to_parquet('data/train_timeseries.parquet', index=False)\n",
    "test_df.to_parquet('data/test_timeseries.parquet', index=False)\n",
    "\n",
    "print(\"\\n‚úÖ Datos guardados en Parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modelo 1: Prophet con MLflow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_prophet_model(train_data, test_data, params):\n",
    "    \"\"\"\n",
    "    Entrena modelo Prophet y registra en MLflow\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=\"Prophet_Forecast\"):\n",
    "        \n",
    "        # Log par√°metros\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_param(\"model_type\", \"Prophet\")\n",
    "        mlflow.log_param(\"train_size\", len(train_data))\n",
    "        mlflow.log_param(\"test_size\", len(test_data))\n",
    "        \n",
    "        # Preparar datos para Prophet\n",
    "        prophet_train = train_data[['date', 'sales']].copy()\n",
    "        prophet_train.columns = ['ds', 'y']\n",
    "        \n",
    "        # Entrenar modelo\n",
    "        model = Prophet(\n",
    "            yearly_seasonality=params['yearly_seasonality'],\n",
    "            weekly_seasonality=params['weekly_seasonality'],\n",
    "            daily_seasonality=params['daily_seasonality'],\n",
    "            changepoint_prior_scale=params['changepoint_prior_scale'],\n",
    "            seasonality_prior_scale=params['seasonality_prior_scale']\n",
    "        )\n",
    "        \n",
    "        model.fit(prophet_train)\n",
    "        \n",
    "        # Predicciones\n",
    "        future = model.make_future_dataframe(periods=len(test_data))\n",
    "        forecast = model.predict(future)\n",
    "        \n",
    "        # Extraer predicciones de test\n",
    "        test_predictions = forecast.tail(len(test_data))[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "        test_predictions['y_true'] = test_data['sales'].values\n",
    "        \n",
    "        # M√©tricas\n",
    "        mae = mean_absolute_error(test_predictions['y_true'], test_predictions['yhat'])\n",
    "        rmse = np.sqrt(mean_squared_error(test_predictions['y_true'], test_predictions['yhat']))\n",
    "        r2 = r2_score(test_predictions['y_true'], test_predictions['yhat'])\n",
    "        mape = np.mean(np.abs((test_predictions['y_true'] - test_predictions['yhat']) / test_predictions['y_true'])) * 100\n",
    "        \n",
    "        # Log m√©tricas\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mape\", mape)\n",
    "        \n",
    "        # Visualizaciones\n",
    "        fig = model.plot(forecast)\n",
    "        plt.title('Prophet Forecast')\n",
    "        plt.savefig('prophet_forecast.png', dpi=150, bbox_inches='tight')\n",
    "        mlflow.log_artifact('prophet_forecast.png')\n",
    "        plt.close()\n",
    "        \n",
    "        fig = model.plot_components(forecast)\n",
    "        plt.savefig('prophet_components.png', dpi=150, bbox_inches='tight')\n",
    "        mlflow.log_artifact('prophet_components.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Guardar predicciones\n",
    "        test_predictions.to_csv('prophet_predictions.csv', index=False)\n",
    "        mlflow.log_artifact('prophet_predictions.csv')\n",
    "        \n",
    "        # Log dataset\n",
    "        mlflow.log_artifact('data/train_timeseries.parquet')\n",
    "        mlflow.log_artifact('data/test_timeseries.parquet')\n",
    "        \n",
    "        print(f\"‚úÖ Prophet entrenado\")\n",
    "        print(f\"   MAE: {mae:.2f}\")\n",
    "        print(f\"   RMSE: {rmse:.2f}\")\n",
    "        print(f\"   R¬≤: {r2:.4f}\")\n",
    "        print(f\"   MAPE: {mape:.2f}%\")\n",
    "        \n",
    "        return model, test_predictions, {'mae': mae, 'rmse': rmse, 'r2': r2, 'mape': mape}\n",
    "\n",
    "# Entrenar con diferentes configuraciones\n",
    "prophet_params = {\n",
    "    'yearly_seasonality': True,\n",
    "    'weekly_seasonality': True,\n",
    "    'daily_seasonality': False,\n",
    "    'changepoint_prior_scale': 0.05,\n",
    "    'seasonality_prior_scale': 10.0\n",
    "}\n",
    "\n",
    "prophet_model, prophet_predictions, prophet_metrics = train_prophet_model(train_df, test_df, prophet_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Modelo 2: ARIMA/SARIMA con MLflow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sarima_model(train_data, test_data, params):\n",
    "    \"\"\"\n",
    "    Entrena modelo SARIMA y registra en MLflow\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=\"SARIMA_Forecast\"):\n",
    "        \n",
    "        # Log par√°metros\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_param(\"model_type\", \"SARIMA\")\n",
    "        mlflow.log_param(\"train_size\", len(train_data))\n",
    "        mlflow.log_param(\"test_size\", len(test_data))\n",
    "        \n",
    "        # Entrenar modelo\n",
    "        model = SARIMAX(\n",
    "            train_data['sales'],\n",
    "            order=params['order'],\n",
    "            seasonal_order=params['seasonal_order'],\n",
    "            enforce_stationarity=False,\n",
    "            enforce_invertibility=False\n",
    "        )\n",
    "        \n",
    "        fitted_model = model.fit(disp=False)\n",
    "        \n",
    "        # Predicciones\n",
    "        predictions = fitted_model.forecast(steps=len(test_data))\n",
    "        \n",
    "        # M√©tricas\n",
    "        mae = mean_absolute_error(test_data['sales'], predictions)\n",
    "        rmse = np.sqrt(mean_squared_error(test_data['sales'], predictions))\n",
    "        r2 = r2_score(test_data['sales'], predictions)\n",
    "        mape = np.mean(np.abs((test_data['sales'] - predictions) / test_data['sales'])) * 100\n",
    "        \n",
    "        # Log m√©tricas\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mape\", mape)\n",
    "        mlflow.log_metric(\"aic\", fitted_model.aic)\n",
    "        mlflow.log_metric(\"bic\", fitted_model.bic)\n",
    "        \n",
    "        # Visualizaci√≥n\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        plt.plot(train_data['date'].tail(100), train_data['sales'].tail(100), label='Train (√∫ltimos 100 d√≠as)', linewidth=2)\n",
    "        plt.plot(test_data['date'], test_data['sales'], label='Test (Real)', linewidth=2)\n",
    "        plt.plot(test_data['date'], predictions, label='SARIMA Prediction', linestyle='--', linewidth=2)\n",
    "        plt.title('SARIMA Forecast')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Sales')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig('sarima_forecast.png', dpi=150, bbox_inches='tight')\n",
    "        mlflow.log_artifact('sarima_forecast.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Residuals plot\n",
    "        residuals = test_data['sales'].values - predictions.values\n",
    "        plt.figure(figsize=(14, 4))\n",
    "        plt.plot(test_data['date'], residuals)\n",
    "        plt.axhline(y=0, color='r', linestyle='--')\n",
    "        plt.title('SARIMA Residuals')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Residual')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig('sarima_residuals.png', dpi=150, bbox_inches='tight')\n",
    "        mlflow.log_artifact('sarima_residuals.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Guardar predicciones\n",
    "        pred_df = pd.DataFrame({\n",
    "            'date': test_data['date'],\n",
    "            'y_true': test_data['sales'],\n",
    "            'y_pred': predictions\n",
    "        })\n",
    "        pred_df.to_csv('sarima_predictions.csv', index=False)\n",
    "        mlflow.log_artifact('sarima_predictions.csv')\n",
    "        \n",
    "        print(f\"‚úÖ SARIMA entrenado\")\n",
    "        print(f\"   MAE: {mae:.2f}\")\n",
    "        print(f\"   RMSE: {rmse:.2f}\")\n",
    "        print(f\"   R¬≤: {r2:.4f}\")\n",
    "        print(f\"   MAPE: {mape:.2f}%\")\n",
    "        print(f\"   AIC: {fitted_model.aic:.2f}\")\n",
    "        print(f\"   BIC: {fitted_model.bic:.2f}\")\n",
    "        \n",
    "        return fitted_model, predictions, {'mae': mae, 'rmse': rmse, 'r2': r2, 'mape': mape}\n",
    "\n",
    "# Par√°metros SARIMA: (p,d,q)x(P,D,Q,s)\n",
    "sarima_params = {\n",
    "    'order': (1, 1, 1),  # (p, d, q)\n",
    "    'seasonal_order': (1, 1, 1, 7)  # (P, D, Q, s) - seasonality semanal\n",
    "}\n",
    "\n",
    "sarima_model, sarima_predictions, sarima_metrics = train_sarima_model(train_df, test_df, sarima_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Modelo 3: LSTM con PyTorch y MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset para LSTM\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, sequence_length):\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.sequence_length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx:idx+self.sequence_length]\n",
    "        y = self.data[idx+self.sequence_length]\n",
    "        return x, y\n",
    "\n",
    "# Modelo LSTM\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, dropout=0.2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, input_size)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # Tomar √∫ltima salida\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        prediction = self.fc(last_output)\n",
    "        return prediction\n",
    "\n",
    "def train_lstm_model(train_data, test_data, params):\n",
    "    \"\"\"\n",
    "    Entrena modelo LSTM y registra en MLflow\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=\"LSTM_Forecast\"):\n",
    "        \n",
    "        # Log par√°metros\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_param(\"model_type\", \"LSTM\")\n",
    "        mlflow.log_param(\"train_size\", len(train_data))\n",
    "        mlflow.log_param(\"test_size\", len(test_data))\n",
    "        \n",
    "        # Normalizar datos\n",
    "        train_sales = train_data['sales'].values\n",
    "        train_mean = train_sales.mean()\n",
    "        train_std = train_sales.std()\n",
    "        \n",
    "        train_normalized = (train_sales - train_mean) / train_std\n",
    "        test_normalized = (test_data['sales'].values - train_mean) / train_std\n",
    "        \n",
    "        # Crear datasets\n",
    "        train_dataset = TimeSeriesDataset(train_normalized, params['sequence_length'])\n",
    "        train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "        \n",
    "        # Modelo\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model = LSTMModel(\n",
    "            input_size=1,\n",
    "            hidden_size=params['hidden_size'],\n",
    "            num_layers=params['num_layers'],\n",
    "            dropout=params['dropout']\n",
    "        ).to(device)\n",
    "        \n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "        \n",
    "        # Entrenar\n",
    "        train_losses = []\n",
    "        for epoch in range(params['epochs']):\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            for batch_x, batch_y in train_loader:\n",
    "                batch_x = batch_x.unsqueeze(-1).to(device)\n",
    "                batch_y = batch_y.unsqueeze(-1).to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "            \n",
    "            avg_loss = epoch_loss / len(train_loader)\n",
    "            train_losses.append(avg_loss)\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{params['epochs']}], Loss: {avg_loss:.4f}\")\n",
    "                mlflow.log_metric(\"train_loss\", avg_loss, step=epoch)\n",
    "        \n",
    "        # Predicciones\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        \n",
    "        # Usar √∫ltimos sequence_length valores de train como semilla\n",
    "        current_sequence = train_normalized[-params['sequence_length']:].tolist()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(len(test_data)):\n",
    "                x = torch.FloatTensor(current_sequence).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "                pred = model(x).item()\n",
    "                predictions.append(pred)\n",
    "                current_sequence = current_sequence[1:] + [pred]\n",
    "        \n",
    "        # Desnormalizar\n",
    "        predictions = np.array(predictions) * train_std + train_mean\n",
    "        \n",
    "        # M√©tricas\n",
    "        mae = mean_absolute_error(test_data['sales'], predictions)\n",
    "        rmse = np.sqrt(mean_squared_error(test_data['sales'], predictions))\n",
    "        r2 = r2_score(test_data['sales'], predictions)\n",
    "        mape = np.mean(np.abs((test_data['sales'] - predictions) / test_data['sales'])) * 100\n",
    "        \n",
    "        # Log m√©tricas\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mape\", mape)\n",
    "        \n",
    "        # Guardar modelo con PyTorch\n",
    "        mlflow.pytorch.log_model(model, \"lstm_model\")\n",
    "        \n",
    "        # Visualizaci√≥n\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        plt.plot(train_data['date'].tail(100), train_data['sales'].tail(100), label='Train (√∫ltimos 100 d√≠as)', linewidth=2)\n",
    "        plt.plot(test_data['date'], test_data['sales'], label='Test (Real)', linewidth=2)\n",
    "        plt.plot(test_data['date'], predictions, label='LSTM Prediction', linestyle='--', linewidth=2)\n",
    "        plt.title('LSTM Forecast')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Sales')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig('lstm_forecast.png', dpi=150, bbox_inches='tight')\n",
    "        mlflow.log_artifact('lstm_forecast.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Training loss\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(train_losses)\n",
    "        plt.title('LSTM Training Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig('lstm_training_loss.png', dpi=150, bbox_inches='tight')\n",
    "        mlflow.log_artifact('lstm_training_loss.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Guardar predicciones\n",
    "        pred_df = pd.DataFrame({\n",
    "            'date': test_data['date'],\n",
    "            'y_true': test_data['sales'],\n",
    "            'y_pred': predictions\n",
    "        })\n",
    "        pred_df.to_csv('lstm_predictions.csv', index=False)\n",
    "        mlflow.log_artifact('lstm_predictions.csv')\n",
    "        \n",
    "        print(f\"\\n‚úÖ LSTM entrenado\")\n",
    "        print(f\"   MAE: {mae:.2f}\")\n",
    "        print(f\"   RMSE: {rmse:.2f}\")\n",
    "        print(f\"   R¬≤: {r2:.4f}\")\n",
    "        print(f\"   MAPE: {mape:.2f}%\")\n",
    "        \n",
    "        return model, predictions, {'mae': mae, 'rmse': rmse, 'r2': r2, 'mape': mape}\n",
    "\n",
    "# Par√°metros LSTM\n",
    "lstm_params = {\n",
    "    'sequence_length': 30,\n",
    "    'hidden_size': 64,\n",
    "    'num_layers': 2,\n",
    "    'dropout': 0.2,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 50\n",
    "}\n",
    "\n",
    "lstm_model, lstm_predictions, lstm_metrics = train_lstm_model(train_df, test_df, lstm_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Comparaci√≥n de Modelos con DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame de comparaci√≥n\n",
    "comparison_df = pd.DataFrame({\n",
    "    'date': test_df['date'],\n",
    "    'actual': test_df['sales'].values,\n",
    "    'prophet': prophet_predictions['yhat'].values,\n",
    "    'sarima': sarima_predictions.values,\n",
    "    'lstm': lstm_predictions\n",
    "})\n",
    "\n",
    "# Guardar en DuckDB\n",
    "con.execute(\"CREATE TABLE IF NOT EXISTS model_predictions AS SELECT * FROM comparison_df\")\n",
    "\n",
    "# An√°lisis con DuckDB\n",
    "metrics_comparison = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        'Prophet' as model,\n",
    "        ROUND(AVG(ABS(actual - prophet)), 2) as mae,\n",
    "        ROUND(SQRT(AVG(POWER(actual - prophet, 2))), 2) as rmse,\n",
    "        ROUND(AVG(ABS((actual - prophet) / actual)) * 100, 2) as mape\n",
    "    FROM model_predictions\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        'SARIMA' as model,\n",
    "        ROUND(AVG(ABS(actual - sarima)), 2) as mae,\n",
    "        ROUND(SQRT(AVG(POWER(actual - sarima, 2))), 2) as rmse,\n",
    "        ROUND(AVG(ABS((actual - sarima) / actual)) * 100, 2) as mape\n",
    "    FROM model_predictions\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        'LSTM' as model,\n",
    "        ROUND(AVG(ABS(actual - lstm)), 2) as mae,\n",
    "        ROUND(SQRT(AVG(POWER(actual - lstm, 2))), 2) as rmse,\n",
    "        ROUND(AVG(ABS((actual - lstm) / actual)) * 100, 2) as mape\n",
    "    FROM model_predictions\n",
    "    \n",
    "    ORDER BY mae\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"üìä Comparaci√≥n de Modelos:\")\n",
    "print(metrics_comparison)\n",
    "\n",
    "# Identificar mejor modelo\n",
    "best_model = metrics_comparison.iloc[0]['model']\n",
    "print(f\"\\nüèÜ Mejor modelo: {best_model} (menor MAE)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualizaci√≥n Comparativa con Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico comparativo interactivo\n",
    "fig = go.Figure()\n",
    "\n",
    "# Datos reales\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=comparison_df['date'],\n",
    "    y=comparison_df['actual'],\n",
    "    mode='lines',\n",
    "    name='Actual',\n",
    "    line=dict(color='black', width=3)\n",
    "))\n",
    "\n",
    "# Prophet\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=comparison_df['date'],\n",
    "    y=comparison_df['prophet'],\n",
    "    mode='lines',\n",
    "    name='Prophet',\n",
    "    line=dict(color='blue', width=2, dash='dash')\n",
    "))\n",
    "\n",
    "# SARIMA\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=comparison_df['date'],\n",
    "    y=comparison_df['sarima'],\n",
    "    mode='lines',\n",
    "    name='SARIMA',\n",
    "    line=dict(color='green', width=2, dash='dot')\n",
    "))\n",
    "\n",
    "# LSTM\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=comparison_df['date'],\n",
    "    y=comparison_df['lstm'],\n",
    "    mode='lines',\n",
    "    name='LSTM',\n",
    "    line=dict(color='red', width=2, dash='dashdot')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Comparaci√≥n de Modelos de Forecasting',\n",
    "    xaxis_title='Fecha',\n",
    "    yaxis_title='Ventas',\n",
    "    height=600,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Gr√°fico de m√©tricas\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='MAE', x=metrics_comparison['model'], y=metrics_comparison['mae']),\n",
    "    go.Bar(name='RMSE', x=metrics_comparison['model'], y=metrics_comparison['rmse']),\n",
    "    go.Bar(name='MAPE', x=metrics_comparison['model'], y=metrics_comparison['mape'])\n",
    "])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='M√©tricas de Error por Modelo',\n",
    "    xaxis_title='Modelo',\n",
    "    yaxis_title='Error',\n",
    "    barmode='group',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Registrar Mejor Modelo en MLflow Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener runs del experimento\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "\n",
    "# Buscar el mejor run por MAE\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=[\"metrics.mae ASC\"],\n",
    "    max_results=1\n",
    ")\n",
    "\n",
    "if runs:\n",
    "    best_run = runs[0]\n",
    "    print(f\"üèÜ Mejor Run:\")\n",
    "    print(f\"   Run ID: {best_run.info.run_id}\")\n",
    "    print(f\"   Run Name: {best_run.info.run_name}\")\n",
    "    print(f\"   MAE: {best_run.data.metrics.get('mae', 0):.2f}\")\n",
    "    print(f\"   RMSE: {best_run.data.metrics.get('rmse', 0):.2f}\")\n",
    "    print(f\"   R¬≤: {best_run.data.metrics.get('r2', 0):.4f}\")\n",
    "    \n",
    "    # Registrar modelo (requiere backend SQL)\n",
    "    # Nota: Para usar Model Registry en producci√≥n, necesitas configurar un backend\n",
    "    # como MySQL o PostgreSQL\n",
    "    print(f\"\\nüí° Para registrar modelo en producci√≥n:\")\n",
    "    print(f\"   mlflow.register_model('runs:/{best_run.info.run_id}/model', 'TimeSeries_Best_Model')\")\n",
    "else:\n",
    "    print(\"No se encontraron runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Resumen y Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéâ RESUMEN DEL EXPERIMENTO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Datos:\")\n",
    "print(f\"   Total d√≠as: {len(df)}\")\n",
    "print(f\"   Train: {len(train_df)} d√≠as\")\n",
    "print(f\"   Test: {len(test_df)} d√≠as\")\n",
    "\n",
    "print(f\"\\nü§ñ Modelos entrenados: 3\")\n",
    "print(f\"   1. Prophet (Facebook)\")\n",
    "print(f\"   2. SARIMA (Statistical)\")\n",
    "print(f\"   3. LSTM (Deep Learning)\")\n",
    "\n",
    "print(f\"\\nüìà Resultados:\")\n",
    "print(metrics_comparison.to_string(index=False))\n",
    "\n",
    "print(f\"\\nüèÜ Ganador: {best_model}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Archivos MLflow generados:\")\n",
    "print(f\"   - Experimento: {experiment_name}\")\n",
    "print(f\"   - Runs: 3\")\n",
    "print(f\"   - Artefactos: Modelos, gr√°ficos, predicciones\")\n",
    "\n",
    "print(f\"\\nüí° Pr√≥ximos pasos:\")\n",
    "print(f\"   - Ajustar hiperpar√°metros\")\n",
    "print(f\"   - Probar ensemble de modelos\")\n",
    "print(f\"   - Implementar reentrenamiento autom√°tico\")\n",
    "print(f\"   - Deployar mejor modelo en producci√≥n\")\n",
    "\n",
    "# Cerrar conexi√≥n\n",
    "con.close()\n",
    "print(\"\\n‚úÖ Conexi√≥n DuckDB cerrada\")\n",
    "print(\"\\nüíª Ver resultados en MLflow UI: mlflow ui --port 5000\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",\n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
